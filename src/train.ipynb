{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.3.19-py3-none-any.whl.metadata (46 kB)\n",
      "Requirement already satisfied: vllm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.8.2)\n",
      "Collecting unsloth_zoo>=2025.3.17 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.3.17-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: torch>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unsloth) (2.6.0)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.29.post3.tar.gz (8.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bitsandbytes (from unsloth)\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: packaging in /Users/pavankumartaddi/Library/Python/3.12/lib/python/site-packages (from unsloth) (24.1)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-0.9.18-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unsloth) (4.48.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unsloth) (3.0.1)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unsloth) (4.66.5)\n",
      "Requirement already satisfied: psutil in /Users/pavankumartaddi/Library/Python/3.12/lib/python/site-packages (from unsloth) (6.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unsloth) (1.26.4)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unsloth) (1.6.0)\n",
      "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n",
      "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
      "  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting protobuf<4.0.0 (from unsloth)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unsloth) (0.25.1)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unsloth) (0.21.0)\n",
      "Requirement already satisfied: cachetools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (5.5.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (2.32.3)\n",
      "Requirement already satisfied: blake3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (1.0.4)\n",
      "Requirement already satisfied: py-cpuinfo in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (9.0.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.21.0)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.12)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (3.7.4)\n",
      "Requirement already satisfied: openai>=1.52.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (1.61.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (2.10.6)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.21.1)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (10.4.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (7.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.8.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.10.11)\n",
      "Requirement already satisfied: llguidance<0.8.0,>=0.7.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.7.11)\n",
      "Requirement already satisfied: outlines==0.1.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (1.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (3.18.0)\n",
      "Requirement already satisfied: partial-json-parser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq in /Users/pavankumartaddi/Library/Python/3.12/lib/python/site-packages (from vllm) (26.1.0)\n",
      "Requirement already satisfied: msgspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.19.0)\n",
      "Requirement already satisfied: gguf==0.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.10.0)\n",
      "Requirement already satisfied: importlib_metadata in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (8.6.1)\n",
      "Requirement already satisfied: mistral_common>=1.5.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mistral_common[opencv]>=1.5.4->vllm) (1.5.4)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (6.0.2)\n",
      "Requirement already satisfied: six>=1.16.0 in /Users/pavankumartaddi/Library/Python/3.12/lib/python/site-packages (from vllm) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=74.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (78.1.0)\n",
      "Requirement already satisfied: einops in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.8.1)\n",
      "Requirement already satisfied: compressed-tensors==0.9.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.9.2)\n",
      "Requirement already satisfied: depyf==0.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (3.1.1)\n",
      "Requirement already satisfied: watchfiles in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (1.0.4)\n",
      "Requirement already satisfied: python-json-logger in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (3.3.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (1.14.0)\n",
      "Requirement already satisfied: ninja in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (1.11.1.4)\n",
      "Requirement already satisfied: torchaudio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from vllm) (2.6.0)\n",
      "Requirement already satisfied: astor in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
      "Requirement already satisfied: dill in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from depyf==0.18.0->vllm) (0.3.8)\n",
      "Requirement already satisfied: interegular in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in /Users/pavankumartaddi/Library/Python/3.12/lib/python/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
      "Requirement already satisfied: referencing in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
      "Requirement already satisfied: pycountry in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (20250224)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.3)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate>=0.34.1->unsloth) (0.5.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (17.0.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.1)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.7)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mistral_common[opencv]>=1.5.4->vllm) (4.11.0.86)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.9->vllm) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (2024.8.30)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (14.0.0)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.3.17->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->vllm) (24.2.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->vllm) (3.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->vllm) (6.1.0)\n",
      "Requirement already satisfied: async_timeout<4.0,>=3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->vllm) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->vllm) (1.12.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from importlib_metadata->vllm) (3.21.0)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting typing_extensions>=4.10 (from vllm)\n",
      "  Using cached typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\n",
      "Requirement already satisfied: typer>=0.12.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.2)\n",
      "Requirement already satisfied: rich-toolkit>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.14.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->outlines==0.1.11->vllm) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema->outlines==0.1.11->vllm) (0.24.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/pavankumartaddi/Library/Python/3.12/lib/python/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.18.0)\n",
      "Requirement already satisfied: click>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn>=0.12.0->uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (8.1.7)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pavankumartaddi/Library/Python/3.12/lib/python/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
      "Downloading unsloth-2025.3.19-py3-none-any.whl (192 kB)\n",
      "Downloading peft-0.15.1-py3-none-any.whl (411 kB)\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Downloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
      "Downloading unsloth_zoo-2025.3.17-py3-none-any.whl (127 kB)\n",
      "Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.18-py3-none-any.whl (123 kB)\n",
      "Using cached typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Building wheels for collected packages: xformers\n",
      "  Building wheel for xformers (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[319 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: BSD License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_deprecation_warning.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/attn_bias_utils.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/checkpoint.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/test.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/utils.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_cpp_lib.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/info.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/triton/importing.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/triton/vararg_kernel.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/triton/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/residual.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/input_projection.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_mem_eff_attention.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_indexing.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_revnet.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_swiglu.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_merge_attentions.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_tiled_matmul.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/utils.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_nystrom_utils.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_attn_decoding.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sequence_parallel_fused.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sddmm.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sp24.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_core.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/rmsnorm.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/modpar_layers.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/swiglu_op.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/unbind.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/rope_padded.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/seqpar.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/sequence_parallel_fused_ops.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/sp24.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/common.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/differentiable_collectives.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/tiled_matmul.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/indexing.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/device_limits.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/find_slowest.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler_dcgm_impl.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler_dcgm.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/api.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profile_analyzer.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/_csr_ops.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/utils.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/blocksparse_tensor.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/csr_tensor.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/fused_softmax.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_blocksparse_attn_interface.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_blocksparse_attention.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/bert_padding.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_og.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_interface.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/_sputnik_sparse.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/core.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/fourier_mix.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/scaled_dot_product.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/utils.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/attention_mask.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/attention_patterns.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/sparsity_config.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/base.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/batch_submit.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/batch_fetch_results.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_with_submitit.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_tasks.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_grid_search.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/model_wrapper.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/dataset.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/k_scaled_index_add.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/matmul_perf_model.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/rope_padded_kernels.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/tiled_matmul_kernels.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/k_index_select_cat.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/rmsnorm_kernels.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/flash3.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/dispatch.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/attn_bias.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/common.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/torch_attention_compat.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck_decoder.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/flash.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/cutlass.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck_splitk.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/triton_splitk.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/_triton/splitk_kernels.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/_triton/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/ops/fmha/_triton\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/losses\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/losses/cross_entropy.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/losses\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/losses/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/losses\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/patch_embed.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/rotary.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_ref.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/interface_torch.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_prefill.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/interface_fa.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/test.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bench.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/utils.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_decode.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_ref.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/pretrained.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/generation.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/benchmark.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/distributed.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/bigcode.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gptj.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/opt.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/llama.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/vit.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/btlm.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/baichuan.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/bert.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/falcon.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gpt_neox.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gpt.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/activations.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/fused_dense.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/rms_norm.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/layer_norm.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/embedding.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/mlp.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/block.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/mha.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/cross_entropy.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/linear.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/k_activations.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/mlp.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/rotary.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/layer_norm.py -> build/lib.macosx-10.9-universal2-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'xformers._C' extension\n",
      "  \u001b[31m   \u001b[0m creating /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention\n",
      "  \u001b[31m   \u001b[0m creating /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/autograd\n",
      "  \u001b[31m   \u001b[0m creating /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu\n",
      "  \u001b[31m   \u001b[0m creating /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/sparse24\n",
      "  \u001b[31m   \u001b[0m creating /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/swiglu\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/13] c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/matmul.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/cpu/matmul.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/matmul.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/matmul.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/cpu/matmul.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m [2/13] c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/sddmm.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/sddmm.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/sddmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/sddmm.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/sddmm.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/sddmm.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/sddmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m [3/13] c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/spmm.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/cpu/spmm.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/spmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/spmm.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/spmm.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/cpu/spmm.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/spmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m [4/13] c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/matmul.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/matmul.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/matmul.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/matmul.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/matmul.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m [5/13] c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/spmm.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/spmm.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/spmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/spmm.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/spmm.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/spmm.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/spmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m [6/13] c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/sparse_softmax.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/sparse_softmax.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/sparse_softmax.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/sparse_softmax.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/sparse_softmax.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/sparse_softmax.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/sparse_softmax.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m [7/13] c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/attention.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/attention.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/attention.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/attention.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/attention.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/attention.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/attention.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m [8/13] c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/sparse_softmax.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/cpu/sparse_softmax.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/sparse_softmax.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/sparse_softmax.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/sparse_softmax.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/cpu/sparse_softmax.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/sparse_softmax.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m [9/13] c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/autograd/matmul.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/autograd/matmul.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/autograd/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/autograd/matmul.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/autograd/matmul.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/autograd/matmul.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/autograd/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m [10/13] c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/sddmm.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/cpu/sddmm.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/sddmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/sddmm.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/sddmm.o.d -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/xformers/csrc/attention/cpu/sddmm.cpp -o /private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/build/temp.macosx-10.9-universal2-cpython-312/xformers/csrc/attention/cpu/sddmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m ninja: build stopped: subcommand failed.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 2209, in _run_ninja_build\n",
      "  \u001b[31m   \u001b[0m     subprocess.run(\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py\", line 571, in run\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, process.args,\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/setup.py\", line 700, in <module>\n",
      "  \u001b[31m   \u001b[0m     setuptools.setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/__init__.py\", line 117, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 186, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 202, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 1002, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/dist.py\", line 1104, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 1021, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/command/bdist_wheel.py\", line 370, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 357, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/dist.py\", line 1104, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 1021, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/command/build.py\", line 135, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 357, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/dist.py\", line 1104, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 1021, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/command/build_ext.py\", line 99, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 368, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/pip-install-mihak70z/xformers_92b77f209bd242e5a8431daa4991cd7b/setup.py\", line 657, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     super().build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 900, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     build_ext.build_extensions(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 484, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     self._build_extensions_serial()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 510, in _build_extensions_serial\n",
      "  \u001b[31m   \u001b[0m     self.build_extension(ext)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/command/build_ext.py\", line 264, in build_extension\n",
      "  \u001b[31m   \u001b[0m     _build_ext.build_extension(self, ext)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 565, in build_extension\n",
      "  \u001b[31m   \u001b[0m     objects = self.compiler.compile(\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 713, in unix_wrap_ninja_compile\n",
      "  \u001b[31m   \u001b[0m     _write_ninja_file_and_compile_objects(\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1869, in _write_ninja_file_and_compile_objects\n",
      "  \u001b[31m   \u001b[0m     _run_ninja_build(\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 2225, in _run_ninja_build\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(message) from e\n",
      "  \u001b[31m   \u001b[0m RuntimeError: Error compiling objects for extension\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for xformers\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for xformers\n",
      "Failed to build xformers\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement triton==3.1.0 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for triton==3.1.0\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting pynvml\n",
      "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml)\n",
      "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
      "Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
      "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: nvidia-ml-py, pynvml\n",
      "Successfully installed nvidia-ml-py-12.570.86 pynvml-12.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth vllm  \n",
    "!pip install triton==3.1.0  \n",
    "!pip install -U pynvml\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/root/workspace/Align-CodeGemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel, PatchFastRL\n",
    "\n",
    "# Patch the FastLanguageModel to integrate GRPO-specific modifications.\n",
    "PatchFastRL(\"GRPO\", FastLanguageModel)\n",
    "\n",
    "from unsloth import is_bfloat16_supported\n",
    "import torch\n",
    "\n",
    "# Set maximum sequence length and LoRA rank (controls the adaptation complexity).\n",
    "max_seq_length = 8192 # Increase if you need longer reasoning traces.\n",
    "lora_rank = 64         # Larger rank can improve performance but may slow down training.\n",
    "\n",
    "# Load the Qwen model in 4-bit mode for reduced memory usage and enable fast inference with vLLM.\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"google/codegemma-7b-it\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True,           # Set to False if using LoRA in 16-bit precision.\n",
    "    fast_inference = True,         # Enable vLLM for faster inference.\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.5,  # Adjust GPU memory usage to avoid out-of-memory errors.\n",
    ")\n",
    "\n",
    "# Wrap the model with PEFT (Parameter-Efficient Fine-Tuning) using LoRA.\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,           # Use a rank greater than 0; common choices include 8, 16, 32, 64, or 128.\n",
    "    lora_alpha = lora_rank,  # A higher lora_alpha value means that the LoRA layers have a greater influence on the model's output, \n",
    "                             # while a lower value reduces this influence\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],                                       # Specify target modules; you can remove QKVO if memory is limited.\n",
    "    use_gradient_checkpointing = \"unsloth\",  # Enable gradient checkpointing for long context finetuning.\n",
    "    random_state = 3407,                     # Set a random seed for reproducibility.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from prompt_template import format_instruction\n",
    "import pandas as pd\n",
    "def load_and_format_json(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data_list = json.load(f)  \n",
    "    data = [\n",
    "        { \n",
    "            \"prompt\": format_instruction(entry[\"instruction\"]) \n",
    "        }\n",
    "        for entry in data_list\n",
    "    ]\n",
    "    df = pd.DataFrame(data)\n",
    "    hf_dataset = Dataset.from_pandas(df)\n",
    "    return hf_dataset\n",
    "train_dataset = load_and_format_json(\"/Users/pavankumartaddi/Desktop/Align-CodeGemma/datas/train_meta.json\")\n",
    "test_dataset = load_and_format_json(\"/Users/pavankumartaddi/Desktop/Align-CodeGemma/datas/test_meta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"\\nYou are an expert AI assistant specializing in generating highly efficient, well-structured, and optimized code using JAX.  \\nFollow these principles:\\n1. **Prioritize efficiency**: Use the most optimal algorithms, minimize computational overhead, and leverage JAX's just-in-time (JIT) compilation and automatic differentiation capabilities for performance optimization. Use JAX primitives wherever applicable for better performance, such as `jax.jit`, `jax.grad`, `jax.vmap`, and `jax.pmap`.\\n2. **Leverage JAX and standard libraries**: Use JAX's powerful vectorized operations (`jax.numpy`,jax.lax), automatic differentiation (`jax.grad`), and other built-in JAX functions to avoid unnecessary custom implementations. Take full advantage of JAX primitives for parallelism, batching.\\n3. **Verify with test cases**: Always include test cases with assertions, including edge cases, to validate the correctness of the solution and to ensure robustness. When relevant, leverage JAX's primitives for optimized testing and verification, particularly when dealing with differentiable code.\\n4. **Think step by step**: Analyze the problem carefully. Break it down into smaller, manageable pieces. Identify efficient solutions using appropriate data structures and optimized JAX library functions. Build the solution incrementally, testing each step for correctness and efficiency.\\n\\nWhile it's mandatory to follow a strict format, ensures that the tests cover various edge cases to verify correctness and robustness.\\n\\n\\nInstruction:\\nWrite a function `run_comparison_suite` that takes a list of test cases. Each test case is a tuple containing `(test_name: str, original_func: callable, transformed_func: callable, args: tuple)`. For each test case, execute both `original_func(*args)` and `transformed_func(*args)`, compare their numerical results for closeness (using a fixed tolerance, e.g., 1e-5), and store the boolean comparison result. Return a dictionary mapping each `test_name` to its boolean result (True for close, False for not close).\\n\\nResponse:\\n- The code implementation is as follows:\\nCode:\\n```python\\n# Your optimized code implementation goes here.\\n# Include test cases with assert statements to confirm the correctness of the code.\\n# Example test case format:\\n# assert function_name(input_data) == expected_output\\n```\\n\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from openai.types import Completion\n",
    "from execserver.code_exec_reqs import exec_test_batched\n",
    "from utils import JAX_LAX_OPERATIONS,JAX_LIBRARIES,JAX_PRIMITIVES,count_jax_usage\n",
    "from typing import List, Dict, Any\n",
    "from openai.types.chat import ChatCompletion  \n",
    "\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "def run_tests_and_reward(\n",
    "    prompts: List[str],\n",
    "    completions: List[List[dict]],\n",
    "    timeout: int = 60,\n",
    "    tests: str = \"\",\n",
    "    timeout_on_client: bool = False\n",
    ") -> List[int]:\n",
    "    server = \"http://localhost:8000\"\n",
    "    \n",
    "    # Get all first content strings (direct content, no need for <code> and <test> parsing)\n",
    "    contents = [completion[0][\"content\"] if completion and \"content\" in completion[0] else \"\" for completion in completions]\n",
    "    \n",
    "    codes = []\n",
    "    for content in contents:\n",
    "        if not content:\n",
    "            codes.append(0.0)  # No content at all\n",
    "            continue\n",
    "        \n",
    "        # If content is provided, treat it as the full code + possible tests\n",
    "        full_code = content.strip() if content else \"\"\n",
    "\n",
    "        # Only append full code if it's not empty, otherwise append 0.0\n",
    "        if full_code:\n",
    "            codes.append(full_code)\n",
    "        else:\n",
    "            codes.append(0.0)  # No code found\n",
    "\n",
    "    # Send the codes for testing (via exec_test_batched)\n",
    "    return exec_test_batched(\n",
    "        server, codes,\n",
    "        timeout=timeout,\n",
    "        timeout_on_client=timeout_on_client\n",
    "    )\n",
    "    \n",
    "\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "def format_reward_func(\n",
    "    prompts: List[str],\n",
    "    completions: List[List[dict]],\n",
    "    **kwargs\n",
    ") -> List[float]:\n",
    "    # Regex pattern checks for \"think\", \"code\", and \"test\" in the content, allowing for any text between them\n",
    "    pattern = re.compile(\n",
    "        r\"\\bthink\\b.*\\bcode\\b.*\\btest\\b.*\",  # Ensure these keywords appear in the content\n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    rewards = []\n",
    "    for completion in completions:\n",
    "        # Extract and strip the content to remove leading/trailing whitespace\n",
    "        content = completion[0][\"content\"] if completion and \"content\" in completion[0] else \"\"\n",
    "        \n",
    "        # Check if the stripped content matches the pattern and assign reward\n",
    "        rewards.append(1.0 if pattern.fullmatch(content) else 0.0)\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "\n",
    "def reward_based_on_jax_usage(\n",
    "    prompts: List[str],\n",
    "    completions: List[List[dict]]\n",
    ") -> List[float]:\n",
    "    codes = []\n",
    "    for completion in completions:\n",
    "        content = completion[0][\"content\"] if completion and \"content\" in completion[0] else \"\"\n",
    "        codes.append(content.strip())  # Strip leading/trailing whitespace\n",
    "\n",
    "    if not codes:\n",
    "        return []\n",
    "\n",
    "    # Calculate JAX usage scores (assuming count_jax_usage is defined elsewhere)\n",
    "    raw_scores = [count_jax_usage(code) for code in codes]\n",
    "    return raw_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "# Configure GRPO training parameters.\n",
    "# This configuration sets up the training hyperparameters, optimization settings, and inference acceleration via vLLM.\n",
    "training_args = GRPOConfig(\n",
    "    use_vllm = True,                     # Enable vLLM to accelerate inference during training.\n",
    "    learning_rate = 5e-6,                # Set the learning rate for the optimizer.\n",
    "    adam_beta1 = 0.9,                    # First beta parameter for the AdamW optimizer.\n",
    "    adam_beta2 = 0.99,                   # Second beta parameter for the AdamW optimizer.\n",
    "    weight_decay = 0.1,                  # Weight decay to regularize the model and prevent overfitting.\n",
    "    warmup_ratio = 0.1,                  # Fraction of steps used for learning rate warmup.\n",
    "    lr_scheduler_type = \"cosine\",        # Use cosine annealing for the learning rate scheduler.\n",
    "    optim = \"adamw_8bit\",                # Use 8-bit AdamW optimizer for memory efficiency.\n",
    "    logging_steps = 1,                   # Log training information every step.\n",
    "    bf16 = is_bfloat16_supported(),      # Use bfloat16 precision if supported by the GPU.\n",
    "    fp16 = not is_bfloat16_supported(),  # Otherwise, fall back to fp16 precision.\n",
    "    per_device_train_batch_size = 1,     # Batch size per device during training.\n",
    "    gradient_accumulation_steps = 1,     # Accumulate gradients over this many steps (increase for smoother training if needed).\n",
    "    num_generations = 8,                 # Number of generations per prompt (reduce if memory issues occur).\n",
    "    max_prompt_length = 256,             # Maximum length for the input prompt.\n",
    "    max_completion_length = 4096,         # Maximum length for the generated completion.\n",
    "    num_train_epochs = 1,               # Uncomment this line to run training for one epoch.\n",
    "    max_steps = 250,                     # Maximum number of training steps.\n",
    "    save_steps = 250,                    # Save the model checkpoint every specified number of steps.\n",
    "    max_grad_norm = 0.1,                 # Maximum gradient norm for gradient clipping.\n",
    "    report_to = \"wandb\",                  # Disable reporting to external services like WandB.\n",
    "    output_dir = \"/root/workspace/Align-CodeGemma/src/outputs\",              # Directory to save the training outputs and checkpoints.\n",
    ")\n",
    "\n",
    "# Instantiate the GRPO trainer with the model, tokenizer, reward functions, and training dataset.\n",
    "trainer = GRPOTrainer(\n",
    "    model = model,                       # The language model to be trained.\n",
    "    processing_class = tokenizer,        # The tokenizer used to preprocess the data.\n",
    "    reward_funcs = [\n",
    "         run_tests_and_reward,\n",
    "         format_reward_func,\n",
    "        reward_based_on_jax_usage     # Reward function evaluating the correctness of the answer.\n",
    "    ],\n",
    "    args = training_args,                # GRPO training configuration.\n",
    "    train_dataset = train_dataset,  \n",
    "    eval_dataset = test_dataset           # The training dataset containing prompts and expected answers.\n",
    ")\n",
    "\n",
    "# Begin training using the GRPO algorithm.\n",
    "trainer.train()\n",
    "\n",
    "# Save the LoRA-adapted model for later use.\n",
    "model.save_lora(\"grpo_saved_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"user\", \"content\" : \"How many r's are in strawberry?\"},\n",
    "], tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "from vllm import SamplingParams\n",
    "\n",
    "# Set the sampling parameters for text generation.\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.8,\n",
    "    top_p = 0.95,\n",
    "    max_tokens = 1024,\n",
    ")\n",
    "\n",
    "# Generate a response from the model without applying any LoRA adapter.\n",
    "output = model.fast_generate(\n",
    "    [text],\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = None,  # No LoRA adapter is used here.\n",
    ")[0].outputs[0].text\n",
    "\n",
    "# Print the generated output.\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
    "    {\"role\" : \"user\", \"content\" : \"How many r's are in strawberry?\"},\n",
    "], tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "from vllm import SamplingParams\n",
    "\n",
    "# Set sampling parameters for controlled text generation.\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.8,\n",
    "    top_p = 0.95,\n",
    "    max_tokens = 1024,\n",
    ")\n",
    "\n",
    "# Generate a response using the saved LoRA adapter.\n",
    "output = model.fast_generate(\n",
    "    text,\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = model.load_lora(\"grpo_saved_lora\"),  # Load the saved LoRA adapter.\n",
    ")[0].outputs[0].text\n",
    "\n",
    "# Print the generated response.\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
