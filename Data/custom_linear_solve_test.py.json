[
  {
    "test_code": "def test_custom_linear_solve_ordered_effects(self):\n\n    def mat_vec(v):\n        jax.debug.callback(lambda: print('mat_vec'), ordered=True)\n        return v\n\n    def solve(b):\n        return lax.custom_linear_solve(mat_vec, b, lambda matvec, x: matvec(x))\n    b = self.rng().randn(24)\n    with jtu.capture_stdout() as output:\n        expected = solve(b)\n        jax.effects_barrier()\n    self.assertEqual(output(), 'mat_vec\\n')\n    with jtu.capture_stdout() as output:\n        computed = jax.jit(solve)(b)\n        jax.effects_barrier()\n    self.assertEqual(output(), 'mat_vec\\n')\n    self.assertAllClose(computed, expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/custom_linear_solve_test.py",
    "function": "def callback(index):\n    i = jnp.arange(len(devices))[index[0]]\n    return jax.vmap(random.key)(i)"
  },
  {
    "test_code": "@jtu.skip_on_flag('jax_skip_slow_tests', True)\n@unittest.skip('Test is too slow (> 2 minutes at time of writing)')\ndef test_custom_linear_solve_pytree(self):\n    \"\"\"Test custom linear solve with inputs and outputs that are pytrees.\"\"\"\n\n    def unrolled_matvec(mat, x):\n        \"\"\"Apply a Python list of lists of scalars to a list of scalars.\"\"\"\n        result = []\n        for i in range(len(mat)):\n            v = 0\n            for j in range(len(x)):\n                if mat[i][j] is not None:\n                    v += mat[i][j] * x[j]\n            result.append(v)\n        return result\n\n    def unrolled_substitution_solve(matvec, b, lower_tri):\n        \"\"\"Solve a triangular unrolled system with fwd/back substitution.\"\"\"\n        zero = jnp.zeros(())\n        one = jnp.ones(())\n        x = [zero for _ in b]\n        ordering = range(len(b)) if lower_tri else range(len(b) - 1, -1, -1)\n        for i in ordering:\n            residual = b[i] - matvec(x)[i]\n            diagonal = matvec([one if i == j else zero for j in range(len(b))])[i]\n            x[i] = residual / diagonal\n        return x\n\n    def custom_unrolled_lower_tri_solve(mat, b):\n        return lax.custom_linear_solve(partial(unrolled_matvec, mat), b, partial(unrolled_substitution_solve, lower_tri=True), partial(unrolled_substitution_solve, lower_tri=False))\n    mat = [[1.0, None, None, None, None, None, None], [1.0, 1.0, None, None, None, None, None], [None, 1.0, 1.0, None, None, None, None], [None, None, 1.0, 1.0, None, None, None], [None, None, None, 1.0, 1.0, None, None], [None, None, None, None, None, 2.0, None], [None, None, None, None, None, 4.0, 3.0]]\n    rng = self.rng()\n    b = list(rng.randn(7))\n    jtu.check_grads(custom_unrolled_lower_tri_solve, (mat, b), order=2, rtol={jnp.float32: 0.02})\n    b_bat = list(b)\n    b_bat[3] = rng.randn(3)\n    jtu.check_grads(jax.vmap(custom_unrolled_lower_tri_solve, in_axes=(None, [None, None, None, 0, None, None, None]), out_axes=[0, 0, 0, 0, 0, None, None]), (mat, b_bat), order=2, rtol={jnp.float32: 0.01})\n    mat[2][1] = rng.randn(3)\n    mat_axis_tree = [[0 if i == 2 and j == 1 else None for j in range(7)] for i in range(7)]\n    jtu.check_grads(jax.vmap(custom_unrolled_lower_tri_solve, in_axes=(mat_axis_tree, None), out_axes=[0, 0, 0, 0, 0, None, None]), (mat, b), order=2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/custom_linear_solve_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.skip_on_flag('jax_skip_slow_tests', True)\ndef test_custom_linear_solve_iterative(self):\n\n    def richardson_iteration(matvec, b, omega=0.1, tolerance=1e-06):\n\n        def cond(x):\n            return jnp.linalg.norm(matvec(x) - b) > tolerance\n\n        def body(x):\n            return x + omega * (b - matvec(x))\n        return lax.while_loop(cond, body, b)\n\n    def matrix_free_solve(matvec, b):\n        return lax.custom_linear_solve(matvec, b, richardson_iteration, richardson_iteration)\n\n    def build_and_solve(a, b):\n        matvec = partial(high_precision_dot, jnp.exp(a))\n        return matrix_free_solve(matvec, jnp.cos(b))\n    rng = np.random.RandomState(0)\n    a = rng.randn(2, 2)\n    b = rng.randn(2)\n    expected = jnp.linalg.solve(jnp.exp(a), jnp.cos(b))\n    actual = build_and_solve(a, b)\n    self.assertAllClose(expected, actual, atol=1e-05)\n    jtu.check_grads(build_and_solve, (a, b), atol=1e-05, order=2, rtol={jnp.float32: 0.06, jnp.float64: 0.002})\n    jtu.check_grads(jax.vmap(build_and_solve), (a[None, :, :], b[None, :]), atol=1e-05, order=2, rtol={jnp.float32: 0.06, jnp.float64: 0.002})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/custom_linear_solve_test.py",
    "function": "def norm(x):\n    norm = np.linalg.norm(x, axis=(-2, -1))\n    return norm / ((inner_dimension + 1) * jnp.finfo(dtype).eps)"
  },
  {
    "test_code": "@jtu.skip_on_flag('jax_skip_slow_tests', True)\n@unittest.skip('Test is too slow (> 1 minute at time of writing)')\ndef test_custom_linear_solve_zeros(self):\n\n    def explicit_jacobian_solve(matvec, b):\n        return lax.stop_gradient(jnp.linalg.solve(jax.jacobian(matvec)(b), b))\n\n    def matrix_free_solve(matvec, b):\n        return lax.custom_linear_solve(matvec, b, explicit_jacobian_solve, explicit_jacobian_solve)\n\n    def linear_solve(a, b):\n        return matrix_free_solve(partial(high_precision_dot, a), b)\n    rng = self.rng()\n    a = rng.randn(3, 3)\n    b = rng.randn(3)\n    jtu.check_grads(lambda x: linear_solve(x, b), (a,), order=2, rtol={np.float32: 0.005})\n    jtu.check_grads(lambda x: linear_solve(a, x), (b,), order=2, rtol={np.float32: 0.005})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/custom_linear_solve_test.py",
    "function": "def linear_solve(a, b):\n    f = lambda y: high_precision_dot(a, y) - b\n    x0 = jnp.zeros_like(b)\n    solution = jnp.linalg.solve(a, b)\n    oracle = lambda func, x0: solution\n    return lax.custom_root(f, x0, oracle, vector_solve)"
  },
  {
    "test_code": "@jtu.skip_on_flag('jax_skip_slow_tests', True)\ndef test_custom_linear_solve_lu(self):\n\n    def linear_solve(a, b):\n        a_factors = jsp.linalg.lu_factor(a)\n        at_factors = jsp.linalg.lu_factor(a.T)\n\n        def solve(matvec, x):\n            return jsp.linalg.lu_solve(a_factors, x)\n\n        def transpose_solve(vecmat, x):\n            return jsp.linalg.lu_solve(at_factors, x)\n        return lax.custom_linear_solve(partial(high_precision_dot, a), b, solve, transpose_solve)\n    rng = self.rng()\n    a = rng.randn(3, 3)\n    b = rng.randn(3)\n    expected = jnp.linalg.solve(a, b)\n    actual = linear_solve(a, b)\n    self.assertAllClose(expected, actual)\n    jtu.check_grads(linear_solve, (a, b), order=2, rtol=0.002)\n    jtu.check_grads(jax.jit(linear_solve), (a, b), order=2, rtol={np.float32: 0.002})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/custom_linear_solve_test.py",
    "function": "def linear_solve(a, b):\n    f = lambda y: high_precision_dot(a, y) - b\n    x0 = jnp.zeros_like(b)\n    solution = jnp.linalg.solve(a, b)\n    oracle = lambda func, x0: solution\n    return lax.custom_root(f, x0, oracle, vector_solve)"
  },
  {
    "test_code": "@jtu.skip_on_flag('jax_skip_slow_tests', True)\ndef test_custom_linear_solve_iterative(self):\n\n    def richardson_iteration(matvec, b, omega=0.1, tolerance=1e-06):\n\n        def cond(x):\n            return jnp.linalg.norm(matvec(x) - b) > tolerance\n\n        def body(x):\n            return x + omega * (b - matvec(x))\n        return lax.while_loop(cond, body, b)\n\n    def matrix_free_solve(matvec, b):\n        return lax.custom_linear_solve(matvec, b, richardson_iteration, richardson_iteration)\n\n    def build_and_solve(a, b):\n        matvec = partial(high_precision_dot, jnp.exp(a))\n        return matrix_free_solve(matvec, jnp.cos(b))\n    rng = np.random.RandomState(0)\n    a = rng.randn(2, 2)\n    b = rng.randn(2)\n    expected = jnp.linalg.solve(jnp.exp(a), jnp.cos(b))\n    actual = build_and_solve(a, b)\n    self.assertAllClose(expected, actual, atol=1e-05)\n    jtu.check_grads(build_and_solve, (a, b), atol=1e-05, order=2, rtol={jnp.float32: 0.06, jnp.float64: 0.002})\n    jtu.check_grads(jax.vmap(build_and_solve), (a[None, :, :], b[None, :]), atol=1e-05, order=2, rtol={jnp.float32: 0.06, jnp.float64: 0.002})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/custom_linear_solve_test.py",
    "function": "def norm(x):\n    norm = np.linalg.norm(x, axis=(-2, -1))\n    return norm / ((n + 1) * jnp.finfo(dtype).eps)"
  }
]