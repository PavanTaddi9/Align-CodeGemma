[
  {
    "test_code": "def test_load_with_layout(self):\n    if not jtu.test_device_matches(['tpu']):\n        self.skipTest('Layouts are only supported on TPUs')\n    mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    np_inp = np.arange(32).reshape(8, 4)\n    s = NamedSharding(mesh, P('x', 'y'))\n    arr = jax.device_put(np_inp, s)\n    out_layout = jax.jit(lambda x: x.T, out_shardings=Layout(DLL.AUTO)).lower(arr).compile().output_layouts\n    self.assertEqual(arr.layout.device_local_layout.major_to_minor, out_layout.device_local_layout.major_to_minor[::-1])\n    ckpt_dir = pathlib.Path(self.create_tempdir('ckpt').full_path)\n    ckpt_path = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/first').full_path)\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, [ckpt_path])\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([arr], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    out, = serialization.run_deserialization([out_layout], tspecs)\n    self.assertEqual(out.layout, out_layout)\n    self.assertIsInstance(out, array.ArrayImpl)\n    self.assertArraysEqual(out, np_inp)\n    for s in out.addressable_shards:\n        self.assertArraysEqual(s.data, np_inp[s.index])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_memory_consumption(self):\n    global_mesh = jtu.create_mesh((2, 4), ('x', 'y'))\n    inp_shape = (2048, 4096)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    sharding = NamedSharding(global_mesh, pspec)\n    src = jnp.arange(num, dtype=np.int32).reshape(inp_shape)\n    inp = array.make_array_from_callback(inp_shape, sharding, lambda idx: src[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('memprof').full_path)\n    tspec = serialization.get_tensorstore_spec(str(ckpt_dir))\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([inp], [tspec], on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n\n    async def deserialize_with_byte_limit():\n        r = await serialization.async_deserialize(sharding, tspec, inp_shape, byte_limiter=serialization._LimitInFlightBytes(4200000))\n        r.block_until_ready()\n    tm.start()\n    asyncio.run(deserialize_with_byte_limit())\n    unused_current, peak = tm.get_traced_memory()\n    self.assertLess(peak, 10000000)\n    deserialize_wo_limit = serialization.async_deserialize(sharding, tspec, inp_shape)\n    tm.clear_traces()\n    asyncio.run(deserialize_wo_limit).block_until_ready()\n    unused_current, peak = tm.get_traced_memory()\n    self.assertGreater(peak, 30000000)\n    tm.stop()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def run(pos):\n    maxiter = 1000\n\n    def cond(v):\n        return v[0] < maxiter\n\n    def step(v):\n        i, pos = v\n        jax.debug.callback(print_it, i + 1, maxiter)\n        return (i + 1, pos + 1)\n    val = (jnp.array(0), pos)\n    val = jax.lax.while_loop(cond, step, val)\n    return val[1]"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_transfer_shard_to_host(self):\n    np_inp = np.arange(16).reshape((4, 4))\n    sharding = SingleDeviceSharding(jax.devices()[0], memory_kind='device')\n    arr = jax.device_put(np_inp, sharding)\n    shard = arr.addressable_shards[0]\n    np_out = asyncio.run(serialization.transfer_shard_to_host(shard))\n    self.assertArraysEqual(np_out, np_inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def run(pos):\n    maxiter = 1000\n\n    def cond(v):\n        return v[0] < maxiter\n\n    def step(v):\n        i, pos = v\n        jax.debug.callback(print_it, i + 1, maxiter)\n        return (i + 1, pos + 1)\n    val = (jnp.array(0), pos)\n    val = jax.lax.while_loop(cond, step, val)\n    return val[1]"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_memory_consumption(self):\n    global_mesh = jtu.create_mesh((2, 4), ('x', 'y'))\n    inp_shape = (2048, 4096)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    sharding = NamedSharding(global_mesh, pspec)\n    src = jnp.arange(num, dtype=np.int32).reshape(inp_shape)\n    inp = array.make_array_from_callback(inp_shape, sharding, lambda idx: src[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('memprof').full_path)\n    tspec = serialization.get_tensorstore_spec(str(ckpt_dir))\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([inp], [tspec], on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n\n    async def deserialize_with_byte_limit():\n        r = await serialization.async_deserialize(sharding, tspec, inp_shape, byte_limiter=serialization._LimitInFlightBytes(4200000))\n        r.block_until_ready()\n    tm.start()\n    asyncio.run(deserialize_with_byte_limit())\n    unused_current, peak = tm.get_traced_memory()\n    self.assertLess(peak, 10000000)\n    deserialize_wo_limit = serialization.async_deserialize(sharding, tspec, inp_shape)\n    tm.clear_traces()\n    asyncio.run(deserialize_wo_limit).block_until_ready()\n    unused_current, peak = tm.get_traced_memory()\n    self.assertGreater(peak, 30000000)\n    tm.stop()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def run(primal_ins, cotangent_outs):\n    primal_outs, vjp = jax.vjp(g, *primal_ins)\n    cotangent_ins = vjp(cotangent_outs)\n    return (primal_outs, cotangent_ins)"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_transfer_shard_to_host(self):\n    np_inp = np.arange(16).reshape((4, 4))\n    sharding = SingleDeviceSharding(jax.devices()[0], memory_kind='device')\n    arr = jax.device_put(np_inp, sharding)\n    shard = arr.addressable_shards[0]\n    np_out = asyncio.run(serialization.transfer_shard_to_host(shard))\n    self.assertArraysEqual(np_out, np_inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def run(primal_ins, cotangent_outs):\n    primal_outs, vjp = jax.vjp(g, *primal_ins)\n    cotangent_ins = vjp(cotangent_outs)\n    return (primal_outs, cotangent_ins)"
  },
  {
    "test_code": "def test_load_with_layout(self):\n    if not jtu.test_device_matches(['tpu']):\n        self.skipTest('Layouts are only supported on TPUs')\n    mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    np_inp = np.arange(32).reshape(8, 4)\n    s = NamedSharding(mesh, P('x', 'y'))\n    arr = jax.device_put(np_inp, s)\n    out_layout = jax.jit(lambda x: x.T, out_shardings=Layout(DLL.AUTO)).lower(arr).compile().output_layouts\n    self.assertEqual(arr.layout.device_local_layout.major_to_minor, out_layout.device_local_layout.major_to_minor[::-1])\n    ckpt_dir = pathlib.Path(self.create_tempdir('ckpt').full_path)\n    ckpt_path = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/first').full_path)\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, [ckpt_path])\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([arr], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    out, = serialization.run_deserialization([out_layout], tspecs)\n    self.assertEqual(out.layout, out_layout)\n    self.assertIsInstance(out, array.ArrayImpl)\n    self.assertArraysEqual(out, np_inp)\n    for s in out.addressable_shards:\n        self.assertArraysEqual(s.data, np_inp[s.index])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def lower(f):\n    \"\"\"Prints the MLIR IR that results from lowering `f`.\n\n    The arguments to `f` are taken to be arrays shaped like `prototypes`.\"\"\"\n    inputs = jax.tree.map(np.array, prototypes)\n    flat_inputs, _ = jax.tree.flatten(inputs)\n    shape_strs = ' '.join([f'{x.dtype.name}[{','.join(map(str, x.shape))}]' for x in flat_inputs])\n    name = f.func.__name__ if hasattr(f, 'func') else f.__name__\n    print(f'\\nTEST: {name} {shape_strs}')\n    print(jax.jit(f).lower(*inputs).compiler_ir())"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_memory_consumption(self):\n    global_mesh = jtu.create_mesh((2, 4), ('x', 'y'))\n    inp_shape = (2048, 4096)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    sharding = NamedSharding(global_mesh, pspec)\n    src = jnp.arange(num, dtype=np.int32).reshape(inp_shape)\n    inp = array.make_array_from_callback(inp_shape, sharding, lambda idx: src[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('memprof').full_path)\n    tspec = serialization.get_tensorstore_spec(str(ckpt_dir))\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([inp], [tspec], on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n\n    async def deserialize_with_byte_limit():\n        r = await serialization.async_deserialize(sharding, tspec, inp_shape, byte_limiter=serialization._LimitInFlightBytes(4200000))\n        r.block_until_ready()\n    tm.start()\n    asyncio.run(deserialize_with_byte_limit())\n    unused_current, peak = tm.get_traced_memory()\n    self.assertLess(peak, 10000000)\n    deserialize_wo_limit = serialization.async_deserialize(sharding, tspec, inp_shape)\n    tm.clear_traces()\n    asyncio.run(deserialize_wo_limit).block_until_ready()\n    unused_current, peak = tm.get_traced_memory()\n    self.assertGreater(peak, 30000000)\n    tm.stop()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "@jax.jit\ndef run(src_dst_ids):\n    return shard_map.shard_map(pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), input_arr.dtype), in_specs=[pl.BlockSpec(memory_space=pltpu.TPUMemorySpace.SMEM), pl.BlockSpec(memory_space=pltpu.TPUMemorySpace.ANY)], out_specs=pl.BlockSpec(memory_space=pltpu.TPUMemorySpace.ANY), scratch_shapes=[pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA], compiler_params=pltpu.TPUCompilerParams(collective_id=0), interpret=mosaic_interpret.TPUInterpretParams(dma_execution_mode='eager', detect_races=True)), mesh=mesh, in_specs=(P(None), P('x', None)), out_specs=P('x', None), check_rep=False)(src_dst_ids, input_arr)"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_transfer_shard_to_host(self):\n    np_inp = np.arange(16).reshape((4, 4))\n    sharding = SingleDeviceSharding(jax.devices()[0], memory_kind='device')\n    arr = jax.device_put(np_inp, sharding)\n    shard = arr.addressable_shards[0]\n    np_out = asyncio.run(serialization.transfer_shard_to_host(shard))\n    self.assertArraysEqual(np_out, np_inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "@jax.jit\ndef run(src_dst_ids):\n    return shard_map.shard_map(pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), input_arr.dtype), in_specs=[pl.BlockSpec(memory_space=pltpu.TPUMemorySpace.SMEM), pl.BlockSpec(memory_space=pltpu.TPUMemorySpace.ANY)], out_specs=pl.BlockSpec(memory_space=pltpu.TPUMemorySpace.ANY), scratch_shapes=[pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA], compiler_params=pltpu.TPUCompilerParams(collective_id=0), interpret=mosaic_interpret.TPUInterpretParams(dma_execution_mode='eager', detect_races=True)), mesh=mesh, in_specs=(P(None), P('x', None)), out_specs=P('x', None), check_rep=False)(src_dst_ids, input_arr)"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_memory_consumption(self):\n    global_mesh = jtu.create_mesh((2, 4), ('x', 'y'))\n    inp_shape = (2048, 4096)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    sharding = NamedSharding(global_mesh, pspec)\n    src = jnp.arange(num, dtype=np.int32).reshape(inp_shape)\n    inp = array.make_array_from_callback(inp_shape, sharding, lambda idx: src[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('memprof').full_path)\n    tspec = serialization.get_tensorstore_spec(str(ckpt_dir))\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([inp], [tspec], on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n\n    async def deserialize_with_byte_limit():\n        r = await serialization.async_deserialize(sharding, tspec, inp_shape, byte_limiter=serialization._LimitInFlightBytes(4200000))\n        r.block_until_ready()\n    tm.start()\n    asyncio.run(deserialize_with_byte_limit())\n    unused_current, peak = tm.get_traced_memory()\n    self.assertLess(peak, 10000000)\n    deserialize_wo_limit = serialization.async_deserialize(sharding, tspec, inp_shape)\n    tm.clear_traces()\n    asyncio.run(deserialize_wo_limit).block_until_ready()\n    unused_current, peak = tm.get_traced_memory()\n    self.assertGreater(peak, 30000000)\n    tm.stop()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def run(interpret=False):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((num_arrays, 128), jnp.float32), out_specs=pl.BlockSpec(memory_space=pltpu.VMEM), interpret=interpret)()"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_transfer_shard_to_host(self):\n    np_inp = np.arange(16).reshape((4, 4))\n    sharding = SingleDeviceSharding(jax.devices()[0], memory_kind='device')\n    arr = jax.device_put(np_inp, sharding)\n    shard = arr.addressable_shards[0]\n    np_out = asyncio.run(serialization.transfer_shard_to_host(shard))\n    self.assertArraysEqual(np_out, np_inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def run(interpret=False):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((num_arrays, 128), jnp.float32), out_specs=pl.BlockSpec(memory_space=pltpu.VMEM), interpret=interpret)()"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_memory_consumption(self):\n    global_mesh = jtu.create_mesh((2, 4), ('x', 'y'))\n    inp_shape = (2048, 4096)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    sharding = NamedSharding(global_mesh, pspec)\n    src = jnp.arange(num, dtype=np.int32).reshape(inp_shape)\n    inp = array.make_array_from_callback(inp_shape, sharding, lambda idx: src[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('memprof').full_path)\n    tspec = serialization.get_tensorstore_spec(str(ckpt_dir))\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([inp], [tspec], on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n\n    async def deserialize_with_byte_limit():\n        r = await serialization.async_deserialize(sharding, tspec, inp_shape, byte_limiter=serialization._LimitInFlightBytes(4200000))\n        r.block_until_ready()\n    tm.start()\n    asyncio.run(deserialize_with_byte_limit())\n    unused_current, peak = tm.get_traced_memory()\n    self.assertLess(peak, 10000000)\n    deserialize_wo_limit = serialization.async_deserialize(sharding, tspec, inp_shape)\n    tm.clear_traces()\n    asyncio.run(deserialize_wo_limit).block_until_ready()\n    unused_current, peak = tm.get_traced_memory()\n    self.assertGreater(peak, 30000000)\n    tm.stop()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def run(refs):\n    x_ref, acc_ref = refs\n\n    @pl.core_map(mesh)\n    def _kernel_entry():\n        pl.run_scoped(functools.partial(_scoped, x_gmem=x_ref, acc_gmem=acc_ref), plgpu.SMEM((blk_m, blk_n), jnp.float32))"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_transfer_shard_to_host(self):\n    np_inp = np.arange(16).reshape((4, 4))\n    sharding = SingleDeviceSharding(jax.devices()[0], memory_kind='device')\n    arr = jax.device_put(np_inp, sharding)\n    shard = arr.addressable_shards[0]\n    np_out = asyncio.run(serialization.transfer_shard_to_host(shard))\n    self.assertArraysEqual(np_out, np_inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def run(refs):\n    x_ref, acc_ref = refs\n\n    @pl.core_map(mesh)\n    def _kernel_entry():\n        pl.run_scoped(functools.partial(_scoped, x_gmem=x_ref, acc_gmem=acc_ref), plgpu.SMEM((blk_m, blk_n), jnp.float32))"
  },
  {
    "test_code": "def test_deserialize_on_array_list(self):\n    global_mesh = jtu.create_mesh((2, 4), ('x', 'y'))\n    inp_shape = (16, 64)\n    pspec = P('x', 'y')\n    sharding = NamedSharding(global_mesh, pspec)\n    inputs = []\n    lambda_fn = lambda idx: src[idx]\n    num_arrays = 5\n    for _ in range(num_arrays):\n        src = jax.random.normal(jax.random.key(0), inp_shape)\n        inp = array.make_array_from_callback(inp_shape, sharding, lambda_fn)\n        inputs.append(inp)\n    ckpt_dir = pathlib.Path(self.create_tempdir().full_path)\n    tspecs = [serialization.get_tensorstore_spec(f'{ckpt_dir}/array_{i}') for i in range(num_arrays)]\n    inputs = tuple(inputs)\n    tspecs = tuple(tspecs)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize(inputs, tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    shardings = tuple([sharding] * num_arrays)\n    restored_arrays = manager.deserialize(shardings, tspecs)\n    self.assertLen(restored_arrays, num_arrays)\n    for inp, deserialized_array in zip(inputs, restored_arrays):\n        self.assertArraysEqual(deserialized_array, inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_memory_consumption(self):\n    global_mesh = jtu.create_mesh((2, 4), ('x', 'y'))\n    inp_shape = (2048, 4096)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    sharding = NamedSharding(global_mesh, pspec)\n    src = jnp.arange(num, dtype=np.int32).reshape(inp_shape)\n    inp = array.make_array_from_callback(inp_shape, sharding, lambda idx: src[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('memprof').full_path)\n    tspec = serialization.get_tensorstore_spec(str(ckpt_dir))\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([inp], [tspec], on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n\n    async def deserialize_with_byte_limit():\n        r = await serialization.async_deserialize(sharding, tspec, inp_shape, byte_limiter=serialization._LimitInFlightBytes(4200000))\n        r.block_until_ready()\n    tm.start()\n    asyncio.run(deserialize_with_byte_limit())\n    unused_current, peak = tm.get_traced_memory()\n    self.assertLess(peak, 10000000)\n    deserialize_wo_limit = serialization.async_deserialize(sharding, tspec, inp_shape)\n    tm.clear_traces()\n    asyncio.run(deserialize_wo_limit).block_until_ready()\n    unused_current, peak = tm.get_traced_memory()\n    self.assertGreater(peak, 30000000)\n    tm.stop()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "def test_memory_consumption_for_save(self):\n    global_mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    inp_shape = (16 * 1024, 16 * 1024)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    sharding = NamedSharding(global_mesh, pspec)\n    src = jnp.arange(num, dtype=np.int32).reshape(inp_shape)\n    inp = array.make_array_from_callback(inp_shape, sharding, lambda idx: src[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('memprofsave').full_path)\n    tspec = serialization.get_tensorstore_spec(str(ckpt_dir))\n    tspec['metadata'] = {'shape': inp.shape, 'compressor': None, 'chunks': inp.shape}\n    is_cpu = jtu.test_device_matches(['cpu'])\n    tm.start()\n    try:\n        manager = serialization.GlobalAsyncCheckpointManager()\n        manager.serialize([inp], [tspec], on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n        manager.wait_until_finished()\n        unused_current, peak = tm.get_traced_memory()\n        self.assertLess(peak, src.nbytes * (1 * (not is_cpu) + 0.5))\n    finally:\n        tm.stop()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "def test_checkpointing_with_path_variant(self):\n    global_mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    inp_shape = (8, 2)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    global_input_data1 = np.arange(num, dtype=np.int32).reshape(inp_shape)\n    a1 = array.make_array_from_callback(inp_shape, NamedSharding(global_mesh, pspec), lambda idx: global_input_data1[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('ckpt_variant').full_path)\n    ckpt_path1 = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/first').full_path)\n    ckpt_paths = [str(ckpt_path1)]\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize_with_paths([a1], ckpt_paths, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    m1, = manager.deserialize_with_paths([NamedSharding(global_mesh, pspec)], ckpt_paths)\n    self.assertIsInstance(m1, array.ArrayImpl)\n    self.assertArraysEqual(np.asarray(m1.addressable_shards[0].data), np.array([[0], [2]], dtype=np.int32))\n    self.assertArraysEqual(np.asarray(m1.addressable_shards[1].data), np.array([[1], [3]], dtype=np.int32))\n    self.assertEqual(m1.addressable_shards[0].data.shape, (2, 1))\n    self.assertEqual(m1.dtype, np.int32)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "def test_checkpointing_jax_array(self):\n    global_mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    inp_shape = (8, 2)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    global_input_data1 = np.arange(num, dtype=np.int32).reshape(inp_shape)\n    a1 = array.make_array_from_callback(inp_shape, NamedSharding(global_mesh, pspec), lambda idx: global_input_data1[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('ckpt').full_path)\n    ckpt_path1 = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/first').full_path)\n    global_input_data2 = np.arange(num, num + num, dtype=np.int32).reshape(inp_shape)\n    a2 = array.make_array_from_callback(inp_shape, NamedSharding(global_mesh, pspec), lambda idx: global_input_data2[idx])\n    ckpt_path2 = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/second').full_path)\n\n    def cb3(_):\n        return np.array([], dtype=np.float32)\n    global_mesh1d = jtu.create_mesh((8,), ('x',))\n    a3 = array.make_array_from_callback((0,), NamedSharding(global_mesh1d, P(None)), cb3)\n    ckpt_path3 = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/third').full_path)\n    ckpt_paths = [str(ckpt_path1), str(ckpt_path2), str(ckpt_path3)]\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, ckpt_paths)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([a1, a2, a3], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    m1, m2, m3 = serialization.run_deserialization([NamedSharding(global_mesh, pspec), NamedSharding(global_mesh, P('x')), NamedSharding(global_mesh1d, P(None))], tspecs)\n    self.assertIsInstance(m1, array.ArrayImpl)\n    self.assertArraysEqual(np.asarray(m1.addressable_shards[0].data), np.array([[0], [2]], dtype=np.int32))\n    self.assertArraysEqual(np.asarray(m1.addressable_shards[1].data), np.array([[1], [3]], dtype=np.int32))\n    self.assertEqual(m1.addressable_shards[0].data.shape, (2, 1))\n    self.assertEqual(m1.dtype, np.int32)\n    self.assertIsInstance(m2, array.ArrayImpl)\n    self.assertArraysEqual(np.asarray(m2.addressable_shards[0].data), np.array([[16, 17], [18, 19]], dtype=np.int32))\n    self.assertArraysEqual(np.asarray(m2.addressable_shards[1].data), np.array([[16, 17], [18, 19]], dtype=np.int32))\n    self.assertEqual(m2.addressable_shards[0].data.shape, (2, 2))\n    self.assertEqual(m2.dtype, np.int32)\n    self.assertIsInstance(m3, array.ArrayImpl)\n    for i, s in enumerate(m3.addressable_shards):\n        self.assertEqual(s.index, (slice(None),))\n        self.assertEqual(s.replica_id, i)\n        self.assertArraysEqual(np.asarray(s.data), np.array([], dtype=np.float32))\n    self.assertEqual(m3.dtype, np.float32)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "def test_checkpointing_ocdbt_transaction(self):\n    global_mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    inp_shape = (8, 2)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    global_input_data1 = np.arange(num, dtype=np.int32).reshape(inp_shape)\n    a1 = array.make_array_from_callback(inp_shape, NamedSharding(global_mesh, pspec), lambda idx: global_input_data1[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('ckpt').full_path)\n    ckpt_path1 = ckpt_dir / 'first'\n    global_input_data2 = np.arange(num, num + num, dtype=np.int32).reshape(inp_shape)\n    a2 = array.make_array_from_callback(inp_shape, NamedSharding(global_mesh, pspec), lambda idx: global_input_data2[idx])\n    ckpt_path2 = ckpt_dir / 'second'\n\n    def cb3(_):\n        return np.array([], dtype=np.float32)\n    global_mesh1d = jtu.create_mesh((8,), ('x',))\n    a3 = array.make_array_from_callback((0,), NamedSharding(global_mesh1d, P(None)), cb3)\n    ckpt_path3 = ckpt_dir / 'third'\n    ckpt_paths = [str(ckpt_path1), str(ckpt_path2), str(ckpt_path3)]\n    tspecs = jax.tree_util.tree_map(lambda p: serialization.get_tensorstore_spec(p, ocdbt=True), ckpt_paths)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    with ts.Transaction(atomic=True) as transaction:\n        manager.serialize([a1, a2, a3], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir), transaction=transaction)\n    manager.wait_until_finished()\n    m1, m2, m3 = serialization.run_deserialization([NamedSharding(global_mesh, pspec), NamedSharding(global_mesh, P('x')), NamedSharding(global_mesh1d, P(None))], tspecs)\n    self.assertIsInstance(m1, array.ArrayImpl)\n    self.assertArraysEqual(np.asarray(m1.addressable_shards[0].data), np.array([[0], [2]], dtype=np.int32))\n    self.assertArraysEqual(np.asarray(m1.addressable_shards[1].data), np.array([[1], [3]], dtype=np.int32))\n    self.assertEqual(m1.addressable_shards[0].data.shape, (2, 1))\n    self.assertEqual(m1.dtype, np.int32)\n    self.assertIsInstance(m2, array.ArrayImpl)\n    self.assertArraysEqual(np.asarray(m2.addressable_shards[0].data), np.array([[16, 17], [18, 19]], dtype=np.int32))\n    self.assertArraysEqual(np.asarray(m2.addressable_shards[1].data), np.array([[16, 17], [18, 19]], dtype=np.int32))\n    self.assertEqual(m2.addressable_shards[0].data.shape, (2, 2))\n    self.assertEqual(m2.dtype, np.int32)\n    self.assertIsInstance(m3, array.ArrayImpl)\n    for i, s in enumerate(m3.addressable_shards):\n        self.assertEqual(s.index, (slice(None),))\n        self.assertEqual(s.replica_id, i)\n        self.assertArraysEqual(np.asarray(s.data), np.array([], dtype=np.float32))\n    self.assertEqual(m3.dtype, np.float32)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "@parameterized.product(input_dtype=[np.int32, jnp.bfloat16])\ndef test_checkpointing_with_bigger_shape_jax_array(self, input_dtype):\n    global_mesh = jtu.create_mesh((2, 2), ('x', 'y'), iota_order=True)\n    global_input_shape = (8, 2)\n    num = math.prod(global_input_shape)\n    global_input_data1 = np.arange(num, dtype=input_dtype).reshape(global_input_shape)\n\n    def cb1(index):\n        return global_input_data1[index]\n    arr = array.make_array_from_callback(global_input_shape, NamedSharding(global_mesh, P('x', 'y')), cb1)\n    ckpt_dir = pathlib.Path(self.create_tempdir('first').full_path)\n    ckpt_paths = [str(ckpt_dir)]\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, ckpt_paths)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([arr], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    ds = NamedSharding(jtu.create_mesh((4, 2), ('x', 'y'), iota_order=True), P('x', 'y'))\n    m1, = serialization.run_deserialization([ds], tspecs, [(12, 2)], [np.float32])\n    expected_data = {0: np.array([[0], [2], [4]], dtype=np.float32), 1: np.array([[1], [3], [5]], dtype=np.float32), 2: np.array([[6], [8], [10]], dtype=np.float32), 3: np.array([[7], [9], [11]], dtype=np.float32), 4: np.array([[12], [14], [0]], dtype=np.float32), 5: np.array([[13], [15], [0]], dtype=np.float32), 6: np.array([[0], [0], [0]], dtype=np.float32), 7: np.array([[0], [0], [0]], dtype=np.float32)}\n    for l in m1.addressable_shards:\n        self.assertArraysEqual(np.asarray(l.data), expected_data[l.device.id])\n    new_ds = GSPMDSharding.get_replicated(list(global_mesh.devices.flat))\n    m2, = serialization.run_deserialization([new_ds], tspecs, [(8, 2)], [np.float32])\n    for l in m2.addressable_shards:\n        self.assertArraysEqual(l.data, global_input_data1.astype('float32'))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "@parameterized.product(input_dtype=[jnp.int4, jnp.int8])\ndef test_checkpointing_with_int4(self, input_dtype):\n    if config.use_shardy_partitioner.value:\n        self.skipTest('TODO(b/376077396): Fix XlaRuntimeError: INVALID_ARGUMENT')\n    global_mesh = jtu.create_mesh((2, 2), ('x', 'y'), iota_order=True)\n    global_input_shape = (8, 2)\n    num = math.prod(global_input_shape)\n    global_input_data = np.arange(num, dtype=input_dtype).reshape(global_input_shape)\n\n    def cb(index):\n        return global_input_data[index]\n    arr = array.make_array_from_callback(global_input_shape, NamedSharding(global_mesh, P('x', 'y')), cb)\n    ckpt_dir = pathlib.Path(self.create_tempdir('first').full_path)\n    ckpt_paths = [str(ckpt_dir)]\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, ckpt_paths)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([arr], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    ds = NamedSharding(jtu.create_mesh((4, 2), ('x', 'y'), iota_order=True), P('x', 'y'))\n    target_dtype = jnp.dtype('int4')\n    m1, = serialization.run_deserialization([ds], tspecs, [(12, 2)], [target_dtype])\n    expected_data = {0: jnp.array([[0], [2], [4]], dtype=target_dtype), 1: jnp.array([[1], [3], [5]], dtype=target_dtype), 2: jnp.array([[6], [8], [10]], dtype=target_dtype), 3: jnp.array([[7], [9], [11]], dtype=target_dtype), 4: jnp.array([[12], [14], [0]], dtype=target_dtype), 5: jnp.array([[13], [15], [0]], dtype=target_dtype), 6: jnp.array([[0], [0], [0]], dtype=target_dtype), 7: jnp.array([[0], [0], [0]], dtype=target_dtype)}\n    for l in m1.addressable_shards:\n        self.assertArraysEqual(np.asarray(l.data), expected_data[l.device.id])\n    new_ds = GSPMDSharding.get_replicated(list(global_mesh.devices.flat))\n    m2, = serialization.run_deserialization([new_ds], tspecs, [(8, 2)], [target_dtype])\n    for l in m2.addressable_shards:\n        self.assertArraysEqual(l.data, global_input_data.astype(target_dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "def test_checkpointing_scalar_jax_array(self):\n    global_mesh = jtu.create_mesh((2,), 'x')\n    global_input_shape = ()\n    data = np.array(4)\n    s = NamedSharding(global_mesh, P(None))\n    array1 = array.make_array_from_callback(global_input_shape, s, lambda idx: data[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('first').full_path)\n    ckpt_paths = [str(ckpt_dir)]\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, ckpt_paths)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([array1], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    ds = NamedSharding(jtu.create_mesh((2,), 'x'), P(None))\n    m1, = serialization.run_deserialization([ds], tspecs, [()], [np.float32])\n    for l in m1.addressable_shards:\n        self.assertArraysEqual(np.asarray(l.data), data.astype(np.float32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "def test_deserialize_tensorstore_array_jax_array(self):\n    global_mesh = jtu.create_mesh((2,), 'x')\n    data = np.arange(1024)\n    tspec = ts.array(data).spec()\n    m1, = serialization.run_deserialization([NamedSharding(global_mesh, P(None))], [tspec])\n    for l in m1.addressable_shards:\n        self.assertArraysEqual(np.asarray(l.data), data)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "def test_load_with_layout(self):\n    if not jtu.test_device_matches(['tpu']):\n        self.skipTest('Layouts are only supported on TPUs')\n    mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    np_inp = np.arange(32).reshape(8, 4)\n    s = NamedSharding(mesh, P('x', 'y'))\n    arr = jax.device_put(np_inp, s)\n    out_layout = jax.jit(lambda x: x.T, out_shardings=Layout(DLL.AUTO)).lower(arr).compile().output_layouts\n    self.assertEqual(arr.layout.device_local_layout.major_to_minor, out_layout.device_local_layout.major_to_minor[::-1])\n    ckpt_dir = pathlib.Path(self.create_tempdir('ckpt').full_path)\n    ckpt_path = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/first').full_path)\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, [ckpt_path])\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([arr], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    out, = serialization.run_deserialization([out_layout], tspecs)\n    self.assertEqual(out.layout, out_layout)\n    self.assertIsInstance(out, array.ArrayImpl)\n    self.assertArraysEqual(out, np_inp)\n    for s in out.addressable_shards:\n        self.assertArraysEqual(s.data, np_inp[s.index])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def create_mesh(shape, axis_names, state):\n    size = math.prod(shape)\n    if len(jax.devices()) < size:\n        state.skip_with_error(f'Requires {size} devices')\n        return None\n    devices = sorted(jax.devices(), key=lambda d: d.id)\n    mesh_devices = np.array(devices[:size]).reshape(shape)\n    global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)\n    return global_mesh"
  },
  {
    "test_code": "def test_deserialize_on_array_list(self):\n    global_mesh = jtu.create_mesh((2, 4), ('x', 'y'))\n    inp_shape = (16, 64)\n    pspec = P('x', 'y')\n    sharding = NamedSharding(global_mesh, pspec)\n    inputs = []\n    lambda_fn = lambda idx: src[idx]\n    num_arrays = 5\n    for _ in range(num_arrays):\n        src = jax.random.normal(jax.random.key(0), inp_shape)\n        inp = array.make_array_from_callback(inp_shape, sharding, lambda_fn)\n        inputs.append(inp)\n    ckpt_dir = pathlib.Path(self.create_tempdir().full_path)\n    tspecs = [serialization.get_tensorstore_spec(f'{ckpt_dir}/array_{i}') for i in range(num_arrays)]\n    inputs = tuple(inputs)\n    tspecs = tuple(tspecs)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize(inputs, tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    shardings = tuple([sharding] * num_arrays)\n    restored_arrays = manager.deserialize(shardings, tspecs)\n    self.assertLen(restored_arrays, num_arrays)\n    for inp, deserialized_array in zip(inputs, restored_arrays):\n        self.assertArraysEqual(deserialized_array, inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def serialize(compiled: jax.stages.Compiled):\n    \"\"\"Serializes a compiled binary.\n\n  Because pytrees are not serializable, they are returned so that\n  the user can handle them properly.\n  \"\"\"\n    unloaded_executable = getattr(compiled._executable, '_unloaded_executable', None)\n    if unloaded_executable is None:\n        raise ValueError('Compilation does not support serialization')\n    args_info_flat, in_tree = jax.tree_util.tree_flatten(compiled.args_info)\n    with io.BytesIO() as file:\n        _JaxPjrtPickler(file).dump((unloaded_executable, args_info_flat, compiled._no_kwargs))\n        return (file.getvalue(), in_tree, compiled.out_tree)"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_memory_consumption(self):\n    global_mesh = jtu.create_mesh((2, 4), ('x', 'y'))\n    inp_shape = (2048, 4096)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    sharding = NamedSharding(global_mesh, pspec)\n    src = jnp.arange(num, dtype=np.int32).reshape(inp_shape)\n    inp = array.make_array_from_callback(inp_shape, sharding, lambda idx: src[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('memprof').full_path)\n    tspec = serialization.get_tensorstore_spec(str(ckpt_dir))\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([inp], [tspec], on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n\n    async def deserialize_with_byte_limit():\n        r = await serialization.async_deserialize(sharding, tspec, inp_shape, byte_limiter=serialization._LimitInFlightBytes(4200000))\n        r.block_until_ready()\n    tm.start()\n    asyncio.run(deserialize_with_byte_limit())\n    unused_current, peak = tm.get_traced_memory()\n    self.assertLess(peak, 10000000)\n    deserialize_wo_limit = serialization.async_deserialize(sharding, tspec, inp_shape)\n    tm.clear_traces()\n    asyncio.run(deserialize_wo_limit).block_until_ready()\n    unused_current, peak = tm.get_traced_memory()\n    self.assertGreater(peak, 30000000)\n    tm.stop()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def serialize(compiled: jax.stages.Compiled):\n    \"\"\"Serializes a compiled binary.\n\n  Because pytrees are not serializable, they are returned so that\n  the user can handle them properly.\n  \"\"\"\n    unloaded_executable = getattr(compiled._executable, '_unloaded_executable', None)\n    if unloaded_executable is None:\n        raise ValueError('Compilation does not support serialization')\n    args_info_flat, in_tree = jax.tree_util.tree_flatten(compiled.args_info)\n    with io.BytesIO() as file:\n        _JaxPjrtPickler(file).dump((unloaded_executable, args_info_flat, compiled._no_kwargs))\n        return (file.getvalue(), in_tree, compiled.out_tree)"
  },
  {
    "test_code": "def test_memory_consumption_for_save(self):\n    global_mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    inp_shape = (16 * 1024, 16 * 1024)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    sharding = NamedSharding(global_mesh, pspec)\n    src = jnp.arange(num, dtype=np.int32).reshape(inp_shape)\n    inp = array.make_array_from_callback(inp_shape, sharding, lambda idx: src[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('memprofsave').full_path)\n    tspec = serialization.get_tensorstore_spec(str(ckpt_dir))\n    tspec['metadata'] = {'shape': inp.shape, 'compressor': None, 'chunks': inp.shape}\n    is_cpu = jtu.test_device_matches(['cpu'])\n    tm.start()\n    try:\n        manager = serialization.GlobalAsyncCheckpointManager()\n        manager.serialize([inp], [tspec], on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n        manager.wait_until_finished()\n        unused_current, peak = tm.get_traced_memory()\n        self.assertLess(peak, src.nbytes * (1 * (not is_cpu) + 0.5))\n    finally:\n        tm.stop()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def serialize(compiled: jax.stages.Compiled):\n    \"\"\"Serializes a compiled binary.\n\n  Because pytrees are not serializable, they are returned so that\n  the user can handle them properly.\n  \"\"\"\n    unloaded_executable = getattr(compiled._executable, '_unloaded_executable', None)\n    if unloaded_executable is None:\n        raise ValueError('Compilation does not support serialization')\n    args_info_flat, in_tree = jax.tree_util.tree_flatten(compiled.args_info)\n    with io.BytesIO() as file:\n        _JaxPjrtPickler(file).dump((unloaded_executable, args_info_flat, compiled._no_kwargs))\n        return (file.getvalue(), in_tree, compiled.out_tree)"
  },
  {
    "test_code": "def test_checkpointing_jax_array(self):\n    global_mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    inp_shape = (8, 2)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    global_input_data1 = np.arange(num, dtype=np.int32).reshape(inp_shape)\n    a1 = array.make_array_from_callback(inp_shape, NamedSharding(global_mesh, pspec), lambda idx: global_input_data1[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('ckpt').full_path)\n    ckpt_path1 = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/first').full_path)\n    global_input_data2 = np.arange(num, num + num, dtype=np.int32).reshape(inp_shape)\n    a2 = array.make_array_from_callback(inp_shape, NamedSharding(global_mesh, pspec), lambda idx: global_input_data2[idx])\n    ckpt_path2 = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/second').full_path)\n\n    def cb3(_):\n        return np.array([], dtype=np.float32)\n    global_mesh1d = jtu.create_mesh((8,), ('x',))\n    a3 = array.make_array_from_callback((0,), NamedSharding(global_mesh1d, P(None)), cb3)\n    ckpt_path3 = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/third').full_path)\n    ckpt_paths = [str(ckpt_path1), str(ckpt_path2), str(ckpt_path3)]\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, ckpt_paths)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([a1, a2, a3], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    m1, m2, m3 = serialization.run_deserialization([NamedSharding(global_mesh, pspec), NamedSharding(global_mesh, P('x')), NamedSharding(global_mesh1d, P(None))], tspecs)\n    self.assertIsInstance(m1, array.ArrayImpl)\n    self.assertArraysEqual(np.asarray(m1.addressable_shards[0].data), np.array([[0], [2]], dtype=np.int32))\n    self.assertArraysEqual(np.asarray(m1.addressable_shards[1].data), np.array([[1], [3]], dtype=np.int32))\n    self.assertEqual(m1.addressable_shards[0].data.shape, (2, 1))\n    self.assertEqual(m1.dtype, np.int32)\n    self.assertIsInstance(m2, array.ArrayImpl)\n    self.assertArraysEqual(np.asarray(m2.addressable_shards[0].data), np.array([[16, 17], [18, 19]], dtype=np.int32))\n    self.assertArraysEqual(np.asarray(m2.addressable_shards[1].data), np.array([[16, 17], [18, 19]], dtype=np.int32))\n    self.assertEqual(m2.addressable_shards[0].data.shape, (2, 2))\n    self.assertEqual(m2.dtype, np.int32)\n    self.assertIsInstance(m3, array.ArrayImpl)\n    for i, s in enumerate(m3.addressable_shards):\n        self.assertEqual(s.index, (slice(None),))\n        self.assertEqual(s.replica_id, i)\n        self.assertArraysEqual(np.asarray(s.data), np.array([], dtype=np.float32))\n    self.assertEqual(m3.dtype, np.float32)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def serialize(compiled: jax.stages.Compiled):\n    \"\"\"Serializes a compiled binary.\n\n  Because pytrees are not serializable, they are returned so that\n  the user can handle them properly.\n  \"\"\"\n    unloaded_executable = getattr(compiled._executable, '_unloaded_executable', None)\n    if unloaded_executable is None:\n        raise ValueError('Compilation does not support serialization')\n    args_info_flat, in_tree = jax.tree_util.tree_flatten(compiled.args_info)\n    with io.BytesIO() as file:\n        _JaxPjrtPickler(file).dump((unloaded_executable, args_info_flat, compiled._no_kwargs))\n        return (file.getvalue(), in_tree, compiled.out_tree)"
  },
  {
    "test_code": "def test_checkpointing_ocdbt_transaction(self):\n    global_mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    inp_shape = (8, 2)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    global_input_data1 = np.arange(num, dtype=np.int32).reshape(inp_shape)\n    a1 = array.make_array_from_callback(inp_shape, NamedSharding(global_mesh, pspec), lambda idx: global_input_data1[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('ckpt').full_path)\n    ckpt_path1 = ckpt_dir / 'first'\n    global_input_data2 = np.arange(num, num + num, dtype=np.int32).reshape(inp_shape)\n    a2 = array.make_array_from_callback(inp_shape, NamedSharding(global_mesh, pspec), lambda idx: global_input_data2[idx])\n    ckpt_path2 = ckpt_dir / 'second'\n\n    def cb3(_):\n        return np.array([], dtype=np.float32)\n    global_mesh1d = jtu.create_mesh((8,), ('x',))\n    a3 = array.make_array_from_callback((0,), NamedSharding(global_mesh1d, P(None)), cb3)\n    ckpt_path3 = ckpt_dir / 'third'\n    ckpt_paths = [str(ckpt_path1), str(ckpt_path2), str(ckpt_path3)]\n    tspecs = jax.tree_util.tree_map(lambda p: serialization.get_tensorstore_spec(p, ocdbt=True), ckpt_paths)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    with ts.Transaction(atomic=True) as transaction:\n        manager.serialize([a1, a2, a3], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir), transaction=transaction)\n    manager.wait_until_finished()\n    m1, m2, m3 = serialization.run_deserialization([NamedSharding(global_mesh, pspec), NamedSharding(global_mesh, P('x')), NamedSharding(global_mesh1d, P(None))], tspecs)\n    self.assertIsInstance(m1, array.ArrayImpl)\n    self.assertArraysEqual(np.asarray(m1.addressable_shards[0].data), np.array([[0], [2]], dtype=np.int32))\n    self.assertArraysEqual(np.asarray(m1.addressable_shards[1].data), np.array([[1], [3]], dtype=np.int32))\n    self.assertEqual(m1.addressable_shards[0].data.shape, (2, 1))\n    self.assertEqual(m1.dtype, np.int32)\n    self.assertIsInstance(m2, array.ArrayImpl)\n    self.assertArraysEqual(np.asarray(m2.addressable_shards[0].data), np.array([[16, 17], [18, 19]], dtype=np.int32))\n    self.assertArraysEqual(np.asarray(m2.addressable_shards[1].data), np.array([[16, 17], [18, 19]], dtype=np.int32))\n    self.assertEqual(m2.addressable_shards[0].data.shape, (2, 2))\n    self.assertEqual(m2.dtype, np.int32)\n    self.assertIsInstance(m3, array.ArrayImpl)\n    for i, s in enumerate(m3.addressable_shards):\n        self.assertEqual(s.index, (slice(None),))\n        self.assertEqual(s.replica_id, i)\n        self.assertArraysEqual(np.asarray(s.data), np.array([], dtype=np.float32))\n    self.assertEqual(m3.dtype, np.float32)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def serialize(compiled: jax.stages.Compiled):\n    \"\"\"Serializes a compiled binary.\n\n  Because pytrees are not serializable, they are returned so that\n  the user can handle them properly.\n  \"\"\"\n    unloaded_executable = getattr(compiled._executable, '_unloaded_executable', None)\n    if unloaded_executable is None:\n        raise ValueError('Compilation does not support serialization')\n    args_info_flat, in_tree = jax.tree_util.tree_flatten(compiled.args_info)\n    with io.BytesIO() as file:\n        _JaxPjrtPickler(file).dump((unloaded_executable, args_info_flat, compiled._no_kwargs))\n        return (file.getvalue(), in_tree, compiled.out_tree)"
  },
  {
    "test_code": "@parameterized.product(input_dtype=[np.int32, jnp.bfloat16])\ndef test_checkpointing_with_bigger_shape_jax_array(self, input_dtype):\n    global_mesh = jtu.create_mesh((2, 2), ('x', 'y'), iota_order=True)\n    global_input_shape = (8, 2)\n    num = math.prod(global_input_shape)\n    global_input_data1 = np.arange(num, dtype=input_dtype).reshape(global_input_shape)\n\n    def cb1(index):\n        return global_input_data1[index]\n    arr = array.make_array_from_callback(global_input_shape, NamedSharding(global_mesh, P('x', 'y')), cb1)\n    ckpt_dir = pathlib.Path(self.create_tempdir('first').full_path)\n    ckpt_paths = [str(ckpt_dir)]\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, ckpt_paths)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([arr], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    ds = NamedSharding(jtu.create_mesh((4, 2), ('x', 'y'), iota_order=True), P('x', 'y'))\n    m1, = serialization.run_deserialization([ds], tspecs, [(12, 2)], [np.float32])\n    expected_data = {0: np.array([[0], [2], [4]], dtype=np.float32), 1: np.array([[1], [3], [5]], dtype=np.float32), 2: np.array([[6], [8], [10]], dtype=np.float32), 3: np.array([[7], [9], [11]], dtype=np.float32), 4: np.array([[12], [14], [0]], dtype=np.float32), 5: np.array([[13], [15], [0]], dtype=np.float32), 6: np.array([[0], [0], [0]], dtype=np.float32), 7: np.array([[0], [0], [0]], dtype=np.float32)}\n    for l in m1.addressable_shards:\n        self.assertArraysEqual(np.asarray(l.data), expected_data[l.device.id])\n    new_ds = GSPMDSharding.get_replicated(list(global_mesh.devices.flat))\n    m2, = serialization.run_deserialization([new_ds], tspecs, [(8, 2)], [np.float32])\n    for l in m2.addressable_shards:\n        self.assertArraysEqual(l.data, global_input_data1.astype('float32'))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def serialize(compiled: jax.stages.Compiled):\n    \"\"\"Serializes a compiled binary.\n\n  Because pytrees are not serializable, they are returned so that\n  the user can handle them properly.\n  \"\"\"\n    unloaded_executable = getattr(compiled._executable, '_unloaded_executable', None)\n    if unloaded_executable is None:\n        raise ValueError('Compilation does not support serialization')\n    args_info_flat, in_tree = jax.tree_util.tree_flatten(compiled.args_info)\n    with io.BytesIO() as file:\n        _JaxPjrtPickler(file).dump((unloaded_executable, args_info_flat, compiled._no_kwargs))\n        return (file.getvalue(), in_tree, compiled.out_tree)"
  },
  {
    "test_code": "@parameterized.product(input_dtype=[jnp.int4, jnp.int8])\ndef test_checkpointing_with_int4(self, input_dtype):\n    if config.use_shardy_partitioner.value:\n        self.skipTest('TODO(b/376077396): Fix XlaRuntimeError: INVALID_ARGUMENT')\n    global_mesh = jtu.create_mesh((2, 2), ('x', 'y'), iota_order=True)\n    global_input_shape = (8, 2)\n    num = math.prod(global_input_shape)\n    global_input_data = np.arange(num, dtype=input_dtype).reshape(global_input_shape)\n\n    def cb(index):\n        return global_input_data[index]\n    arr = array.make_array_from_callback(global_input_shape, NamedSharding(global_mesh, P('x', 'y')), cb)\n    ckpt_dir = pathlib.Path(self.create_tempdir('first').full_path)\n    ckpt_paths = [str(ckpt_dir)]\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, ckpt_paths)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([arr], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    ds = NamedSharding(jtu.create_mesh((4, 2), ('x', 'y'), iota_order=True), P('x', 'y'))\n    target_dtype = jnp.dtype('int4')\n    m1, = serialization.run_deserialization([ds], tspecs, [(12, 2)], [target_dtype])\n    expected_data = {0: jnp.array([[0], [2], [4]], dtype=target_dtype), 1: jnp.array([[1], [3], [5]], dtype=target_dtype), 2: jnp.array([[6], [8], [10]], dtype=target_dtype), 3: jnp.array([[7], [9], [11]], dtype=target_dtype), 4: jnp.array([[12], [14], [0]], dtype=target_dtype), 5: jnp.array([[13], [15], [0]], dtype=target_dtype), 6: jnp.array([[0], [0], [0]], dtype=target_dtype), 7: jnp.array([[0], [0], [0]], dtype=target_dtype)}\n    for l in m1.addressable_shards:\n        self.assertArraysEqual(np.asarray(l.data), expected_data[l.device.id])\n    new_ds = GSPMDSharding.get_replicated(list(global_mesh.devices.flat))\n    m2, = serialization.run_deserialization([new_ds], tspecs, [(8, 2)], [target_dtype])\n    for l in m2.addressable_shards:\n        self.assertArraysEqual(l.data, global_input_data.astype(target_dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def serialize(compiled: jax.stages.Compiled):\n    \"\"\"Serializes a compiled binary.\n\n  Because pytrees are not serializable, they are returned so that\n  the user can handle them properly.\n  \"\"\"\n    unloaded_executable = getattr(compiled._executable, '_unloaded_executable', None)\n    if unloaded_executable is None:\n        raise ValueError('Compilation does not support serialization')\n    args_info_flat, in_tree = jax.tree_util.tree_flatten(compiled.args_info)\n    with io.BytesIO() as file:\n        _JaxPjrtPickler(file).dump((unloaded_executable, args_info_flat, compiled._no_kwargs))\n        return (file.getvalue(), in_tree, compiled.out_tree)"
  },
  {
    "test_code": "def test_checkpointing_scalar_jax_array(self):\n    global_mesh = jtu.create_mesh((2,), 'x')\n    global_input_shape = ()\n    data = np.array(4)\n    s = NamedSharding(global_mesh, P(None))\n    array1 = array.make_array_from_callback(global_input_shape, s, lambda idx: data[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('first').full_path)\n    ckpt_paths = [str(ckpt_dir)]\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, ckpt_paths)\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([array1], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    ds = NamedSharding(jtu.create_mesh((2,), 'x'), P(None))\n    m1, = serialization.run_deserialization([ds], tspecs, [()], [np.float32])\n    for l in m1.addressable_shards:\n        self.assertArraysEqual(np.asarray(l.data), data.astype(np.float32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def serialize(compiled: jax.stages.Compiled):\n    \"\"\"Serializes a compiled binary.\n\n  Because pytrees are not serializable, they are returned so that\n  the user can handle them properly.\n  \"\"\"\n    unloaded_executable = getattr(compiled._executable, '_unloaded_executable', None)\n    if unloaded_executable is None:\n        raise ValueError('Compilation does not support serialization')\n    args_info_flat, in_tree = jax.tree_util.tree_flatten(compiled.args_info)\n    with io.BytesIO() as file:\n        _JaxPjrtPickler(file).dump((unloaded_executable, args_info_flat, compiled._no_kwargs))\n        return (file.getvalue(), in_tree, compiled.out_tree)"
  },
  {
    "test_code": "def test_load_with_layout(self):\n    if not jtu.test_device_matches(['tpu']):\n        self.skipTest('Layouts are only supported on TPUs')\n    mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    np_inp = np.arange(32).reshape(8, 4)\n    s = NamedSharding(mesh, P('x', 'y'))\n    arr = jax.device_put(np_inp, s)\n    out_layout = jax.jit(lambda x: x.T, out_shardings=Layout(DLL.AUTO)).lower(arr).compile().output_layouts\n    self.assertEqual(arr.layout.device_local_layout.major_to_minor, out_layout.device_local_layout.major_to_minor[::-1])\n    ckpt_dir = pathlib.Path(self.create_tempdir('ckpt').full_path)\n    ckpt_path = pathlib.Path(self.create_tempdir(f'{ckpt_dir}/first').full_path)\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, [ckpt_path])\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([arr], tspecs, on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n    out, = serialization.run_deserialization([out_layout], tspecs)\n    self.assertEqual(out.layout, out_layout)\n    self.assertIsInstance(out, array.ArrayImpl)\n    self.assertArraysEqual(out, np_inp)\n    for s in out.addressable_shards:\n        self.assertArraysEqual(s.data, np_inp[s.index])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def serialize(compiled: jax.stages.Compiled):\n    \"\"\"Serializes a compiled binary.\n\n  Because pytrees are not serializable, they are returned so that\n  the user can handle them properly.\n  \"\"\"\n    unloaded_executable = getattr(compiled._executable, '_unloaded_executable', None)\n    if unloaded_executable is None:\n        raise ValueError('Compilation does not support serialization')\n    args_info_flat, in_tree = jax.tree_util.tree_flatten(compiled.args_info)\n    with io.BytesIO() as file:\n        _JaxPjrtPickler(file).dump((unloaded_executable, args_info_flat, compiled._no_kwargs))\n        return (file.getvalue(), in_tree, compiled.out_tree)"
  },
  {
    "test_code": "def test_deserialization_with_int4(self):\n    if config.use_shardy_partitioner.value:\n        self.skipTest('TODO(b/376077396): Fix XlaRuntimeError: INVALID_ARGUMENT')\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest(\"Fails on GPU. Enable after it's fixed\")\n    dtype = jnp.int4\n    shape = (8, 2)\n    arr = jnp.arange(np.prod(shape)).reshape(shape).astype(dtype)\n    ckpt_dir = pathlib.Path(self.create_tempdir('test_ckpt').full_path)\n    sharding = jax.sharding.GSPMDSharding.get_replicated(jax.devices())\n    tspecs = jax.tree_util.tree_map(serialization.get_tensorstore_spec, [ckpt_dir])\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([arr], tspecs, on_commit_callback=lambda: None)\n    manager.wait_until_finished()\n    deserialized_arr, = serialization.run_deserialization(shardings=[sharding], tensorstore_specs=tspecs, global_shapes=[shape], dtypes=[dtype])\n    out = deserialized_arr.astype(jnp.int8)\n    self.assertEqual(out.dtype, jnp.int8)\n    self.assertArraysEqual(out + out, out * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def serialize(compiled: jax.stages.Compiled):\n    \"\"\"Serializes a compiled binary.\n\n  Because pytrees are not serializable, they are returned so that\n  the user can handle them properly.\n  \"\"\"\n    unloaded_executable = getattr(compiled._executable, '_unloaded_executable', None)\n    if unloaded_executable is None:\n        raise ValueError('Compilation does not support serialization')\n    args_info_flat, in_tree = jax.tree_util.tree_flatten(compiled.args_info)\n    with io.BytesIO() as file:\n        _JaxPjrtPickler(file).dump((unloaded_executable, args_info_flat, compiled._no_kwargs))\n        return (file.getvalue(), in_tree, compiled.out_tree)"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_memory_consumption(self):\n    global_mesh = jtu.create_mesh((2, 4), ('x', 'y'))\n    inp_shape = (2048, 4096)\n    pspec = P('x', 'y')\n    num = math.prod(inp_shape)\n    sharding = NamedSharding(global_mesh, pspec)\n    src = jnp.arange(num, dtype=np.int32).reshape(inp_shape)\n    inp = array.make_array_from_callback(inp_shape, sharding, lambda idx: src[idx])\n    ckpt_dir = pathlib.Path(self.create_tempdir('memprof').full_path)\n    tspec = serialization.get_tensorstore_spec(str(ckpt_dir))\n    manager = serialization.GlobalAsyncCheckpointManager()\n    manager.serialize([inp], [tspec], on_commit_callback=partial(self._on_commit_callback, ckpt_dir, ckpt_dir))\n    manager.wait_until_finished()\n\n    async def deserialize_with_byte_limit():\n        r = await serialization.async_deserialize(sharding, tspec, inp_shape, byte_limiter=serialization._LimitInFlightBytes(4200000))\n        r.block_until_ready()\n    tm.start()\n    asyncio.run(deserialize_with_byte_limit())\n    unused_current, peak = tm.get_traced_memory()\n    self.assertLess(peak, 10000000)\n    deserialize_wo_limit = serialization.async_deserialize(sharding, tspec, inp_shape)\n    tm.clear_traces()\n    asyncio.run(deserialize_wo_limit).block_until_ready()\n    unused_current, peak = tm.get_traced_memory()\n    self.assertGreater(peak, 30000000)\n    tm.stop()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def run(*args, **kwargs):\n    mosaic_gpu_lib._mosaic_gpu_ext._cupti_init()\n    try:\n        results = jax.block_until_ready(jax.jit(f)(*args, **kwargs))\n    finally:\n        timings = mosaic_gpu_lib._mosaic_gpu_ext._cupti_get_timings()\n    return (results, timings)"
  },
  {
    "test_code": "@jtu.skip_on_devices('cpu')\ndef test_transfer_shard_to_host(self):\n    np_inp = np.arange(16).reshape((4, 4))\n    sharding = SingleDeviceSharding(jax.devices()[0], memory_kind='device')\n    arr = jax.device_put(np_inp, sharding)\n    shard = arr.addressable_shards[0]\n    np_out = asyncio.run(serialization.transfer_shard_to_host(shard))\n    self.assertArraysEqual(np_out, np_inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/jax/experimental/array_serialization/serialization_test.py",
    "function": "def run(*args, **kwargs):\n    mosaic_gpu_lib._mosaic_gpu_ext._cupti_init()\n    try:\n        results = jax.block_until_ready(jax.jit(f)(*args, **kwargs))\n    finally:\n        timings = mosaic_gpu_lib._mosaic_gpu_ext._cupti_get_timings()\n    return (results, timings)"
  }
]