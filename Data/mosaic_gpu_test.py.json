[
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_input_output_aliases(self):\n\n    def kernel(a_ref, b_ref):\n        del b_ref\n        a_ref[...] = jnp.ones_like(a_ref)\n    a = np.zeros((64, 64), dtype=jnp.float32)\n    b = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)], out_specs=plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM), input_output_aliases={0: 0}, out_shape=a)(a)\n    np.testing.assert_array_equal(b, np.ones_like(a))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@parameterized.product(m=[512], n=[512], manual_consumed_barriers=[False, True])\ndef test_pipelined_copy(self, m, n, manual_consumed_barriers):\n    x = jax.random.uniform(jax.random.key(0), (m, n), dtype=jnp.float16)\n    o = jnp.zeros((m, n), dtype=jnp.float16)\n    blk_m = blk_n = 64\n    o_last_block = jnp.zeros((blk_m, blk_n), dtype=jnp.float16)\n\n    def copy_kernel(x_smem, o_smem, o_last_block_smem, *consumed_barriers):\n        o_smem[...] = x_smem[...]\n        o_last_block_smem[...] = x_smem[...]\n        if manual_consumed_barriers:\n            [x_barrier] = consumed_barriers\n            plgpu.barrier_arrive(x_barrier)\n    block_spec = plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[])\n    pipeline = mgpu_pipeline.emit_pipeline_warp_specialized(copy_kernel, grid=(m // blk_m, n // blk_n), memory_registers=40, max_concurrent_steps=2, num_compute_wgs=2, wg_axis='wg', manual_consumed_barriers=manual_consumed_barriers, in_specs=[block_spec], out_specs=[block_spec, plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (0, 0))])\n    mesh = plgpu.GPUMesh(grid=(1,), num_threads=3, axis_names=('_', 'wg'))\n\n    def run(refs):\n\n        @pl.core_map(mesh, compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n        def _kernel_entry():\n            pipeline(*refs)\n\n    @jax.jit\n    def run_function(x, o, o_last_block):\n        _, out, out_last = pl.run_state(run)((x, o, o_last_block))\n        return (out, out_last)\n    out, out_last_block = run_function(x, o, o_last_block)\n    np.testing.assert_array_equal(out, x)\n    np.testing.assert_array_equal(out_last_block, x[-blk_m:, -blk_n:])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_elementwise_add(self, m=256, n=256, num_compute_wgs=2):\n    blk_m = blk_n = 64\n    x = jax.random.uniform(jax.random.key(0), (m, n), dtype=jnp.float32)\n    y = jax.random.uniform(jax.random.key(1), (m, n), dtype=jnp.float32)\n    o = jnp.zeros((m, n), dtype=jnp.float32)\n\n    def tiled_add_kernel(x_smem, y_smem, o_smem):\n        o_smem[...] = x_smem[...] + y_smem[...]\n    pipeline = mgpu_pipeline.emit_pipeline_warp_specialized(tiled_add_kernel, grid=(m // blk_m, n // blk_n), max_concurrent_steps=2, num_compute_wgs=num_compute_wgs, memory_registers=40, wg_axis='wg', in_specs=[plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[]), plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[])], out_specs=[plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[])])\n    mesh = plgpu.GPUMesh(grid=(1,), num_threads=num_compute_wgs + 1, axis_names=('_', 'wg'))\n\n    def run(refs):\n\n        @pl.core_map(mesh, compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n        def _kernel_entry():\n            pipeline(*refs)\n\n    @jax.jit\n    def run_function(x, y, o):\n        _, _, out = pl.run_state(run)((x, y, o))\n        return out\n    out = run_function(x, y, o)\n    reference = x + y\n    np.testing.assert_allclose(out, reference, atol=0.0001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_carry_accumulate(self, m=256, n=256, num_compute_wgs=2):\n    blk_m = blk_n = 64\n    x = jax.random.uniform(jax.random.key(0), (m, n), dtype=jnp.float32)\n    acc_init = jnp.zeros((blk_m, blk_n), dtype=jnp.float32)\n\n    def _scoped(acc_smem, x_gmem, acc_gmem):\n\n        def _compute_thread():\n            o_acc = plgpu.layout_cast(jnp.full((blk_m, blk_n), 0, dtype=jnp.float32), plgpu.Layout.WG_STRIDED((blk_m, blk_n), vec_size=2))\n            carry_init = (o_acc,)\n            final_carry = (yield carry_init)\n            o_final, = final_carry\n            acc_smem[...] = o_final\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(acc_smem, acc_gmem)\n            plgpu.wait_smem_to_gmem(0)\n\n        def tiled_acc_kernel(x_smem, carry):\n            o_carry, = carry\n            new_carry = x_smem[...] + o_carry\n            return (new_carry,)\n        pipeline = mgpu_pipeline.emit_pipeline_warp_specialized(tiled_acc_kernel, grid=(m // blk_m, n // blk_n), max_concurrent_steps=2, num_compute_wgs=num_compute_wgs, memory_registers=40, wg_axis='wg', carry_coroutine=_compute_thread, in_specs=[plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[])], out_specs=[])\n        pipeline(x_gmem)\n    mesh = plgpu.GPUMesh(grid=(1,), num_threads=num_compute_wgs + 1, axis_names=('_', 'wg'))\n\n    def run(refs):\n        x_ref, acc_ref = refs\n\n        @pl.core_map(mesh)\n        def _kernel_entry():\n            pl.run_scoped(functools.partial(_scoped, x_gmem=x_ref, acc_gmem=acc_ref), plgpu.SMEM((blk_m, blk_n), jnp.float32))\n\n    @jax.jit\n    def run_function(x, acc):\n        _, out_acc = pl.run_state(run)((x, acc))\n        return out_acc\n    out_acc = run_function(x, acc_init)\n    ref = jnp.sum(jnp.stack(np.split(x, m // blk_m, axis=0)), axis=0)\n    ref = jnp.sum(jnp.stack(np.split(ref, n // blk_n, axis=1)), axis=0)\n    np.testing.assert_allclose(out_acc, ref, atol=0.0001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(state):\n    it, _, fx, _ = state\n    return (jnp.max(jnp.abs(fx)) > tol) & (it < max_it)"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(state):\n    it, _, fx, _ = state\n    return (jnp.max(jnp.abs(fx)) > tol) & (it < max_it)"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(state):\n    it, _, fx, _ = state\n    return (jnp.max(jnp.abs(fx)) > tol) & (it < max_it)"
  },
  {
    "test_code": "def test_manual(self):\n    max_concurrent_steps = 2\n    num_steps = 4\n\n    def kernel(x_gmem, o_gmem):\n        return pl.run_scoped(functools.partial(scoped_kernel, x_gmem, o_gmem), plgpu.SMEM((max_concurrent_steps, 32, 16), jnp.float32), plgpu.SMEM((max_concurrent_steps, 32, 16), jnp.float32), plgpu.Barrier(1, num_barriers=max_concurrent_steps))\n\n    def scoped_kernel(x_gmem, o_gmem, x_smem, o_smem, barrier):\n        gmem_slice = pl.ds(pl.program_id(0) * 32, 32)\n\n        def body(step, _):\n            slot = step % max_concurrent_steps\n            plgpu.barrier_wait(barrier.at[slot])\n            plgpu.wait_smem_to_gmem(max_concurrent_steps - 1)\n            o_smem.at[slot][...] = x_smem.at[slot][...] + 1.0\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem.at[slot], o_gmem.at[gmem_slice, pl.ds(step * 16, 16)])\n            fetch_step = step + max_concurrent_steps\n            fetch_slot = slot\n            jax.lax.cond(fetch_step < num_steps, lambda: plgpu.copy_gmem_to_smem(x_gmem.at[gmem_slice, pl.ds(fetch_step * 16, 16)], x_smem.at[fetch_slot], barrier.at[fetch_slot]), lambda: None)\n            return ()\n        for slot in range(min(max_concurrent_steps, num_steps)):\n            plgpu.copy_gmem_to_smem(x_gmem.at[gmem_slice, pl.ds(slot * 16, 16)], x_smem.at[slot], barrier.at[slot])\n        jax.lax.fori_loop(0, num_steps, body, ())\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(32 * 4 * 64).reshape(32 * 4, 64).astype(jnp.float32)\n    kernel_fn = pl.pallas_call(kernel, in_specs=[pl.BlockSpec(memory_space=plgpu.GMEM)], out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(4, 1))\n    np.testing.assert_array_equal(kernel_fn(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(state):\n    it, _, fx, _ = state\n    return (jnp.max(jnp.abs(fx)) > tol) & (it < max_it)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "def test_realistic_matmul(self):\n    dtype = jnp.float16\n    swizzle = 128\n    elems_128b = swizzle // jnp.dtype(dtype).itemsize\n    grid_m, grid_k, grid_n = (132, 10, 4)\n    tile_m = tile_n = 128\n    tile_k = elems_128b\n    m, k, n = (grid_m * tile_m, grid_k * tile_k, grid_n * tile_n)\n\n    def kernel(a_ref, b_ref, o_ref, acc_ref):\n        assert a_ref.shape == (tile_m, tile_k)\n        assert b_ref.shape == (tile_k, tile_n)\n        assert o_ref.shape == acc_ref.shape == (tile_m, tile_n)\n        plgpu.wgmma(acc_ref, a_ref, b_ref)\n        is_last_step = pl.program_id(2) == grid_k - 1\n\n        @pl.when(is_last_step)\n        def _epilogue():\n            o_ref[...] = acc_ref[...].astype(dtype)\n        plgpu.wgmma_wait(1)\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(m, k), dtype=dtype)\n    b = jax.random.uniform(key2, shape=(k, n), dtype=dtype)\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((tile_m, tile_k), lambda m, n, k: (m, k), transforms=(plgpu.TilingTransform((64, elems_128b)), plgpu.SwizzleTransform(128))), plgpu.GPUBlockSpec((tile_k, tile_n), lambda m, n, k: (k, n), transforms=(plgpu.TilingTransform((elems_128b, elems_128b)), plgpu.SwizzleTransform(128)))], out_specs=plgpu.GPUBlockSpec((tile_m, tile_n), lambda m, n, k: (m, n), transforms=(plgpu.TilingTransform((64, elems_128b)), plgpu.SwizzleTransform(128))), out_shape=jax.ShapeDtypeStruct((m, n), jnp.float16), scratch_shapes=[plgpu.ACC((tile_m, tile_n), jnp.float32)], grid=(grid_m, grid_n, grid_k), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'parallel', 'sequential'], max_concurrent_steps=2, delay_release=1))(a, b)\n    np.testing.assert_allclose(res, a @ b, rtol=0.001)",
    "assertions": [
      "assert a_ref.shape == (tile_m, tile_k)",
      "assert b_ref.shape == (tile_k, tile_n)",
      "assert o_ref.shape == acc_ref.shape == (tile_m, tile_n)"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float16, jnp.float32)\ndef test_wgmma(self, dtype):\n    rhs_transpose = jnp.dtype(dtype).itemsize != 2\n    swizzle = 128\n    elems_128b = swizzle // jnp.dtype(dtype).itemsize\n\n    def kernel(a_ref, b_ref, o_ref):\n        if rhs_transpose:\n            b_ref = plgpu.transpose_ref(b_ref, (1, 0))\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref, b_ref)\n            return acc_ref[...]\n        o_ref[...] = pl.run_scoped(scope, plgpu.ACC((64, 192), jnp.float32))\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=dtype)\n    b_shape = (128, 192)\n    if rhs_transpose:\n        b_shape = b_shape[::-1]\n    b = jax.random.uniform(key2, shape=b_shape, dtype=dtype)\n    rhs_transforms = (plgpu.TilingTransform((elems_128b, elems_128b)),)\n    if rhs_transpose:\n        rhs_transforms += (plgpu.TransposeTransform((1, 0, 2, 3)),)\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda i, j: (i, j), transforms=(plgpu.TilingTransform((64, elems_128b)), plgpu.SwizzleTransform(128))), plgpu.GPUBlockSpec(b_shape, lambda *i: i, transforms=(*rhs_transforms, plgpu.SwizzleTransform(128)))], out_specs=plgpu.GPUBlockSpec((64, 192), lambda *i: i), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float32), grid=(1, 1))(a, b)\n    np.testing.assert_allclose(res, a @ (b.T if rhs_transpose else b), rtol=0.001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "def test_wgmma_registers(self):\n\n    def kernel(a_ref, b_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref[...], b_ref)\n            return acc_ref[...]\n        o_ref[...] = pl.run_scoped(scope, plgpu.ACC((64, 192), jnp.float32))\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(128, 192), dtype=jnp.float16)\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((128, 192), lambda: (0, 0), transforms=transforms)], out_specs=plgpu.GPUBlockSpec((64, 192), lambda: (0, 0)), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float32))(a, b)\n    np.testing.assert_allclose(res, a @ b, rtol=0.001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "def test_wgmma_registers_init(self):\n\n    def kernel(a_ref, b_ref, i_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref[...], b_ref)\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    key1, key2, key3 = jax.random.split(jax.random.key(42), 3)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(128, 192), dtype=jnp.float16)\n    i = jax.random.uniform(key3, shape=(64, 192), dtype=jnp.float16) * 10\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((128, 192), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((64, 192), lambda: (0, 0), transforms=transforms)], out_specs=plgpu.GPUBlockSpec((64, 192), lambda: (0, 0)), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float16))(a, b, i)\n    np.testing.assert_allclose(res, i + a @ b, rtol=0.002)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "def test_wgmma_sliced_ref(self):\n\n    def kernel(a_ref, b_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref.at[0], b_ref.at[0])\n            return acc_ref[...]\n        o_ref[...] = pl.run_scoped(scope, plgpu.ACC((64, 192), jnp.float32))\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(2, 64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(2, 128, 192), dtype=jnp.float16)\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((2, 64, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))), plgpu.GPUBlockSpec((2, 128, 192), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))], out_specs=plgpu.GPUBlockSpec((64, 192), lambda: (0, 0)), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float32))(a, b)\n    np.testing.assert_allclose(res, a[0] @ b[0], rtol=0.001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "def test_wgmma_sliced_acc(self):\n    swizzle = 128\n    elems_128b = swizzle // jnp.dtype(jnp.float16).itemsize\n\n    def kernel(a_ref, b_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref, b_ref)\n            return (acc_ref[:, :64], acc_ref[:, 64:])\n        o_ref[:, :64], o_ref[:, 64:] = pl.run_scoped(scope, plgpu.ACC((64, 128), jnp.float32))\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(128, 128), dtype=jnp.float16)\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda i, j: (i, j), transforms=(plgpu.TilingTransform((64, elems_128b)), plgpu.SwizzleTransform(128))), plgpu.GPUBlockSpec((128, 128), lambda *i: i, transforms=(plgpu.TilingTransform((elems_128b, elems_128b)), plgpu.SwizzleTransform(128)))], out_specs=plgpu.GPUBlockSpec((64, 128), lambda *i: i), out_shape=jax.ShapeDtypeStruct((64, 128), jnp.float32), grid=(1, 1))(a, b)\n    np.testing.assert_allclose(res, a @ b, rtol=0.001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "def test_realistic_matmul(self):\n    dtype = jnp.float16\n    swizzle = 128\n    elems_128b = swizzle // jnp.dtype(dtype).itemsize\n    grid_m, grid_k, grid_n = (132, 10, 4)\n    tile_m = tile_n = 128\n    assert tile_m % elems_128b == 0\n    tile_k = elems_128b\n    m, k, n = (grid_m * tile_m, grid_k * tile_k, grid_n * tile_n)\n\n    def kernel(a_gmem, b_gmem, o_smem, acc):\n\n        def kernel_body(a_smem, b_smem):\n            assert a_smem.shape == (tile_m, tile_k)\n            assert b_smem.shape == (tile_k, tile_n)\n            plgpu.wgmma(acc, a_smem, b_smem)\n            plgpu.wgmma_wait(1)\n        pid_m = pl.program_id(0)\n        pid_n = pl.program_id(1)\n        plgpu.emit_pipeline(kernel_body, in_specs=[plgpu.GPUBlockSpec((tile_m, tile_k), lambda k: (pid_m, k), transforms=(plgpu.TilingTransform((64, elems_128b)), plgpu.SwizzleTransform(128))), plgpu.GPUBlockSpec((tile_k, tile_n), lambda k: (k, pid_n), transforms=(plgpu.TilingTransform((elems_128b, elems_128b)), plgpu.SwizzleTransform(128)))], grid=(grid_k,), max_concurrent_steps=2, delay_release=1)(a_gmem, b_gmem)\n        o_smem[...] = acc[...].astype(dtype)\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(m, k), dtype=dtype)\n    b = jax.random.uniform(key2, shape=(k, n), dtype=dtype)\n    res = pl.pallas_call(kernel, in_specs=[pl.BlockSpec(memory_space=plgpu.GMEM), pl.BlockSpec(memory_space=plgpu.GMEM)], out_specs=plgpu.GPUBlockSpec((tile_m, tile_n), lambda m, n: (m, n), transforms=(plgpu.TilingTransform((64, elems_128b)), plgpu.SwizzleTransform(128))), out_shape=jax.ShapeDtypeStruct((m, n), jnp.float16), scratch_shapes=[plgpu.ACC((tile_m, tile_n), jnp.float32)], grid=(grid_m, grid_n))(a, b)\n    np.testing.assert_array_equal(res, a @ b)",
    "assertions": [
      "assert tile_m % elems_128b == 0",
      "assert a_smem.shape == (tile_m, tile_k)",
      "assert b_smem.shape == (tile_k, tile_n)"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "def test_carry_accumulate(self, m=256, n=256, num_compute_wgs=2):\n    blk_m = blk_n = 64\n    x = jax.random.uniform(jax.random.key(0), (m, n), dtype=jnp.float32)\n    acc_init = jnp.zeros((blk_m, blk_n), dtype=jnp.float32)\n\n    def _scoped(acc_smem, x_gmem, acc_gmem):\n\n        def _compute_thread():\n            o_acc = plgpu.layout_cast(jnp.full((blk_m, blk_n), 0, dtype=jnp.float32), plgpu.Layout.WG_STRIDED((blk_m, blk_n), vec_size=2))\n            carry_init = (o_acc,)\n            final_carry = (yield carry_init)\n            o_final, = final_carry\n            acc_smem[...] = o_final\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(acc_smem, acc_gmem)\n            plgpu.wait_smem_to_gmem(0)\n\n        def tiled_acc_kernel(x_smem, carry):\n            o_carry, = carry\n            new_carry = x_smem[...] + o_carry\n            return (new_carry,)\n        pipeline = mgpu_pipeline.emit_pipeline_warp_specialized(tiled_acc_kernel, grid=(m // blk_m, n // blk_n), max_concurrent_steps=2, num_compute_wgs=num_compute_wgs, memory_registers=40, wg_axis='wg', carry_coroutine=_compute_thread, in_specs=[plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[])], out_specs=[])\n        pipeline(x_gmem)\n    mesh = plgpu.GPUMesh(grid=(1,), num_threads=num_compute_wgs + 1, axis_names=('_', 'wg'))\n\n    def run(refs):\n        x_ref, acc_ref = refs\n\n        @pl.core_map(mesh)\n        def _kernel_entry():\n            pl.run_scoped(functools.partial(_scoped, x_gmem=x_ref, acc_gmem=acc_ref), plgpu.SMEM((blk_m, blk_n), jnp.float32))\n\n    @jax.jit\n    def run_function(x, acc):\n        _, out_acc = pl.run_state(run)((x, acc))\n        return out_acc\n    out_acc = run_function(x, acc_init)\n    ref = jnp.sum(jnp.stack(np.split(x, m // blk_m, axis=0)), axis=0)\n    ref = jnp.sum(jnp.stack(np.split(ref, n // blk_n, axis=1)), axis=0)\n    np.testing.assert_allclose(out_acc, ref, atol=0.0001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.named_scope('bar_cond')\ndef cond(x):\n    return x < 5.0"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.named_scope('bar_cond')\ndef cond(x):\n    return x < 5.0"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.named_scope('bar_cond')\ndef cond(x):\n    return x < 5.0"
  },
  {
    "test_code": "def test_manual(self):\n    max_concurrent_steps = 2\n    num_steps = 4\n\n    def kernel(x_gmem, o_gmem):\n        return pl.run_scoped(functools.partial(scoped_kernel, x_gmem, o_gmem), plgpu.SMEM((max_concurrent_steps, 32, 16), jnp.float32), plgpu.SMEM((max_concurrent_steps, 32, 16), jnp.float32), plgpu.Barrier(1, num_barriers=max_concurrent_steps))\n\n    def scoped_kernel(x_gmem, o_gmem, x_smem, o_smem, barrier):\n        gmem_slice = pl.ds(pl.program_id(0) * 32, 32)\n\n        def body(step, _):\n            slot = step % max_concurrent_steps\n            plgpu.barrier_wait(barrier.at[slot])\n            plgpu.wait_smem_to_gmem(max_concurrent_steps - 1)\n            o_smem.at[slot][...] = x_smem.at[slot][...] + 1.0\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem.at[slot], o_gmem.at[gmem_slice, pl.ds(step * 16, 16)])\n            fetch_step = step + max_concurrent_steps\n            fetch_slot = slot\n            jax.lax.cond(fetch_step < num_steps, lambda: plgpu.copy_gmem_to_smem(x_gmem.at[gmem_slice, pl.ds(fetch_step * 16, 16)], x_smem.at[fetch_slot], barrier.at[fetch_slot]), lambda: None)\n            return ()\n        for slot in range(min(max_concurrent_steps, num_steps)):\n            plgpu.copy_gmem_to_smem(x_gmem.at[gmem_slice, pl.ds(slot * 16, 16)], x_smem.at[slot], barrier.at[slot])\n        jax.lax.fori_loop(0, num_steps, body, ())\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(32 * 4 * 64).reshape(32 * 4, 64).astype(jnp.float32)\n    kernel_fn = pl.pallas_call(kernel, in_specs=[pl.BlockSpec(memory_space=plgpu.GMEM)], out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(4, 1))\n    np.testing.assert_array_equal(kernel_fn(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.named_scope('bar_cond')\ndef cond(x):\n    return x < 5.0"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n    tracer_spy.append(x_ref)\n    y_ref[...] = jnp.log(x_ref[...])"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(x):\n    return jnp.linalg.norm(matvec(x) - b) > tolerance"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(x):\n    return jnp.linalg.norm(matvec(x) - b) > tolerance"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(x):\n    return jnp.linalg.norm(matvec(x) - b) > tolerance"
  },
  {
    "test_code": "def test_manual(self):\n    max_concurrent_steps = 2\n    num_steps = 4\n\n    def kernel(x_gmem, o_gmem):\n        return pl.run_scoped(functools.partial(scoped_kernel, x_gmem, o_gmem), plgpu.SMEM((max_concurrent_steps, 32, 16), jnp.float32), plgpu.SMEM((max_concurrent_steps, 32, 16), jnp.float32), plgpu.Barrier(1, num_barriers=max_concurrent_steps))\n\n    def scoped_kernel(x_gmem, o_gmem, x_smem, o_smem, barrier):\n        gmem_slice = pl.ds(pl.program_id(0) * 32, 32)\n\n        def body(step, _):\n            slot = step % max_concurrent_steps\n            plgpu.barrier_wait(barrier.at[slot])\n            plgpu.wait_smem_to_gmem(max_concurrent_steps - 1)\n            o_smem.at[slot][...] = x_smem.at[slot][...] + 1.0\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem.at[slot], o_gmem.at[gmem_slice, pl.ds(step * 16, 16)])\n            fetch_step = step + max_concurrent_steps\n            fetch_slot = slot\n            jax.lax.cond(fetch_step < num_steps, lambda: plgpu.copy_gmem_to_smem(x_gmem.at[gmem_slice, pl.ds(fetch_step * 16, 16)], x_smem.at[fetch_slot], barrier.at[fetch_slot]), lambda: None)\n            return ()\n        for slot in range(min(max_concurrent_steps, num_steps)):\n            plgpu.copy_gmem_to_smem(x_gmem.at[gmem_slice, pl.ds(slot * 16, 16)], x_smem.at[slot], barrier.at[slot])\n        jax.lax.fori_loop(0, num_steps, body, ())\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(32 * 4 * 64).reshape(32 * 4, 64).astype(jnp.float32)\n    kernel_fn = pl.pallas_call(kernel, in_specs=[pl.BlockSpec(memory_space=plgpu.GMEM)], out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(4, 1))\n    np.testing.assert_array_equal(kernel_fn(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(x):\n    return jnp.linalg.norm(matvec(x) - b) > tolerance"
  },
  {
    "test_code": "@parameterized.product(dtypes=[(jnp.float16, jnp.float16), (jnp.int16, jnp.bfloat16), (jnp.int16, jnp.float16), (jnp.uint16, jnp.float16), (jnp.float32, jnp.int32), (jnp.float32, jnp.uint32), (jnp.uint32, jnp.int32), (jnp.int32, jnp.uint32)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_bitcast_convert_type(self, dtypes, thread_semantics):\n    in_dtype, out_dtype = dtypes\n    m, n = (16, 8)\n    out_shape = jax.ShapeDtypeStruct((m, n), out_dtype)\n\n    @functools.partial(pl.pallas_call, out_shape=out_shape, compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def convert(x_ref, y_ref):\n        y_ref[...] = jax.lax.bitcast_convert_type(x_ref[...], out_shape)\n    x = jnp.arange(m * n, dtype=in_dtype).reshape((m, n))\n    np.testing.assert_array_equal(convert(x), jax.lax.bitcast_convert_type(x, out_dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_vjp\ndef convert(x):\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_vjp\ndef inner(carry, scale):\n    del scale\n    return carry"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_vjp\ndef inner(carry, scale):\n    del scale\n    return carry"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_vjp\ndef inner(carry, scale):\n    del scale\n    return carry"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_vjp\ndef inner(carry, scale):\n    del scale\n    return carry"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(x):\n    return jax.pure_callback(_cond_callback, jax.ShapeDtypeStruct((), np.bool_), x)"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(x):\n    return jax.pure_callback(_cond_callback, jax.ShapeDtypeStruct((), np.bool_), x)"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(x):\n    return jax.pure_callback(_cond_callback, jax.ShapeDtypeStruct((), np.bool_), x)"
  },
  {
    "test_code": "def test_manual(self):\n    max_concurrent_steps = 2\n    num_steps = 4\n\n    def kernel(x_gmem, o_gmem):\n        return pl.run_scoped(functools.partial(scoped_kernel, x_gmem, o_gmem), plgpu.SMEM((max_concurrent_steps, 32, 16), jnp.float32), plgpu.SMEM((max_concurrent_steps, 32, 16), jnp.float32), plgpu.Barrier(1, num_barriers=max_concurrent_steps))\n\n    def scoped_kernel(x_gmem, o_gmem, x_smem, o_smem, barrier):\n        gmem_slice = pl.ds(pl.program_id(0) * 32, 32)\n\n        def body(step, _):\n            slot = step % max_concurrent_steps\n            plgpu.barrier_wait(barrier.at[slot])\n            plgpu.wait_smem_to_gmem(max_concurrent_steps - 1)\n            o_smem.at[slot][...] = x_smem.at[slot][...] + 1.0\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem.at[slot], o_gmem.at[gmem_slice, pl.ds(step * 16, 16)])\n            fetch_step = step + max_concurrent_steps\n            fetch_slot = slot\n            jax.lax.cond(fetch_step < num_steps, lambda: plgpu.copy_gmem_to_smem(x_gmem.at[gmem_slice, pl.ds(fetch_step * 16, 16)], x_smem.at[fetch_slot], barrier.at[fetch_slot]), lambda: None)\n            return ()\n        for slot in range(min(max_concurrent_steps, num_steps)):\n            plgpu.copy_gmem_to_smem(x_gmem.at[gmem_slice, pl.ds(slot * 16, 16)], x_smem.at[slot], barrier.at[slot])\n        jax.lax.fori_loop(0, num_steps, body, ())\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(32 * 4 * 64).reshape(32 * 4, 64).astype(jnp.float32)\n    kernel_fn = pl.pallas_call(kernel, in_specs=[pl.BlockSpec(memory_space=plgpu.GMEM)], out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(4, 1))\n    np.testing.assert_array_equal(kernel_fn(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(x):\n    return jax.pure_callback(_cond_callback, jax.ShapeDtypeStruct((), np.bool_), x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(state):\n    idx, x, output = state\n    chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n    chunk_host = jax.device_put(chunk, TransferToMemoryKind('pinned_host'))\n    output = jax.lax.dynamic_update_slice_in_dim(output, chunk_host, idx * chunk_size, axis=0)\n    return (idx + 1, x, output)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(state):\n    idx, x, output = state\n    chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n    chunk_host = jax.device_put(chunk, TransferToMemoryKind('pinned_host'))\n    output = jax.lax.dynamic_update_slice_in_dim(output, chunk_host, idx * chunk_size, axis=0)\n    return (idx + 1, x, output)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(state):\n    idx, x, output = state\n    chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n    chunk_host = jax.device_put(chunk, TransferToMemoryKind('pinned_host'))\n    output = jax.lax.dynamic_update_slice_in_dim(output, chunk_host, idx * chunk_size, axis=0)\n    return (idx + 1, x, output)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(state):\n    idx, x, output = state\n    chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n    chunk_host = jax.device_put(chunk, TransferToMemoryKind('pinned_host'))\n    output = jax.lax.dynamic_update_slice_in_dim(output, chunk_host, idx * chunk_size, axis=0)\n    return (idx + 1, x, output)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(state):\n    idx, x, _ = state\n    chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n    return (idx * chunk_size < x.shape[0]) & jnp.any(chunk > 0)"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(state):\n    idx, x, _ = state\n    chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n    return (idx * chunk_size < x.shape[0]) & jnp.any(chunk > 0)"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(state):\n    idx, x, _ = state\n    chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n    return (idx * chunk_size < x.shape[0]) & jnp.any(chunk > 0)"
  },
  {
    "test_code": "def test_manual(self):\n    max_concurrent_steps = 2\n    num_steps = 4\n\n    def kernel(x_gmem, o_gmem):\n        return pl.run_scoped(functools.partial(scoped_kernel, x_gmem, o_gmem), plgpu.SMEM((max_concurrent_steps, 32, 16), jnp.float32), plgpu.SMEM((max_concurrent_steps, 32, 16), jnp.float32), plgpu.Barrier(1, num_barriers=max_concurrent_steps))\n\n    def scoped_kernel(x_gmem, o_gmem, x_smem, o_smem, barrier):\n        gmem_slice = pl.ds(pl.program_id(0) * 32, 32)\n\n        def body(step, _):\n            slot = step % max_concurrent_steps\n            plgpu.barrier_wait(barrier.at[slot])\n            plgpu.wait_smem_to_gmem(max_concurrent_steps - 1)\n            o_smem.at[slot][...] = x_smem.at[slot][...] + 1.0\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem.at[slot], o_gmem.at[gmem_slice, pl.ds(step * 16, 16)])\n            fetch_step = step + max_concurrent_steps\n            fetch_slot = slot\n            jax.lax.cond(fetch_step < num_steps, lambda: plgpu.copy_gmem_to_smem(x_gmem.at[gmem_slice, pl.ds(fetch_step * 16, 16)], x_smem.at[fetch_slot], barrier.at[fetch_slot]), lambda: None)\n            return ()\n        for slot in range(min(max_concurrent_steps, num_steps)):\n            plgpu.copy_gmem_to_smem(x_gmem.at[gmem_slice, pl.ds(slot * 16, 16)], x_smem.at[slot], barrier.at[slot])\n        jax.lax.fori_loop(0, num_steps, body, ())\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(32 * 4 * 64).reshape(32 * 4, 64).astype(jnp.float32)\n    kernel_fn = pl.pallas_call(kernel, in_specs=[pl.BlockSpec(memory_space=plgpu.GMEM)], out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(4, 1))\n    np.testing.assert_array_equal(kernel_fn(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def cond(state):\n    idx, x, _ = state\n    chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n    return (idx * chunk_size < x.shape[0]) & jnp.any(chunk > 0)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, out_shardings=(tpu_sharding, cpu_sharding))\ndef init():\n    tpu_array = jax.random.normal(jax.random.key(42), (16, 16))\n    cpu_array = jax.random.normal(jax.random.key(42), (16, 16))\n    return (tpu_array, cpu_array)"
  },
  {
    "test_code": "def test_wgmma_registers_init(self):\n\n    def kernel(a_ref, b_ref, i_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref[...], b_ref)\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    key1, key2, key3 = jax.random.split(jax.random.key(42), 3)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(128, 192), dtype=jnp.float16)\n    i = jax.random.uniform(key3, shape=(64, 192), dtype=jnp.float16) * 10\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((128, 192), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((64, 192), lambda: (0, 0), transforms=transforms)], out_specs=plgpu.GPUBlockSpec((64, 192), lambda: (0, 0)), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float16))(a, b, i)\n    np.testing.assert_allclose(res, i + a @ b, rtol=0.002)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, out_shardings=(tpu_sharding, cpu_sharding))\ndef init():\n    tpu_array = jax.random.normal(jax.random.key(42), (16, 16))\n    cpu_array = jax.random.normal(jax.random.key(42), (16, 16))\n    return (tpu_array, cpu_array)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(x):\n    return jnp.reshape(x, (-1, x.shape[1]))"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(x):\n    return jnp.reshape(x, (-1, x.shape[1]))"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(x):\n    return jnp.reshape(x, (-1, x.shape[1]))"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(x):\n    return jnp.reshape(x, (-1, x.shape[1]))"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(meta_params, params):\n    grads = jax.grad(loss)(params, meta_params)\n    grads = lax.psum(grads, axis_name='i')\n    net_grads, mpo_grads = grads\n    net = params[0] + net_grads\n    mpo = params[1]\n    return mpo * net"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(meta_params, params):\n    grads = jax.grad(loss)(params, meta_params)\n    grads = lax.psum(grads, axis_name='i')\n    net_grads, mpo_grads = grads\n    net = params[0] + net_grads\n    mpo = params[1]\n    return mpo * net"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(meta_params, params):\n    grads = jax.grad(loss)(params, meta_params)\n    grads = lax.psum(grads, axis_name='i')\n    net_grads, mpo_grads = grads\n    net = params[0] + net_grads\n    mpo = params[1]\n    return mpo * net"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(meta_params, params):\n    grads = jax.grad(loss)(params, meta_params)\n    grads = lax.psum(grads, axis_name='i')\n    net_grads, mpo_grads = grads\n    net = params[0] + net_grads\n    mpo = params[1]\n    return mpo * net"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=(None, NamedSharding(mesh, P())))\ndef init():\n    tensor = jnp.zeros(shape=(1,))\n    other_tensor = jnp.zeros(shape=(1,))\n    return (tensor, other_tensor)"
  },
  {
    "test_code": "def test_wgmma_registers_init(self):\n\n    def kernel(a_ref, b_ref, i_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref[...], b_ref)\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    key1, key2, key3 = jax.random.split(jax.random.key(42), 3)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(128, 192), dtype=jnp.float16)\n    i = jax.random.uniform(key3, shape=(64, 192), dtype=jnp.float16) * 10\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((128, 192), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((64, 192), lambda: (0, 0), transforms=transforms)], out_specs=plgpu.GPUBlockSpec((64, 192), lambda: (0, 0)), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float16))(a, b, i)\n    np.testing.assert_allclose(res, i + a @ b, rtol=0.002)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, out_shardings=(None, NamedSharding(mesh, P())))\ndef init():\n    tensor = jnp.zeros(shape=(1,))\n    other_tensor = jnp.zeros(shape=(1,))\n    return (tensor, other_tensor)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def init():\n    key, subkey = jax.random.split(key_list[0])\n    key_list[0] = key\n    return jax.random.normal(subkey, ())"
  },
  {
    "test_code": "def test_wgmma_registers_init(self):\n\n    def kernel(a_ref, b_ref, i_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref[...], b_ref)\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    key1, key2, key3 = jax.random.split(jax.random.key(42), 3)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(128, 192), dtype=jnp.float16)\n    i = jax.random.uniform(key3, shape=(64, 192), dtype=jnp.float16) * 10\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((128, 192), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((64, 192), lambda: (0, 0), transforms=transforms)], out_specs=plgpu.GPUBlockSpec((64, 192), lambda: (0, 0)), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float16))(a, b, i)\n    np.testing.assert_allclose(res, i + a @ b, rtol=0.002)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def init():\n    key, subkey = jax.random.split(key_list[0])\n    key_list[0] = key\n    return jax.random.normal(subkey, ())"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_jvp\ndef sum(x):\n    return jnp.sum(x, axis=0)"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_jvp\ndef sum(x):\n    return jnp.sum(x, axis=0)"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_jvp\ndef sum(x):\n    return jnp.sum(x, axis=0)"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_jvp\ndef sum(x):\n    return jnp.sum(x, axis=0)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_jvp\ndef sum(x):\n    return jnp.sum(x, axis=0)"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_jvp\ndef sum(x):\n    return jnp.sum(x, axis=0)"
  },
  {
    "test_code": "def test_carry_accumulate(self, m=256, n=256, num_compute_wgs=2):\n    blk_m = blk_n = 64\n    x = jax.random.uniform(jax.random.key(0), (m, n), dtype=jnp.float32)\n    acc_init = jnp.zeros((blk_m, blk_n), dtype=jnp.float32)\n\n    def _scoped(acc_smem, x_gmem, acc_gmem):\n\n        def _compute_thread():\n            o_acc = plgpu.layout_cast(jnp.full((blk_m, blk_n), 0, dtype=jnp.float32), plgpu.Layout.WG_STRIDED((blk_m, blk_n), vec_size=2))\n            carry_init = (o_acc,)\n            final_carry = (yield carry_init)\n            o_final, = final_carry\n            acc_smem[...] = o_final\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(acc_smem, acc_gmem)\n            plgpu.wait_smem_to_gmem(0)\n\n        def tiled_acc_kernel(x_smem, carry):\n            o_carry, = carry\n            new_carry = x_smem[...] + o_carry\n            return (new_carry,)\n        pipeline = mgpu_pipeline.emit_pipeline_warp_specialized(tiled_acc_kernel, grid=(m // blk_m, n // blk_n), max_concurrent_steps=2, num_compute_wgs=num_compute_wgs, memory_registers=40, wg_axis='wg', carry_coroutine=_compute_thread, in_specs=[plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[])], out_specs=[])\n        pipeline(x_gmem)\n    mesh = plgpu.GPUMesh(grid=(1,), num_threads=num_compute_wgs + 1, axis_names=('_', 'wg'))\n\n    def run(refs):\n        x_ref, acc_ref = refs\n\n        @pl.core_map(mesh)\n        def _kernel_entry():\n            pl.run_scoped(functools.partial(_scoped, x_gmem=x_ref, acc_gmem=acc_ref), plgpu.SMEM((blk_m, blk_n), jnp.float32))\n\n    @jax.jit\n    def run_function(x, acc):\n        _, out_acc = pl.run_state(run)((x, acc))\n        return out_acc\n    out_acc = run_function(x, acc_init)\n    ref = jnp.sum(jnp.stack(np.split(x, m // blk_m, axis=0)), axis=0)\n    ref = jnp.sum(jnp.stack(np.split(ref, n // blk_n, axis=1)), axis=0)\n    np.testing.assert_allclose(out_acc, ref, atol=0.0001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.custom_jvp\ndef sum(x):\n    return jnp.sum(x, axis=0)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef inner(a, x):\n    return (a, jnp.exp(x))"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef inner(a, x):\n    return (a, jnp.exp(x))"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef inner(a, x):\n    return (a, jnp.exp(x))"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef inner(a, x):\n    return (a, jnp.exp(x))"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    y = jnp.array([2, 5])\n    return lax.rev(x * y, (0,))"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.argmax(x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(ctx, dst, _):\n    i8 = ir.IntegerType.get_signless(8)\n    iota = iota_tensor(m, n, jnp.uint8)\n    (iota > 10).astype(i8, is_signed=False).store_untiled(dst)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return x + c"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jnp.cos(jnp.sum(jnp.exp(-x)) ** 2)"
  },
  {
    "test_code": "def test_pipeline_mode(self):\n\n    def body(x_ref, y_ref, o_ref):\n        x = x_ref[:]\n        y = y_ref[:]\n        o_ref[:] = x + y\n    data_size = 64 * 256\n    block_size = 256\n    x = jnp.arange(data_size, dtype=jnp.float32)\n    y = jnp.arange(data_size, dtype=jnp.float32)\n    in_specs = [pl.BlockSpec((block_size,), lambda *i: i, pipeline_mode=pl.Buffered(2)), pl.BlockSpec((block_size,), lambda *i: i, pipeline_mode=pl.Buffered(1))]\n    out_specs = pl.BlockSpec((block_size,), lambda *i: i)\n\n    @jax.jit\n    def vadd(x, y):\n        return pl.pallas_call(body, out_shape=jax.ShapeDtypeStruct(x.shape, jnp.float32), in_specs=in_specs, out_specs=out_specs, grid=data_size // block_size)(x, y)\n    with self.assertRaisesRegex(Exception, 'Pipeline mode is not supported'):\n        vadd(x, y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef vadd(x, y):\n    return self.pallas_call(body, out_shape=jax.ShapeDtypeStruct(x.shape, jnp.float32), in_specs=in_specs, out_specs=out_specs, grid=data_size // block_size)(x, y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, y):\n    z = jax.numpy.add(x, y)\n    return self.pallas_call(kernel, grid=(3,), in_specs=[pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0))], out_specs=pl.BlockSpec((1, 128, 128), lambda i: (i, 0, 0)), out_shape=x, compiler_params=pltpu.TPUCompilerParams(allow_input_fusion=[True]))(z)"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=1, grid=(grid_size,), in_specs=[pl.BlockSpec((8, 128), lambda i, s_ref: (pl.load(s_ref[0], (i,)), 0)), pl.BlockSpec((1, 128), lambda i, s_ref: (0, 0))], out_specs=pl.BlockSpec((32, 128), lambda i, s_ref: (pl.load(s_ref[0], i), 0)), scratch_shapes=[pltpu.SemaphoreType.REGULAR((3,))] if scratch else []))\ndef kernel(s_refs, src, to_store, dst, *scratch_refs):\n    s_ref, s2, s3 = s_refs\n    assert s_ref.shape == (2,)\n    assert s2.shape == (3,)\n    assert s3 is None\n    store_idx = s_ref[pl.program_id(0)]\n    pl.store(dst, (pl.dslice(store_idx, 1), slice(None)), to_store[...])"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    return pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), grid=(iters,), in_specs=(pl.BlockSpec(x.shape, lambda i: (0, 0)),), out_specs=pl.BlockSpec(x.shape, lambda i: (0, 0)), interpret=mosaic_interpret.TPUInterpretParams())(x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "@parameterized.product(input_factor=[0.001, 1, 10, 100, 100])\ndef test_layer_norm(self, input_factor):\n    eps = 1e-05\n    gamma = 1.0\n    beta = 1.0\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def layer_norm(x_ref, o_ref):\n        x_mean = jnp.mean(x_ref[...])\n        x_centered = x_ref[...] - x_mean\n        o_ref[...] = x_centered * jax.lax.rsqrt(jnp.mean(x_centered ** 2) + eps) * gamma + beta\n\n    def layer_norm_np(x):\n        x_mean = np.mean(x)\n        x_centered = x - x_mean\n        return x_centered / np.sqrt(np.mean(x_centered ** 2) + eps) * gamma + beta\n    x = jnp.ones((256,)).astype(jnp.float32) * input_factor\n    np.testing.assert_allclose(layer_norm(x), layer_norm_np(x))\n    x = jax.random.uniform(jax.random.key(42), shape=(256,), dtype=jnp.float32) * input_factor\n    np.testing.assert_allclose(layer_norm(x), layer_norm_np(x), rtol=5e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_realistic_matmul(self):\n    dtype = jnp.float16\n    swizzle = 128\n    elems_128b = swizzle // jnp.dtype(dtype).itemsize\n    grid_m, grid_k, grid_n = (132, 10, 4)\n    tile_m = tile_n = 128\n    tile_k = elems_128b\n    m, k, n = (grid_m * tile_m, grid_k * tile_k, grid_n * tile_n)\n\n    def kernel(a_ref, b_ref, o_ref, acc_ref):\n        assert a_ref.shape == (tile_m, tile_k)\n        assert b_ref.shape == (tile_k, tile_n)\n        assert o_ref.shape == acc_ref.shape == (tile_m, tile_n)\n        plgpu.wgmma(acc_ref, a_ref, b_ref)\n        is_last_step = pl.program_id(2) == grid_k - 1\n\n        @pl.when(is_last_step)\n        def _epilogue():\n            o_ref[...] = acc_ref[...].astype(dtype)\n        plgpu.wgmma_wait(1)\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(m, k), dtype=dtype)\n    b = jax.random.uniform(key2, shape=(k, n), dtype=dtype)\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((tile_m, tile_k), lambda m, n, k: (m, k), transforms=(plgpu.TilingTransform((64, elems_128b)), plgpu.SwizzleTransform(128))), plgpu.GPUBlockSpec((tile_k, tile_n), lambda m, n, k: (k, n), transforms=(plgpu.TilingTransform((elems_128b, elems_128b)), plgpu.SwizzleTransform(128)))], out_specs=plgpu.GPUBlockSpec((tile_m, tile_n), lambda m, n, k: (m, n), transforms=(plgpu.TilingTransform((64, elems_128b)), plgpu.SwizzleTransform(128))), out_shape=jax.ShapeDtypeStruct((m, n), jnp.float16), scratch_shapes=[plgpu.ACC((tile_m, tile_n), jnp.float32)], grid=(grid_m, grid_n, grid_k), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'parallel', 'sequential'], max_concurrent_steps=2, delay_release=1))(a, b)\n    np.testing.assert_allclose(res, a @ b, rtol=0.001)",
    "assertions": [
      "assert a_ref.shape == (tile_m, tile_k)",
      "assert b_ref.shape == (tile_k, tile_n)",
      "assert o_ref.shape == acc_ref.shape == (tile_m, tile_n)"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float16, jnp.float32)\ndef test_wgmma(self, dtype):\n    rhs_transpose = jnp.dtype(dtype).itemsize != 2\n    swizzle = 128\n    elems_128b = swizzle // jnp.dtype(dtype).itemsize\n\n    def kernel(a_ref, b_ref, o_ref):\n        if rhs_transpose:\n            b_ref = plgpu.transpose_ref(b_ref, (1, 0))\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref, b_ref)\n            return acc_ref[...]\n        o_ref[...] = pl.run_scoped(scope, plgpu.ACC((64, 192), jnp.float32))\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=dtype)\n    b_shape = (128, 192)\n    if rhs_transpose:\n        b_shape = b_shape[::-1]\n    b = jax.random.uniform(key2, shape=b_shape, dtype=dtype)\n    rhs_transforms = (plgpu.TilingTransform((elems_128b, elems_128b)),)\n    if rhs_transpose:\n        rhs_transforms += (plgpu.TransposeTransform((1, 0, 2, 3)),)\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda i, j: (i, j), transforms=(plgpu.TilingTransform((64, elems_128b)), plgpu.SwizzleTransform(128))), plgpu.GPUBlockSpec(b_shape, lambda *i: i, transforms=(*rhs_transforms, plgpu.SwizzleTransform(128)))], out_specs=plgpu.GPUBlockSpec((64, 192), lambda *i: i), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float32), grid=(1, 1))(a, b)\n    np.testing.assert_allclose(res, a @ (b.T if rhs_transpose else b), rtol=0.001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_wgmma_registers(self):\n\n    def kernel(a_ref, b_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref[...], b_ref)\n            return acc_ref[...]\n        o_ref[...] = pl.run_scoped(scope, plgpu.ACC((64, 192), jnp.float32))\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(128, 192), dtype=jnp.float16)\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((128, 192), lambda: (0, 0), transforms=transforms)], out_specs=plgpu.GPUBlockSpec((64, 192), lambda: (0, 0)), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float32))(a, b)\n    np.testing.assert_allclose(res, a @ b, rtol=0.001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_wgmma_registers_init(self):\n\n    def kernel(a_ref, b_ref, i_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref[...], b_ref)\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    key1, key2, key3 = jax.random.split(jax.random.key(42), 3)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(128, 192), dtype=jnp.float16)\n    i = jax.random.uniform(key3, shape=(64, 192), dtype=jnp.float16) * 10\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((128, 192), lambda: (0, 0), transforms=transforms), plgpu.GPUBlockSpec((64, 192), lambda: (0, 0), transforms=transforms)], out_specs=plgpu.GPUBlockSpec((64, 192), lambda: (0, 0)), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float16))(a, b, i)\n    np.testing.assert_allclose(res, i + a @ b, rtol=0.002)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_wgmma_sliced_ref(self):\n\n    def kernel(a_ref, b_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref.at[0], b_ref.at[0])\n            return acc_ref[...]\n        o_ref[...] = pl.run_scoped(scope, plgpu.ACC((64, 192), jnp.float32))\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(2, 64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(2, 128, 192), dtype=jnp.float16)\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((2, 64, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))), plgpu.GPUBlockSpec((2, 128, 192), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))], out_specs=plgpu.GPUBlockSpec((64, 192), lambda: (0, 0)), out_shape=jax.ShapeDtypeStruct((64, 192), jnp.float32))(a, b)\n    np.testing.assert_allclose(res, a[0] @ b[0], rtol=0.001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_wgmma_sliced_acc(self):\n    swizzle = 128\n    elems_128b = swizzle // jnp.dtype(jnp.float16).itemsize\n\n    def kernel(a_ref, b_ref, o_ref):\n\n        def scope(acc_ref):\n            plgpu.wgmma(acc_ref, a_ref, b_ref)\n            return (acc_ref[:, :64], acc_ref[:, 64:])\n        o_ref[:, :64], o_ref[:, 64:] = pl.run_scoped(scope, plgpu.ACC((64, 128), jnp.float32))\n    key1, key2 = jax.random.split(jax.random.key(42), 2)\n    a = jax.random.uniform(key1, shape=(64, 128), dtype=jnp.float16)\n    b = jax.random.uniform(key2, shape=(128, 128), dtype=jnp.float16)\n    res = pl.pallas_call(kernel, in_specs=[plgpu.GPUBlockSpec((64, 128), lambda i, j: (i, j), transforms=(plgpu.TilingTransform((64, elems_128b)), plgpu.SwizzleTransform(128))), plgpu.GPUBlockSpec((128, 128), lambda *i: i, transforms=(plgpu.TilingTransform((elems_128b, elems_128b)), plgpu.SwizzleTransform(128)))], out_specs=plgpu.GPUBlockSpec((64, 128), lambda *i: i), out_shape=jax.ShapeDtypeStruct((64, 128), jnp.float32), grid=(1, 1))(a, b)\n    np.testing.assert_allclose(res, a @ b, rtol=0.001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_elementwise_add(self, m=256, n=256, num_compute_wgs=2):\n    blk_m = blk_n = 64\n    x = jax.random.uniform(jax.random.key(0), (m, n), dtype=jnp.float32)\n    y = jax.random.uniform(jax.random.key(1), (m, n), dtype=jnp.float32)\n    o = jnp.zeros((m, n), dtype=jnp.float32)\n\n    def tiled_add_kernel(x_smem, y_smem, o_smem):\n        o_smem[...] = x_smem[...] + y_smem[...]\n    pipeline = mgpu_pipeline.emit_pipeline_warp_specialized(tiled_add_kernel, grid=(m // blk_m, n // blk_n), max_concurrent_steps=2, num_compute_wgs=num_compute_wgs, memory_registers=40, wg_axis='wg', in_specs=[plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[]), plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[])], out_specs=[plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[])])\n    mesh = plgpu.GPUMesh(grid=(1,), num_threads=num_compute_wgs + 1, axis_names=('_', 'wg'))\n\n    def run(refs):\n\n        @pl.core_map(mesh, compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n        def _kernel_entry():\n            pipeline(*refs)\n\n    @jax.jit\n    def run_function(x, y, o):\n        _, _, out = pl.run_state(run)((x, y, o))\n        return out\n    out = run_function(x, y, o)\n    reference = x + y\n    np.testing.assert_allclose(out, reference, atol=0.0001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_carry_accumulate(self, m=256, n=256, num_compute_wgs=2):\n    blk_m = blk_n = 64\n    x = jax.random.uniform(jax.random.key(0), (m, n), dtype=jnp.float32)\n    acc_init = jnp.zeros((blk_m, blk_n), dtype=jnp.float32)\n\n    def _scoped(acc_smem, x_gmem, acc_gmem):\n\n        def _compute_thread():\n            o_acc = plgpu.layout_cast(jnp.full((blk_m, blk_n), 0, dtype=jnp.float32), plgpu.Layout.WG_STRIDED((blk_m, blk_n), vec_size=2))\n            carry_init = (o_acc,)\n            final_carry = (yield carry_init)\n            o_final, = final_carry\n            acc_smem[...] = o_final\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(acc_smem, acc_gmem)\n            plgpu.wait_smem_to_gmem(0)\n\n        def tiled_acc_kernel(x_smem, carry):\n            o_carry, = carry\n            new_carry = x_smem[...] + o_carry\n            return (new_carry,)\n        pipeline = mgpu_pipeline.emit_pipeline_warp_specialized(tiled_acc_kernel, grid=(m // blk_m, n // blk_n), max_concurrent_steps=2, num_compute_wgs=num_compute_wgs, memory_registers=40, wg_axis='wg', carry_coroutine=_compute_thread, in_specs=[plgpu.GPUBlockSpec(block_shape=(blk_m, blk_n), index_map=lambda i, j: (i, j), transforms=[])], out_specs=[])\n        pipeline(x_gmem)\n    mesh = plgpu.GPUMesh(grid=(1,), num_threads=num_compute_wgs + 1, axis_names=('_', 'wg'))\n\n    def run(refs):\n        x_ref, acc_ref = refs\n\n        @pl.core_map(mesh)\n        def _kernel_entry():\n            pl.run_scoped(functools.partial(_scoped, x_gmem=x_ref, acc_gmem=acc_ref), plgpu.SMEM((blk_m, blk_n), jnp.float32))\n\n    @jax.jit\n    def run_function(x, acc):\n        _, out_acc = pl.run_state(run)((x, acc))\n        return out_acc\n    out_acc = run_function(x, acc_init)\n    ref = jnp.sum(jnp.stack(np.split(x, m // blk_m, axis=0)), axis=0)\n    ref = jnp.sum(jnp.stack(np.split(ref, n // blk_n, axis=1)), axis=0)\n    np.testing.assert_allclose(out_acc, ref, atol=0.0001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def assert_allclose(self, out: jnp.ndarray, expected_out: jnp.ndarray, *, atol: float=1e-05, rtol: float=1e-05):\n    self.assertEqual(out.dtype, expected_out.dtype)\n    np.testing.assert_allclose(out.astype(jnp.float32), expected_out.astype(jnp.float32), atol=atol, rtol=rtol)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros_like(x)\n\n    def inner(refs):\n        x_ref, y_ref = refs\n\n        @pl.core_map(mesh)\n        def _():\n            num_cores = jax.lax.psum(1, 'x')\n            slc_size = 16 // num_cores\n\n            def alloc(x_vmem_ref, y_vmem_ref, sem):\n                core_index = jax.lax.axis_index('x')\n                slc = pl.ds(core_index * slc_size, slc_size)\n                pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n                y = x_vmem_ref[...] + jax.lax.axis_index('x')\n                y_vmem_ref[...] = y\n                pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n            pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)\n    _, y = pl.run_state(inner)((x, y))\n    return y"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(refs):\n    x_ref, y_ref = refs\n\n    @pl.core_map(mesh)\n    def _():\n        num_cores = jax.lax.psum(1, 'x')\n        slc_size = 16 // num_cores\n\n        def alloc(x_vmem_ref, y_vmem_ref, sem):\n            core_index = jax.lax.axis_index('x')\n            slc = pl.ds(core_index * slc_size, slc_size)\n            pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n            y = x_vmem_ref[...] + jax.lax.axis_index('x')\n            y_vmem_ref[...] = y\n            pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n        pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(refs):\n    x_ref, y_ref = refs\n\n    @pl.core_map(mesh)\n    def _():\n        num_cores = jax.lax.psum(1, 'x')\n        slc_size = 16 // num_cores\n\n        def alloc(x_vmem_ref, y_vmem_ref, sem):\n            core_index = jax.lax.axis_index('x')\n            slc = pl.ds(core_index * slc_size, slc_size)\n            pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n            y = x_vmem_ref[...] + jax.lax.axis_index('x')\n            y_vmem_ref[...] = y\n            pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n        pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(refs):\n    x_ref, y_ref = refs\n\n    @pl.core_map(mesh)\n    def _():\n        num_cores = jax.lax.psum(1, 'x')\n        slc_size = 16 // num_cores\n\n        def alloc(x_vmem_ref, y_vmem_ref, sem):\n            core_index = jax.lax.axis_index('x')\n            slc = pl.ds(core_index * slc_size, slc_size)\n            pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n            y = x_vmem_ref[...] + jax.lax.axis_index('x')\n            y_vmem_ref[...] = y\n            pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n        pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def inner(refs):\n    x_ref, y_ref = refs\n\n    @pl.core_map(mesh)\n    def _():\n        num_cores = jax.lax.psum(1, 'x')\n        slc_size = 16 // num_cores\n\n        def alloc(x_vmem_ref, y_vmem_ref, sem):\n            core_index = jax.lax.axis_index('x')\n            slc = pl.ds(core_index * slc_size, slc_size)\n            pltpu.async_copy(x_ref.at[slc], x_vmem_ref, sem).wait()\n            y = x_vmem_ref[...] + jax.lax.axis_index('x')\n            y_vmem_ref[...] = y\n            pltpu.async_copy(y_vmem_ref, y_ref.at[slc], sem).wait()\n        pl.run_scoped(alloc, pltpu.VMEM((slc_size, 128), x_ref.dtype), pltpu.VMEM((slc_size, 128), y_ref.dtype), pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x, out):\n    mask = x[...] != 0\n    concated_mask = jnp.concatenate([mask, mask], axis=0)\n    concated_x = jnp.concatenate([x[:], x[:]], axis=0)\n    out[:] = lax.select(concated_mask, concated_x, jnp.zeros_like(concated_x))"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x):\n    return jax.nn.relu(x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(src_dst_ids_ref, x_ref, o_ref, send_sem, recv_sem):\n    barrier_sem = pltpu.get_barrier_semaphore()\n\n    @functools.partial(jax.lax.fori_loop, 0, num_devices, init_val=None)\n    def _(i, _):\n        pltpu.semaphore_signal(barrier_sem, inc=1, device_id=(jnp.int32(i),), device_id_type=pltpu.DeviceIdType.MESH)\n        return None\n    pltpu.semaphore_wait(barrier_sem, num_devices)\n    my_id = lax.axis_index('x')\n    src_dst_ids = src_dst_ids_ref[:]\n    recv_count = 0\n    for i in range(src_dst_ids.shape[0]):\n        src_id = src_dst_ids[i, 0]\n        dst_id = src_dst_ids[i, 1]\n\n        @pl.when(src_id == my_id)\n        def _():\n            dma = pltpu.make_async_remote_copy(src_ref=x_ref, dst_ref=o_ref, send_sem=send_sem, recv_sem=recv_sem, device_id=(dst_id,), device_id_type=pltpu.DeviceIdType.MESH)\n            dma.start()\n            dma.wait_send()\n        recv_count += jnp.where(dst_id == my_id, 1, 0)\n\n    @pl.when(recv_count > 0)\n    def _():\n        fake_dma = pltpu.make_async_remote_copy(src_ref=x_ref.at[pl.ds(0, 8 * recv_count)], dst_ref=o_ref.at[pl.ds(0, 8 * recv_count)], send_sem=send_sem, recv_sem=recv_sem, device_id=(my_id,), device_id_type=pltpu.DeviceIdType.MESH)\n        fake_dma.wait_recv()"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = jnp.zeros(x.shape[1:], x.dtype)\n\n    def body(refs):\n        copy_start, copy_done = make_stateful_async_slice(2)\n        x_ref, y_ref = refs\n        fut = copy_start(x_ref, y_ref)\n        copy_done(x_ref, y_ref, fut)\n    _, y = state_discharge.run_state(body)((x, y))\n    return y"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, y_ref):\n\n    def body(ready_sem, send_sem, recv_sem):\n        my_id = lax.axis_index('x')\n        my_other_id = lax.axis_index('y')\n        axis_size = lax.psum(1, 'x')\n        if direction == 'right':\n            neighbor = lax.rem(my_id + 1, axis_size)\n        else:\n            neighbor = lax.rem(my_id - 1, axis_size)\n            neighbor = jnp.where(neighbor < 0, neighbor + axis_size, neighbor)\n        pltpu.semaphore_signal(ready_sem, device_id=(my_other_id, neighbor))\n        pltpu.semaphore_wait(ready_sem)\n        copy_done = pltpu.async_remote_copy(x_ref, y_ref, send_sem, recv_sem, device_id=(my_other_id, neighbor))\n        copy_done.wait_send()\n        copy_done.wait_recv()\n    pl.run_scoped(body, pltpu.SemaphoreType.REGULAR, pltpu.SemaphoreType.DMA, pltpu.SemaphoreType.DMA)"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.sin(x_ref[...])"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_hbm_ref, y_hbm_ref, o_hbm_ref):\n    grid = (pl.cdiv(m, bm), pl.cdiv(n, bn), pl.cdiv(k, bk))\n\n    def run(acc_scratch_ref):\n        pltpu.emit_pipeline(partial(basic_matmul_kernel, acc_scratch_ref=acc_scratch_ref, k=k), in_specs=[pl.BlockSpec((bm, bk), lambda i, j, k: (i, k)), pl.BlockSpec((bk, bn), lambda i, j, k: (k, j))], out_specs=pl.BlockSpec((bm, bn), lambda i, j, k: (i, j)), grid=grid, core_axis=0, dimension_semantics=(pltpu.PARALLEL, pltpu.PARALLEL, pltpu.ARBITRARY))(x_hbm_ref, y_hbm_ref, o_hbm_ref)\n    accum_dtype = jnp.float32 if jnp.issubdtype(x.dtype, jnp.floating) else jnp.int32\n    pl.run_scoped(run, pltpu.VMEM((bm, bn), accum_dtype))"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def f(x, *, eager=False):\n\n    def copy_one(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    grid = (2, 2)\n    block_shape = (x.shape[0] // grid[0], x.shape[1] // grid[1])\n    return pl.pallas_call(copy_one, out_shape=jax.ShapeDtypeStruct(x.shape, x.dtype), in_specs=[pl.BlockSpec(block_shape, lambda i, j: (i, j))], out_specs=pl.BlockSpec(block_shape, lambda i, j: (i, j)), grid=grid, interpret=eager and jtu.test_device_matches(['cpu']))(x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((2,), jnp.float32))\ndef kernel(x_ref, o_ref):\n    jax.debug.print('x = {}', x_ref)"
  },
  {
    "test_code": "@parameterized.named_parameters(('_g2s', False), ('_s2g', True))\ndef test_copy_with_transforms(self, to_smem):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        if to_smem:\n            plgpu.copy_gmem_to_smem(x_ref, o_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n        else:\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(x_ref, o_ref)\n            plgpu.wait_smem_to_gmem(0)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    if not to_smem:\n        in_spec, out_spec = (out_spec, in_spec)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "def test_scoped_copy_with_transforms(self):\n    ts = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))\n\n    def kernel(x_ref, o_ref, barrier_ref):\n\n        def body(tmp_ref):\n            plgpu.copy_gmem_to_smem(x_ref, tmp_ref, barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n            o_ref[...] = tmp_ref[...] * 2\n        pl.run_scoped(body, plgpu.SMEM((128, 128), jnp.float32, transforms=ts))\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=ts, memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), x * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "def test_copy_with_transforms_and_indexing(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, o_ref.at[i], barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 128, 128), lambda: (0, 0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.TransposeTransform((0, 2, 1, 3, 4)), plgpu.SwizzleTransform(128)), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 128, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(128 * 128, dtype=jnp.float32).reshape(128, 128)\n    np.testing.assert_array_equal(f(x), np.stack([x, x], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "def test_indexing_before_transpose(self):\n\n    def kernel(x_ref, o_ref, barrier_ref):\n        for i in range(2):\n            plgpu.copy_gmem_to_smem(x_ref, plgpu.transpose_ref(o_ref.at[i], (1, 0, 2)), barrier_ref)\n            plgpu.barrier_wait(barrier_ref)\n    in_spec = pl.BlockSpec(memory_space=plgpu.GMEM)\n    out_spec = plgpu.GPUBlockSpec((2, 64, 2, 128), lambda: (0, 0, 0, 0), memory_space=plgpu.SMEM)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct([2, 64, 2, 128], jnp.float32), in_specs=(in_spec,), out_specs=out_spec, scratch_shapes=[plgpu.Barrier(num_arrivals=1)])\n    x = jnp.arange(2 * 64 * 128, dtype=jnp.float32).reshape(2, 64, 128)\n    xt = x.transpose((1, 0, 2))\n    np.testing.assert_array_equal(f(x), np.stack([xt, xt], axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "def test_print_wgmma_tiled_layout(self):\n    shape = (128, 64)\n    size = math.prod(shape)\n\n    def kernel(x_ref, o_ref):\n        pl.debug_print('{}', x_ref[...])\n    spec = plgpu.GPUBlockSpec(shape, lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128)))\n    x = jnp.arange(size, dtype=jnp.float32).reshape(shape)\n    f = pl.pallas_call(kernel, out_shape=x, in_specs=[spec], out_specs=spec)\n    with self.capture_stdout() as get_output:\n        jax.block_until_ready(f(x))\n    output = get_output()\n    results = re.findall('\\\\[(\\\\d+), (\\\\d+)\\\\]/\\\\[128, 64\\\\]: (\\\\d+)', output)\n    self.assertLen(results, size)\n    for i, j, v in results:\n        i, j, v = map(int, (i, j, v))\n        self.assertEqual(v, i * shape[1] + j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "@parameterized.product(thread_semantics=[*plgpu.ThreadSemantics])\ndef test_run_scoped(self, thread_semantics):\n\n    def kernel(x_ref, o_ref):\n\n        def body(tmp_ref):\n            self.assertEqual(tmp_ref.shape, (8, 128))\n            tmp_ref[...] = x_ref[...] + 1.0\n            return tmp_ref[...]\n        tmp = pl.run_scoped(body, plgpu.SMEM((8, 128), jnp.float32))\n        self.assertEqual(tmp.shape, (8, 128))\n        o_ref[...] = tmp\n    inp = np.ones((8, 128), jnp.float32)\n    f = pl.pallas_call(kernel, out_shape=jax.ShapeDtypeStruct((8, 128), jnp.float32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    o = f(inp)\n    np.testing.assert_array_equal(o, inp + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "def test_slicing(self):\n    left = upper = slice(None, 64)\n    right = lower = slice(64, None)\n\n    def rotate(src, dst):\n        dst[upper, left] = src[lower, left]\n        dst[upper, right] = src[upper, left]\n        dst[lower, right] = src[upper, right]\n        dst[lower, left] = src[lower, right]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    spec = plgpu.GPUBlockSpec((128, 128), lambda: (0, 0), transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n    f = pl.pallas_call(rotate, out_shape=x, in_specs=[spec], out_specs=spec)\n    expected = np.empty_like(x)\n    rotate(x, expected)\n    np.testing.assert_array_equal(f(x), expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "def test_multiple_wg(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('y',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                wg_idx = jax.lax.axis_index('y')\n                y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat(np.arange(2), 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "def test_multiple_wg_with_grid(self):\n    mesh = plgpu.GPUMesh(grid=(2, 2), num_threads=2, axis_names=('x', 'y', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n                xy_idx = jax.lax.axis_index(('x', 'y'))\n                yx_idx = jax.lax.axis_index(('y', 'x'))\n                wg_idx = jax.lax.axis_index('wg')\n                num_wgs = jax.lax.psum(1, 'wg')\n                y_ref[xy_idx, wg_idx] = jnp.broadcast_to(yx_idx * num_wgs + wg_idx, (128,))\n        y_init = jnp.zeros((4, 2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1, 4, 5, 2, 3, 6, 7], 128).reshape(4, 2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "def test_multiple_wg_with_squashed_grid(self):\n    b = 4\n    x_dim = 3\n    y_dim = 5\n    z_dim = 7\n    num_threads = 2\n    mesh = plgpu.GPUMesh(grid=(b, x_dim, y_dim, z_dim), num_threads=num_threads, axis_names=('b', 'x', 'y', 'z', 'wg'))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def _():\n                b_idx = jax.lax.axis_index('b')\n                x_idx = jax.lax.axis_index('x')\n                y_idx = jax.lax.axis_index('y')\n                z_idx = jax.lax.axis_index('z')\n                wg_idx = jax.lax.axis_index('wg')\n                bxyzw_idx = jax.lax.axis_index(('b', 'x', 'y', 'z', 'wg'))\n                y_ref[b_idx, x_idx, y_idx, z_idx, wg_idx] = jnp.broadcast_to(bxyzw_idx, (128,))\n        y_init = jnp.zeros((b, x_dim, y_dim, z_dim, num_threads, 128), np.int32)\n        return inner(y_init)\n    result = f()[:, :, :, :, :, 0]\n    ref = np.arange(b * x_dim * y_dim * z_dim * num_threads).reshape(result.shape)\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "def test_cross_wg_barrier(self):\n    mesh = plgpu.GPUMesh(num_threads=2, axis_names=('wg',))\n\n    @jax.jit\n    def f():\n\n        @pl.run_state\n        def inner(y_ref):\n\n            @pl.core_map(mesh)\n            def kernel():\n\n                def scoped(barrier):\n                    plgpu.barrier_arrive(barrier)\n                    plgpu.barrier_wait(barrier)\n                    wg_idx = jax.lax.axis_index('wg')\n                    y_ref[wg_idx] = jnp.broadcast_to(wg_idx, (128,))\n                pl.run_scoped(scoped, plgpu.Barrier(num_arrivals=2))\n        y_init = jnp.zeros((2, 128), np.int32)\n        return inner(y_init)\n    np.testing.assert_array_equal(f(), np.repeat([0, 1], 128).reshape(2, 128))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct(out_shape, jnp.float32))\ndef f(x_ref, o_ref):\n    x = x_ref[...]\n    o_ref[...] = jax.lax.broadcast_in_dim(x, out_shape, dims)"
  },
  {
    "test_code": "@parameterized.product(dtypes=[(jnp.float16, jnp.float16), (jnp.int16, jnp.bfloat16), (jnp.int16, jnp.float16), (jnp.uint16, jnp.float16), (jnp.float32, jnp.int32), (jnp.float32, jnp.uint32), (jnp.uint32, jnp.int32), (jnp.int32, jnp.uint32)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_bitcast_convert_type(self, dtypes, thread_semantics):\n    in_dtype, out_dtype = dtypes\n    m, n = (16, 8)\n    out_shape = jax.ShapeDtypeStruct((m, n), out_dtype)\n\n    @functools.partial(pl.pallas_call, out_shape=out_shape, compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def convert(x_ref, y_ref):\n        y_ref[...] = jax.lax.bitcast_convert_type(x_ref[...], out_shape)\n    x = jnp.arange(m * n, dtype=in_dtype).reshape((m, n))\n    np.testing.assert_array_equal(convert(x), jax.lax.bitcast_convert_type(x, out_dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@functools.partial(self.pallas_call, out_shape=out_shape, grid=grid)\ndef convert(x_ref, y_ref):\n    y_ref[...] = jax.lax.bitcast_convert_type(x_ref[...], out_dtype)"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "@jax.vmap\n@functools.partial(self.pallas_call, out_shape=jax.ShapeDtypeStruct((64, 128), x.dtype), grid=(2,), in_specs=[pl.BlockSpec((8, 128), lambda i: (i, 0))], out_specs=pl.BlockSpec((32, 128), lambda i: (i, 0)))\ndef kernel(src, dst):\n    dst[0:1] = to_store"
  },
  {
    "test_code": "@parameterized.named_parameters(('add_one', lambda x: x + 1.0), ('logistic', jax.lax.logistic), ('exp', jax.lax.exp), ('square', lambda x: x ** 2), ('rsqrt', jax.lax.rsqrt), ('tanh', jax.lax.tanh, 1e-06), ('log', jax.lax.log))\ndef test_unary_op(self, unary, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary(x_ref[...])\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_allclose(kernel(x), unary(x), rtol=rtol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.product(op=[operator.add, lambda x, _: x + 1, operator.sub, operator.mul, lax.div, jnp.minimum, jnp.maximum], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_binary_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = op(x_ref[...], y_ref[...])\n    key0, key1 = jax.random.split(jax.random.key(0), 2)\n    x = (jax.random.uniform(key0, [256]) * 42).astype(dtype)\n    y = (jax.random.uniform(key1, [256]) * 42).astype(dtype)\n    np.testing.assert_array_equal(kernel(x, y), op(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.product(op=[lax.eq, operator.ne, operator.lt, operator.le, operator.gt, operator.ge], dtype=[jnp.float32, jnp.int32, jnp.uint32], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_comparison_op(self, op, dtype, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], dtype), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(op(dtype(42), dtype(24)).astype(dtype), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], op(42, 24), dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_add_first(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        o_ref[...] = x_ref[...] + y_ref[0]\n    x = jnp.arange(256).astype(jnp.float32)\n    y = jnp.flip(x).reshape(1, 256)\n    np.testing.assert_array_equal(kernel(x, y), x + y[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_reshape(self):\n    shape1, shape2 = ((128,), (2, 16, 4))\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape2, jnp.float32))\n    def kernel(x_ref, out_ref):\n        x_ref_reshaped = x_ref.reshape(shape2)\n        self.assertEqual(x_ref.shape, shape1)\n        self.assertEqual(x_ref_reshaped.shape, shape2)\n        out_ref[...] = x_ref_reshaped[...]\n    x = jnp.arange(math.prod(shape1)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x.reshape(shape2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_add_one_grid(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_add_one_grid_with_scratch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.float32), in_specs=[pl.BlockSpec((128,), lambda *i: i)], out_specs=pl.BlockSpec((128,), lambda *i: i), scratch_shapes=[plgpu.SMEM((128,), jnp.float32)], grid=2)\n    def kernel(x_ref, o_ref, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        o_ref[...] = scratch_ref[...]\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.product(max_concurrent_steps=[1, 2, 3, 4, 16])\ndef test_add_one_grid_pipelined(self, max_concurrent_steps):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((128, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((128, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([128 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=max_concurrent_steps), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(128 * 2 * 64).reshape((128 * 2, 64)).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_program_id(self):\n\n    @functools.partial(pl.pallas_call, out_specs=pl.BlockSpec((16, 16), lambda i, j: (i, j)), out_shape=jax.ShapeDtypeStruct([16, 64], jnp.int32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(4, 4))\n    def kernel(o_ref):\n        o_ref[...] = jnp.broadcast_to(pl.program_id(1), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.repeat(jnp.repeat(jnp.arange(4), 16)[None], 16, axis=0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_add_one_grid_pipelined_sequential_invariant_output(self):\n\n    @functools.partial(pl.pallas_call, in_specs=[pl.BlockSpec((32, 16), lambda i, j: (i, j))], out_specs=pl.BlockSpec((32, 16), lambda i, j: (i, 0)), out_shape=jax.ShapeDtypeStruct([32 * 2, 64], jnp.float32), compiler_params=plgpu.GPUCompilerParams(dimension_semantics=['parallel', 'sequential'], max_concurrent_steps=2), grid=(2, 4))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + 1.0\n    x = jnp.arange(32 * 2 * 64).reshape((32 * 2, 64)).astype(jnp.float32)\n    y = jnp.empty_like(x)\n    for i in range(2):\n        i_slice = slice(32 * i, 32 * (i + 1))\n        for j in range(4):\n            j_slice = slice(16 * j, 16 * (j + 1))\n            y = y.at[i_slice, :16].set(x[i_slice, j_slice] + 1)\n    np.testing.assert_array_equal(kernel(x)[:, :16], y[:, :16])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.parameters(jnp.float32, jnp.int32, jnp.uint32)\ndef test_iota(self, dtype):\n    dimension = 1\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128, 128), dtype))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.broadcasted_iota(dtype, (128, 128), dimension, layout=plgpu.Layout.WGMMA)\n    np.testing.assert_array_equal(kernel(), jax.lax.broadcasted_iota(dtype, (128, 128), dimension))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_copy_smem_to_gmem(self, indexer, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM((256,), jnp.float32)], compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        plgpu.copy_smem_to_gmem(scratch_ref.at[indexer], o_ref_gmem.at[indexer])\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract', 'shape': (64, 64), 'indexers': (4, slice(0, 64))})\ndef test_copy_smem_to_gmem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), out_specs=pl.BlockSpec(memory_space=plgpu.GMEM), scratch_shapes=[plgpu.SMEM(shape, jnp.float32)])\n    def kernel(x_ref, o_ref_gmem, scratch_ref):\n        scratch_ref[...] = x_ref[...] + 1\n        plgpu.commit_smem()\n        for indexer in indexers:\n            scratch_ref = scratch_ref.at[indexer]\n            o_ref_gmem = o_ref_gmem.at[indexer]\n        plgpu.copy_smem_to_gmem(scratch_ref, o_ref_gmem)\n        plgpu.wait_smem_to_gmem(0)\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.product(indexer=[..., slice(128), slice(None, 128)])\ndef test_copy_gmem_to_smem(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((256,), jnp.float32), plgpu.Barrier(num_arrivals=1)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem.at[indexer], scratch_ref.at[indexer], barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x)[indexer], x[indexer] + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.named_parameters({'testcase_name': '1d_none', 'shape': (256,), 'indexers': (slice(0, 128), slice(None, 32))}, {'testcase_name': '1d_offset', 'shape': (256,), 'indexers': (slice(32, 96), slice(0, 32))}, {'testcase_name': '2d_extract_static', 'shape': (64, 64), 'indexers': (4, slice(0, 64))}, {'testcase_name': '2d_extract_dyn', 'shape': (64, 64), 'indexers': lambda in_dev: (pl.program_id(0) + 4 if in_dev else jnp.array(4), slice(0, 64))})\ndef test_copy_gmem_to_smem_with_multiple_gmem_indexers(self, shape, indexers):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM(shape, jnp.float32), plgpu.Barrier(num_arrivals=1)], grid=(1,))\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        scratch_ref_sliced = scratch_ref\n        for indexer in indexers(True) if callable(indexers) else indexers:\n            scratch_ref_sliced = scratch_ref_sliced.at[indexer]\n            x_ref_gmem = x_ref_gmem.at[indexer]\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref_sliced, barrier_ref)\n        plgpu.barrier_wait(barrier_ref)\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(np.prod(shape)).astype(jnp.float32).reshape(*shape)\n    result = kernel(x)\n    ref = x + 1.0\n    for indexer in indexers(False) if callable(indexers) else indexers:\n        result = result[indexer]\n        ref = ref[indexer]\n    np.testing.assert_array_equal(result, ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_gmem_to_smem_with_multiple_smem_indexers_and_transforms(self):\n    x = jnp.arange(512 * 512, dtype=jnp.int32).reshape(512, 512)\n\n    @functools.partial(pl.pallas_call, grid=(4, 4), out_shape=jax.ShapeDtypeStruct((256, 128), jnp.int32), in_specs=(plgpu.GPUBlockSpec(block_shape=(128, 128), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM, transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(128))),), out_specs=plgpu.GPUBlockSpec(block_shape=(64, 32), index_map=lambda i, j: (i, j), memory_space=plgpu.SMEM))\n    def kernel(x_ref, o_ref):\n        x_sliced = x_ref.at[0:64, 32:96].at[:, 0:32]\n        o_ref[...] = x_sliced[...]\n    ref = jnp.concatenate([x[blk:blk + 64, :] for blk in range(0, 512, 128)])\n    ref = jnp.concatenate([ref[:, blk + 32:blk + 64] for blk in range(0, 512, 128)], axis=1)\n    np.testing.assert_array_equal(kernel(x), ref)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.product(indexer=[0, 1, 2, 3])\ndef test_copy_gmem_to_smem_with_indexed_barrier(self, indexer):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),), scratch_shapes=[plgpu.SMEM((128,), jnp.float32), plgpu.Barrier(num_arrivals=1, num_barriers=4)])\n    def kernel(x_ref_gmem, o_ref, scratch_ref, barrier_ref):\n        plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref.at[indexer])\n        plgpu.barrier_wait(barrier_ref.at[indexer])\n        o_ref[...] = scratch_ref[...] + 1\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_copy_gmem_to_smem_in_run_scoped(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32), in_specs=(pl.BlockSpec(memory_space=plgpu.GMEM),))\n    def kernel(x_ref_gmem, o_ref):\n\n        def body(barrier_ref):\n\n            def inner_body(scratch_ref):\n                plgpu.copy_gmem_to_smem(x_ref_gmem, scratch_ref, barrier_ref)\n                plgpu.barrier_wait(barrier_ref)\n                o_ref[...] = scratch_ref[...] + 1\n            pl.run_scoped(inner_body, plgpu.SMEM((256,), jnp.float32))\n        pl.run_scoped(body, plgpu.Barrier(num_arrivals=1))\n    x = jnp.arange(256).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + 1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_add_doubled_sum(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...] + jnp.sum(x_ref[...]) + jnp.sum(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32)\n    np.testing.assert_array_equal(kernel(x), x + x.sum() * 2)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.named_parameters(('rsqrt', jax.lax.rsqrt), ('log', jax.lax.log, 5e-07), ('exp', jax.lax.exp), ('exp2', jax.lax.exp2, 5e-07), ('logistic', jax.lax.logistic), ('tanh', jax.lax.tanh, 5e-07))\ndef test_approx_math_unary_op(self, unary_op, rtol=1e-07):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32), compiler_params=plgpu.GPUCompilerParams(approx_math=True))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = unary_op(x_ref[...])\n    x = jnp.arange(128).astype(jnp.float32) / 128\n    np.testing.assert_allclose(kernel(x), unary_op(x), rtol=rtol, atol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_print(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.float32))\n    def kernel(x_ref, o_ref):\n        del x_ref, o_ref\n        pl.debug_print('It works!')\n    x = jnp.arange(256).astype(jnp.float32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertEqual(output(), 'It works!\\n')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_print_array(self):\n    in_shape = [2, 1, 64, 64]\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(in_shape, jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x: {}', x_ref[...])\n    x = jnp.arange(math.prod(in_shape), dtype=jnp.int32).reshape(in_shape)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x: [1, 0, 43, 23]/{in_shape}: 6871\\n', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_load_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct((128,), jnp.int32), in_specs=[plgpu.GPUBlockSpec(memory_space=plgpu.GPUMemorySpace.GMEM)])\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.broadcast_to(x_ref[10], (128,))\n    np.testing.assert_array_equal(kernel(jnp.arange(11, dtype=jnp.int32)), jnp.full((128,), 10, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_program_id(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.program_id(0))\n    np.testing.assert_array_equal(kernel(), jnp.array([0] * 128 + [1] * 128, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_program_id_in_squashed_grid(self):\n    grid = (2, 3, 4, 5)\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((1,) * len(grid) + (128,), lambda *i: (*i, 0)), out_shape=jax.ShapeDtypeStruct([*grid, 128], jnp.int32), grid=grid)\n    def kernel(o_ref):\n        mult = 1\n        idx = 0\n        for axis in range(len(grid) - 1, -1, -1):\n            idx += pl.program_id(axis) * mult\n            mult *= pl.num_programs(axis)\n        o_ref[...] = jnp.full(o_ref.shape, idx)\n    np.testing.assert_array_equal(kernel()[:, :, :, :, 0], jnp.arange(math.prod(grid), dtype=jnp.int32).reshape(*grid))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_program_id_in_block_spec(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)),), out_specs=pl.BlockSpec((2, 128), lambda i: (pl.program_id(0), i)), out_shape=jax.ShapeDtypeStruct([2, 128], jnp.int32), grid=2)\n    def kernel(x_ref, o_ref):\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(2 * 128, dtype=jnp.int32).reshape([2, 128])\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_num_programs(self):\n\n    @functools.partial(pl.pallas_call, in_specs=(), out_specs=pl.BlockSpec((128,), lambda *i: i), out_shape=jax.ShapeDtypeStruct([128 * 2], jnp.int32), grid=2)\n    def kernel(o_ref):\n        o_ref[...] = jnp.full(o_ref.shape, pl.num_programs(0), o_ref.dtype)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 2, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_swizzled_blockspec_shapes(self):\n    spec = plgpu.GPUBlockSpec((128, 64), lambda *i: i, transforms=(plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128)))\n\n    @functools.partial(pl.pallas_call, in_specs=[spec], out_specs=spec, out_shape=jax.ShapeDtypeStruct((128, 128), jnp.float16), grid=(2, 2))\n    def kernel(x_ref, o_ref):\n        assert x_ref.shape == (128, 64), x_ref.shape\n        o_ref[...] = x_ref[...]\n    x = jnp.arange(128 * 128).astype(jnp.float16).reshape(128, 128)\n    np.testing.assert_array_equal(kernel(x), x)",
    "assertions": [
      "assert x_ref.shape == (128, 64), x_ref.shape"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_fori_loop_dynamic_bounds(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), grid=(1,))\n    def kernel(o_ref):\n        zero = pl.program_id(0)\n        o_ref[...] = jax.lax.broadcast(jax.lax.fori_loop(2 + zero, 4 + zero, lambda i, x: x + i, 0), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, dtype=jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.parameters([*plgpu.ThreadSemantics])\ndef test_cond(self, thread_semantics):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        jax.lax.cond(x_ref[0] % 2 == 0, lambda: pl.debug_print('acc % 2'), lambda: pl.debug_print('acc'))\n        o_ref[...] = jnp.broadcast_to(jnp.asarray(0, dtype=o_ref.dtype), o_ref.shape)\n    x = jnp.full((256,), 1234, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn('acc % 2', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_layout_cast(self, shape=(256, 64)):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct(shape, jnp.float32))\n    def kernel(o_ref):\n        o_ref[...] = plgpu.layout_cast(jnp.full(shape, 42.0, jnp.float32), plgpu.Layout.WGMMA)\n    x = jnp.full(shape, 42.0, jnp.float32)\n    np.testing.assert_array_equal(kernel(), x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_stage0(self):\n\n    def body(l_ref, r_ref, o_ref):\n        o_ref[...] = l_ref[...] + r_ref[...]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x)(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_stage1(self):\n    row_block = 64\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n        o_ref[my_slice] = l_ref[my_slice] + r_ref[my_slice]\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_stage3(self):\n    row_block, col_block = (64, 128)\n\n    def body(l_ref, r_ref, o_ref):\n        my_slice = pl.ds(lax.axis_index('rows') * row_block, row_block)\n\n        def scoped(l_smem, r_smem, o_smem, barrier):\n            plgpu.copy_gmem_to_smem(l_ref.at[my_slice], l_smem, barrier)\n            plgpu.copy_gmem_to_smem(r_ref.at[my_slice], r_smem, barrier)\n            plgpu.barrier_wait(barrier)\n            o_smem[...] = l_smem[...] + r_smem[...]\n            plgpu.commit_smem()\n            plgpu.copy_smem_to_gmem(o_smem, o_ref.at[my_slice])\n            plgpu.wait_smem_to_gmem(0)\n        pl.run_scoped(scoped, *[plgpu.SMEM((row_block, col_block), jnp.float16)] * 3, plgpu.Barrier(num_arrivals=2))\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_stage4(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = pl.BlockSpec((row_block, col_block), lambda c: (r, c))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_stage5(self):\n    row_block, col_block = (64, 32)\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n            o_smem[...] = l_smem[...] + r_smem[...]\n        r = lax.axis_index('rows')\n        block = plgpu.GPUBlockSpec((row_block, col_block), lambda c: (r, c), transforms=(plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64)))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // col_block,), in_specs=[block] * 2, out_specs=[block])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2,), axis_names=('rows',))(x, x)\n    np.testing.assert_allclose(out, x + x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "def test_stage6(self):\n    m_block = n_block = 64\n    k_block = 32\n\n    def body(l_ref, r_ref, o_ref):\n\n        def compute(l_smem, r_smem, o_smem):\n\n            def do_wgmma(acc_ref):\n                plgpu.wgmma(acc_ref, l_smem, r_smem)\n                return acc_ref[...]\n            o_smem[...] += pl.run_scoped(do_wgmma, plgpu.ACC((m_block, n_block), jnp.float16))\n        m, n = (lax.axis_index('m'), lax.axis_index('n'))\n        lo_transforms = (plgpu.TilingTransform((64, 32)), plgpu.SwizzleTransform(64))\n        r_transforms = (plgpu.TilingTransform((32, 32)), plgpu.SwizzleTransform(64))\n        plgpu.emit_pipeline(compute, grid=(l_ref.shape[1] // k_block,), in_specs=[plgpu.GPUBlockSpec((m_block, k_block), lambda k: (m, k), transforms=lo_transforms), plgpu.GPUBlockSpec((k_block, n_block), lambda k: (k, n), transforms=r_transforms)], out_specs=[plgpu.GPUBlockSpec((m_block, n_block), lambda k: (m, n), transforms=lo_transforms)])(l_ref, r_ref, o_ref)\n    x = jnp.arange(128 * 128, dtype=jnp.float16).reshape(128, 128)\n    out = plgpu.kernel(body, out_shape=x, grid=(2, 2), axis_names=('m', 'n'))(x, x)\n    np.testing.assert_allclose(out, x @ x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def kernel(x_ref, o_ref):\n    o_ref[...] = jnp.zeros_like(o_ref)\n    new_o_ref = o_ref.at[pl.ds(0, 8)].at[0].at[pl.ds(0, 4), pl.ds(0, 4)]\n    new_o_ref[...] = x_ref[...]"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_array(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = _fori_loop(force_while, 2, 4, lambda i, x: x + i, x_ref[...])\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), x + 2 + 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _fori_loop(force_while: bool, lb, ub, body, init):\n    if force_while:\n        lb, ub = (jnp.asarray(lb), jnp.asarray(ub))\n    return jax.lax.fori_loop(lb, ub, body, init)"
  },
  {
    "test_code": "@parameterized.product(force_while=[False, True], thread_semantics=[*plgpu.ThreadSemantics])\ndef test_fori_loop_scalar(self, force_while, thread_semantics):\n    if force_while and thread_semantics == plgpu.ThreadSemantics.Warpgroup:\n        self.skipTest('WG semantics does not support force_while.')\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32), compiler_params=plgpu.GPUCompilerParams(thread_semantics=thread_semantics))\n    def kernel(o_ref):\n        o_ref[...] = jax.lax.broadcast(_fori_loop(force_while, 2, 4, lambda i, x: x + i, jnp.int32(0)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 5, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _fori_loop(force_while: bool, lb, ub, body, init):\n    if force_while:\n        lb, ub = (jnp.asarray(lb), jnp.asarray(ub))\n    return jax.lax.fori_loop(lb, ub, body, init)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_tuple(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(o_ref):\n\n        def body(step, xs):\n            return tuple((jax.lax.cond(step % 2 == 0, lambda x: x + 1, lambda x: x, x) for x in xs))\n        o_ref[...] = jax.lax.broadcast(sum(_fori_loop(force_while, 2, 4, body, (jnp.int32(0),) * 3)), o_ref.shape)\n    np.testing.assert_array_equal(kernel(), jnp.full([256], 3 * (0 + 1), jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _fori_loop(force_while: bool, lb, ub, body, init):\n    if force_while:\n        lb, ub = (jnp.asarray(lb), jnp.asarray(ub))\n    return jax.lax.fori_loop(lb, ub, body, init)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_indexed_store(self, force_while):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([4, 128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n\n        def body(idx, _):\n            o_ref[idx] = x_ref[idx] + y_ref[idx]\n            return ()\n        _fori_loop(force_while, 0, 4, body, ())\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = x + 1\n    np.testing.assert_array_equal(kernel(x, y), x + y)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _fori_loop(force_while: bool, lb, ub, body, init):\n    if force_while:\n        lb, ub = (jnp.asarray(lb), jnp.asarray(ub))\n    return jax.lax.fori_loop(lb, ub, body, init)"
  },
  {
    "test_code": "@parameterized.parameters(False, True)\ndef test_fori_loop_accumulator(self, force_while):\n    transforms = (plgpu.TilingTransform((64, 64)), plgpu.SwizzleTransform(128))\n\n    @functools.partial(pl.pallas_call, in_specs=[plgpu.GPUBlockSpec((64, 64), lambda: (0, 0), transforms=transforms)], out_shape=jax.ShapeDtypeStruct((64, 64), jnp.float16), out_specs=plgpu.GPUBlockSpec((64, 64), lambda: (0, 0)))\n    def kernel(i_ref, o_ref):\n\n        def scope(acc_ref):\n            return _fori_loop(force_while, 0, 4, lambda _, v: v + acc_ref[...], acc_ref[...])\n        o_ref[...] = pl.run_state(scope)(plgpu.ACC.init(i_ref[...]))\n    acc_ini = jnp.ones((64, 64), dtype=jnp.float16)\n    np.testing.assert_array_equal(kernel(acc_ini), jnp.full((64, 64), 5, dtype=jnp.float16))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _fori_loop(force_while: bool, lb, ub, body, init):\n    if force_while:\n        lb, ub = (jnp.asarray(lb), jnp.asarray(ub))\n    return jax.lax.fori_loop(lb, ub, body, init)"
  },
  {
    "test_code": "def test_add_xy_indexed(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.float32))\n    def kernel(x_ref, y_ref, o_ref):\n        idx = _sum_same_dtype(y_ref[...])\n        o_ref[...] = x_ref[idx]\n    x = jnp.arange(4 * 128).reshape(4, 128).astype(jnp.float32)\n    y = jnp.zeros(128, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x, y), x[jnp.sum(y)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _sum_same_dtype(x):\n    return jnp.sum(x, dtype=x.dtype)"
  },
  {
    "test_code": "def test_print_scalar(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]))\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum()}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _sum_same_dtype(x):\n    return jnp.sum(x, dtype=x.dtype)"
  },
  {
    "test_code": "def test_print_scalar_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        del o_ref\n        pl.debug_print('x.sum() = {}', _sum_same_dtype(x_ref[...]) + 1)\n    x = jnp.arange(256, dtype=jnp.int32)\n    with self.capture_stdout() as output:\n        jax.block_until_ready(kernel(x))\n    self.assertIn(f'x.sum() = {x.sum() + 1}', output())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _sum_same_dtype(x):\n    return jnp.sum(x, dtype=x.dtype)"
  },
  {
    "test_code": "def test_while_loop(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(x_ref, o_ref):\n        o_ref[...] = jnp.zeros(o_ref.shape, dtype=jnp.int32)\n\n        def cond(acc):\n            _, last_o = acc\n            return _sum_same_dtype(last_o) < 128 * 10\n\n        def body(acc):\n            i, _ = acc\n            o_ref[...] += x_ref[i]\n            return (i + 1, o_ref[...])\n        _ = jax.lax.while_loop(cond, body, (0, o_ref[...]))\n    np.testing.assert_array_equal(kernel(jnp.ones([128, 128], jnp.int32)), jnp.full([128], 10, jnp.int32))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _sum_same_dtype(x):\n    return jnp.sum(x, dtype=x.dtype)"
  },
  {
    "test_code": "def test_while_loop_layout_mismatch(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([128], jnp.int32))\n    def kernel(o_ref):\n\n        def cond(acc):\n            return _sum_same_dtype(acc) < 128\n\n        def body(acc):\n            del acc\n            return plgpu.layout_cast(jnp.zeros(o_ref.shape, o_ref.dtype), plgpu.Layout.WGMMA_ROW)\n        _ = jax.lax.while_loop(cond, body, o_ref[...])\n    with self.assertRaisesRegex(ValueError, 'has layout .*, when it should be'):\n        kernel()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _sum_same_dtype(x):\n    return jnp.sum(x, dtype=x.dtype)"
  },
  {
    "test_code": "def test_cond_returning_array(self):\n\n    @functools.partial(pl.pallas_call, out_shape=jax.ShapeDtypeStruct([256], jnp.int32))\n    def kernel(x_ref, o_ref):\n        acc = _sum_same_dtype(x_ref[...])\n        acc2, acc = jax.lax.cond(acc % 2 == 0, lambda: (acc * 2, acc), lambda: (acc, acc * 2))\n        o_ref[...] = jnp.broadcast_to(acc + acc2, o_ref.shape)\n    x = jnp.arange(256, dtype=jnp.int32)\n    np.testing.assert_array_equal(kernel(x), jnp.broadcast_to(jnp.sum(x) * 3, [256]))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/pallas/mosaic_gpu_test.py",
    "function": "def _sum_same_dtype(x):\n    return jnp.sum(x, dtype=x.dtype)"
  }
]