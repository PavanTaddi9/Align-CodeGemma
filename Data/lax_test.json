[
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def testPadErrors(self):\n    with self.assertRaisesRegex(ValueError, 'padding_value must be a scalar'):\n        lax.pad(np.zeros(2), np.zeros(2), [(0, 0, 0)])\n    with self.assertRaisesRegex(ValueError, 'padding_config'):\n        lax.pad(np.zeros(2), 0.0, [(0, 1, 0), (0, 1, 0)])\n    with self.assertRaisesRegex(ValueError, 'interior padding in padding_config must be nonnegative'):\n        lax.pad(np.zeros(2), 0.0, [(0, 1, -1)])\n    with self.assertRaisesRegex(ValueError, 'Dimension size after padding is not at least 0'):\n        lax.pad(np.zeros(2), 0.0, [(-3, 0, 0)])\n    with self.assertRaisesRegex(ValueError, 'Dimension size after padding is not at least 0'):\n        lax.pad(np.zeros(2), 0.0, [(-4, 0, 1)])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testCollapse(self):\n\n    @jax.jit\n    def collapse_first_two(x):\n        return lax.collapse(x, 0, 2)\n    self.assertEqual((6,), collapse_first_two(np.zeros((2, 3))).shape)\n    self.assertEqual((6, 4), collapse_first_two(np.zeros((2, 3, 4))).shape)\n    self.assertEqual((2, 3, 4), collapse_first_two(np.zeros((1, 2, 3, 4))).shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testCollapseLastTwo(self):\n\n    @jax.jit\n    def collapse_last_two_none_end(x):\n        return lax.collapse(x, -2)\n\n    @jax.jit\n    def collapse_last_two_pos_end(x):\n        return lax.collapse(x, -2)\n    self.assertEqual((4, 3, 10), collapse_last_two_none_end(np.zeros((4, 3, 2, 5))).shape)\n    self.assertEqual((4, 3, 10), collapse_last_two_pos_end(np.zeros((4, 3, 2, 5))).shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{testcase_name}', 'operand_shape': operand_shape, 'indices_shape': indices_shape, 'update_shape': update_shape, 'dimension_numbers': dimension_numbers, 'msg': msg} for testcase_name, operand_shape, indices_shape, update_shape, dimension_numbers, msg in [('ScatterWithUpdatesBiggerThanInput', (64, 48), (32, 1), (65, 32), lax.ScatterDimensionNumbers(update_window_dims=(0,), inserted_window_dims=(1,), scatter_dims_to_operand_dims=(1,)), 'Bounds of the window dimensions'), ('ScatterWithUpdatesBiggerThanInputV2', (64, 48), (32, 1), (32, 49), lax.ScatterDimensionNumbers(update_window_dims=(1,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(1,)), 'Bounds of the window dimensions'), ('ScatterWithUpdatesNotMatchingIndices', (64, 48), (32, 1), (64, 31), lax.ScatterDimensionNumbers(update_window_dims=(1,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(1,)), 'Bounds of the scatter dimensions'), ('ScatterWithUpdatesNotMatchingIndicesV2', (64, 48), (32, 1), (31, 48), lax.ScatterDimensionNumbers(update_window_dims=(1,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(1,)), 'Bounds of the scatter dimensions'), ('ScatterNdWithUpdatesBiggerThanInput', (64, 48), (10, 9, 8, 7, 1), (10, 9, 8, 7, 65), lax.ScatterDimensionNumbers(update_window_dims=(4,), inserted_window_dims=(1,), scatter_dims_to_operand_dims=(1,)), 'Bounds of the window dimensions'), ('ScatterNdWithUpdatesNotMatchingIndices', (64, 48), (10, 9, 8, 7, 1), (9, 9, 8, 7, 64), lax.ScatterDimensionNumbers(update_window_dims=(4,), inserted_window_dims=(1,), scatter_dims_to_operand_dims=(0,)), 'Bounds of the scatter dimensions'), ('InvalidUpdates', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4, 1), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(1, 2), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4)), 'Updates tensor must be of rank 7; got 8.'), ('NonAscendingUpdateWindowDims', (6, 5, 4, 3, 2), (5, 4, 3, 2, 1), (10, 9, 8, 7, 6, 5, 4, 3, 2), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6, 8, 7), inserted_window_dims=(), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4)), 'update_window_dims in scatter op must be sorted'), ('RepeatedUpdateWindowDims', (6, 5, 4, 3, 2), (5, 4, 3, 2, 1), (10, 9, 8, 7, 6, 5, 4, 3, 2), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6, 7, 7), inserted_window_dims=(), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4)), 'update_window_dims in scatter op must not repeat'), ('OutOfBoundsUpdateWindowDims', (6, 5, 4, 3, 2), (5, 4, 3, 2, 1), (10, 9, 8, 7, 6, 5, 4, 3, 2), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6, 7, 9), inserted_window_dims=(), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4)), 'Invalid update_window_dims set in scatter op'), ('NonAscendingInsertedWindowDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(2, 1), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4)), 'inserted_window_dims in scatter op must be sorted'), ('RepeatedInsertedWindowDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(1, 1), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4)), 'inserted_window_dims in scatter op must not repeat'), ('OutOfBoundsInsertedWindowDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(1, 5), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4)), 'Invalid inserted_window_dims set in scatter op'), ('MismatchingScatterDimsToOperandDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(1, 2), scatter_dims_to_operand_dims=(0, 1, 2, 3)), 'Scatter op has 4 elements in scatter_dims_to_operand_dims and the bound of dimension index_vector_dim=4 of indices is 5. These two numbers must be equal'), ('OutOfBoundsScatterDimsToOperandDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(1, 2), scatter_dims_to_operand_dims=(0, 1, 2, 3, 10)), 'Invalid scatter_dims_to_operand_dims mapping'), ('RepeatedValuesInScatterDimsToOperandDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(1, 2), scatter_dims_to_operand_dims=(0, 1, 2, 2, 3)), 'scatter_dims_to_operand_dims in scatter op must not repeat'), ('InsufficientWindowDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 4), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(1,), scatter_dims_to_operand_dims=(0, 1, 2, 3)), \"Scatter op has window of size 4; doesn't match operand of rank 5.\"), ('InsufficientWindowDimsV2', (10, 49, 48, 47, 46, 45), (10, 9, 8, 7, 3), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(1,), scatter_dims_to_operand_dims=(1, 2, 3), operand_batching_dims=(0,), scatter_indices_batching_dims=(0,)), \"Scatter op has window of size 5; doesn't match operand of rank 6.\"), ('RepeatedOperandBatchingDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(0, 1), scatter_dims_to_operand_dims=(0, 1, 4), operand_batching_dims=(2, 3, 3)), 'operand_batching_dims in scatter op must not repeat'), ('NonAscendingOperandBatchingDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(0, 1), scatter_dims_to_operand_dims=(0, 1, 4), operand_batching_dims=(3, 2)), 'operand_batching_dims in scatter op must be sorted'), ('OutOfBoundsOperandBatchingDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4), operand_batching_dims=(0, 10)), 'Invalid operand_batching_dims set in scatter op; valid range is'), ('NonDisjointCollapsedAndBatchingDims', (50, 49, 48, 47, 46, 45), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(0, 1), scatter_dims_to_operand_dims=(0, 1, 4), operand_batching_dims=(1, 2)), 'inserted_window_dims and operand_batching_dims in scatter op must be disjoint'), ('NonDisjointScatterDimsToOperandDimsAndBatchingDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(0, 1), scatter_dims_to_operand_dims=(0, 1, 2, 4), operand_batching_dims=(2, 3)), 'scatter_dims_to_operand_dims and operand_batching_dims in scatter op must be disjoint'), ('RepeatedScatterIndicesBatchingDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(0, 1), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4), scatter_indices_batching_dims=(0, 1, 0)), 'scatter_indices_batching_dims in scatter op must not repeat'), ('OutOfBoundsScatterIndicesBatchingDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(0, 1), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4), scatter_indices_batching_dims=(0, 5)), 'Invalid scatter_indices_batching_dims set in scatter op; valid range'), ('IndexVectorDimInScatterIndicesBatchingDims', (50, 49, 48, 47, 46), (10, 9, 8, 7, 5), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(0, 1), scatter_dims_to_operand_dims=(0, 1, 2, 3, 4), scatter_indices_batching_dims=(0, 4)), 'Scatter op cannot have the index vector dimension as a batching dimension'), ('MismatchingNumberOfBatchingDims', (50, 49, 48, 47, 46, 45), (10, 9, 8, 7, 4), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(1, 2), scatter_dims_to_operand_dims=(1, 2, 3, 4), operand_batching_dims=(0,), scatter_indices_batching_dims=(0, 1)), 'Scatter op requires equal numbers of operand_batching_dims and scatter_indices_batching_dims'), ('MismatchingBatchingDimSizes', (10, 9, 48, 47, 46, 45), (10, 9, 8, 7, 2), (10, 9, 8, 7, 3, 2, 4), lax.ScatterDimensionNumbers(update_window_dims=(4, 5, 6), inserted_window_dims=(2,), scatter_dims_to_operand_dims=(2, 3), operand_batching_dims=(0, 1), scatter_indices_batching_dims=(1, 0)), 'Scatter op requires operand batching dimensions and indices batching dimensions to have the same shape')]))\ndef testScatterShapeCheckingRule(self, operand_shape, indices_shape, update_shape, dimension_numbers, msg):\n    indices = np.zeros(indices_shape, dtype=np.int32)\n\n    def f(x, y):\n        operand = lax.broadcast(x, operand_shape)\n        updates = lax.broadcast(y, update_shape)\n        return lax.scatter(operand, indices, updates, dimension_numbers)\n    with self.assertRaisesRegex(TypeError, msg):\n        jax.eval_shape(f, np.int32(1), np.int32(1))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testDynamicUpdateSliceTypeErrors(self):\n    self.assertRaisesRegex(TypeError, 'index arguments to dynamic_update_slice must be integers of the same type', lambda: lax.dynamic_update_slice(np.ones((3, 4), dtype=np.float32), np.zeros((2, 2), dtype=np.float32), (np.int32(1), np.int16(2))))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_window_strides_dimension_shape_rule(self):\n    msg = 'conv_general_dilated window and window_strides must have the same number of dimensions'\n    lhs = jax.numpy.zeros((1, 1, 3, 3))\n    rhs = np.zeros((1, 1, 1, 1))\n    with self.assertRaisesRegex(ValueError, msg):\n        jax.lax.conv(lhs, rhs, [1], 'SAME')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_reduce_window_scalar_init_value_shape_rule(self):\n    args = {'operand': np.ones((4, 4), dtype=np.int32), 'init_value': np.zeros((1,), dtype=np.int32), 'computation': lax.max, 'window_dimensions': (2, 2), 'window_strides': (2, 2), 'padding': 'VALID', 'base_dilation': (1, 1), 'window_dilation': (1, 1)}\n    msg = 'reduce_window expected init_values to be scalars but init_values have shapes \\\\[\\\\(1,\\\\)\\\\].'\n    with self.assertRaisesRegex(TypeError, msg):\n        lax.reduce_window(**args)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product(dtype_in=lax_test_util.all_dtypes, dtype_out=lax_test_util.all_dtypes)\n@jtu.ignore_warning(category=NumpyComplexWarning)\ndef testConvertElementTypeAvoidsCopies(self, dtype_in, dtype_out):\n    x = jax.device_put(np.zeros(5, dtype_in))\n    self.assertEqual(x.dtype, dtype_in)\n    y = lax.convert_element_type(x, dtype_out)\n    self.assertEqual(y.dtype, dtype_out)\n    x_buf = x\n    y_buf = y\n    if np.dtype(dtype_in) == np.dtype(dtype_out):\n        self.assertEqual(x_buf.unsafe_buffer_pointer(), y_buf.unsafe_buffer_pointer())\n    else:\n        self.assertNotEqual(x_buf.unsafe_buffer_pointer(), y_buf.unsafe_buffer_pointer())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_gather_batched_index_dtype(self):\n    dtype = jnp.int8\n    size = jnp.iinfo(dtype).max + 10\n    indices = jnp.zeros(size, dtype=dtype)\n    values = jnp.zeros((size, 1))\n    results = jax.vmap(lambda x, i: jnp.take(x, i, axis=0))(values, indices)\n    self.assertArraysEqual(results, jnp.zeros(size))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_equality(self):\n    eq = jax.jit(lambda k1, k2: k1 == k2)\n    ne = jax.jit(lambda k1, k2: k1 != k2)\n    k1 = jax.jit(lambda: make(()))()\n    k2 = jax.jit(lambda: jake(make(())))()\n    self.assertTrue(eq(k1, k1))\n    self.assertFalse(eq(k1, k2))\n    self.assertTrue(ne(k1, k2))\n    self.assertFalse(ne(k1, k1))\n    size = 5\n    idx = slice(2, 4)\n    ks = jax.jit(lambda k: jake(make((size,))).at[idx].set(k))(k1)\n    expected = jnp.zeros(size, dtype=bool).at[idx].set(True)\n    self.assertArraysEqual(eq(k1, ks), expected)\n    self.assertArraysEqual(ne(k1, ks), ~expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_composite_attribute_dtypes(self):\n\n    @jax.jit\n    def my_tangent_composite_with_attributes(x):\n\n        def decomposition(x, **_):\n            return lax.sin(x) / lax.cos(x)\n        return lax.composite(decomposition, 'my.tangent')(x, dtype=np.dtype(np.float32), int=1, omit=None, str='bar', tensor=np.zeros((1, 2), dtype=np.float32), tensor_r1=np.zeros((2,), dtype=np.float32))\n    pi = jnp.pi\n    x = jnp.array([0.0, pi / 4, 3 * pi / 4, pi], dtype=jnp.float32)\n    output = my_tangent_composite_with_attributes(x)\n    self.assertArraysAllClose(output, jnp.array([0.0, 1.0, -1.0, 0.0], dtype=jnp.float32))\n    mlir_module = my_tangent_composite_with_attributes.lower(x).as_text()\n    self.assertIn('stablehlo.composite \"my.tangent\" %arg0 {composite_attributes = {dtype = f32, int = 1 : i64, str = \"bar\", tensor = dense<0.000000e+00> : tensor<1x2xf32>, tensor_r1 = dense<0.000000e+00> : tensor<2xf32>}, decomposition = @my.tangent} : (tensor<4xf32>) -> tensor<4xf32>', mlir_module)\n    self.assertIn('func.func private @my.tangent', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_composite_unsupported_attribute_dtypes(self):\n\n    def my_tangent_composite_with_attributes(x):\n\n        def decomposition(x, **_):\n            return lax.sin(x) / lax.cos(x)\n        return lax.composite(decomposition, 'my.tangent')(x, tensor=jnp.zeros((1, 2), dtype=jnp.float32))\n    pi = jnp.pi\n    x = jnp.array([0.0, pi / 4, 3 * pi / 4, pi], dtype=jnp.float32)\n    with self.assertRaisesRegex(UnexpectedTracerError, 'Note: If you are passing jax arrays as attributes, use numpy arrays instead.'):\n        jax.jit(my_tangent_composite_with_attributes).lower(x).as_text()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product([{'m': 5, 'k': 4, 'n': 3, 'num_groups': 1}, {'m': 10, 'k': 9, 'n': 8, 'num_groups': 2}], dtype=jtu.dtypes.numeric)\ndef test_ragged_dot(self, m, k, n, num_groups, dtype):\n    \"\"\"Tests ragged_dot.\n\n    The ragged_dot is tested against numpy reference implementation, and by\n    running JAX compilation.\n\n    Raises:\n      SkipTest: in the case dtype is not supported.\n    \"\"\"\n    lhs_shape = (m, k)\n    rhs_shape = (num_groups, k, n)\n\n    def group_sizes(m, num_groups):\n        ends_no_final = jnp.sort(self.rng().choice(m, size=num_groups - 1))\n        ends = jnp.concatenate([ends_no_final, jnp.array([m], dtype=ends_no_final.dtype)])\n        starts = jnp.concatenate([jnp.zeros(1, dtype=ends_no_final.dtype), ends_no_final])\n        return ends - starts\n    rng = jtu.rand_small(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype), group_sizes(m, num_groups)]\n    self._CompileAndCheck(lax.ragged_dot, args_maker)\n    self._CheckAgainstNumpy(lax_reference.ragged_dot, lax.ragged_dot, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testDotAlgorithmCasting(self):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('F32_F32_F32 is not supported on TPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F32_F32_F32')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertEqual(fun(lhs, rhs).dtype, np.float16)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, abstracted_axes=('n',))\ndef fun(x):\n    return jnp.sum(x)"
  },
  {
    "test_code": "@jtu.sample_product(op=['add', 'mul'], op_namespace=[lax, operator], arr_weak_type=[False, True], init_weak_type=[False, True])\ndef testReduceWeakType(self, op_namespace, op, arr_weak_type, init_weak_type):\n    op = getattr(op_namespace, op)\n    arr = lax_internal._convert_element_type(np.arange(10), int, weak_type=arr_weak_type)\n    init = lax_internal._convert_element_type(1, int, weak_type=init_weak_type)\n    fun = lambda arr, init: lax.reduce(arr, init, op, (0,))\n    out = fun(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out), arr_weak_type and init_weak_type)\n    out_jit = jax.jit(fun)(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), arr_weak_type and init_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, abstracted_axes=('n',))\ndef fun(x):\n    return jnp.sum(x)"
  },
  {
    "test_code": "def test_composite_with_tracer_consts(self):\n\n    def fun(x, scale):\n\n        @partial(lax.composite, name='my.consts')\n        def my_consts(y):\n            return jnp.round(y / scale)\n        return my_consts(x)\n    scale = jnp.array([0.5, 0.4, 0.3], dtype=jnp.float32)\n    x = jnp.array([1.0, 2.0, 3.0], dtype=jnp.float32)\n    self.assertAllClose(fun(x, scale), jnp.round(x / scale))\n    self.assertAllClose(jax.jit(partial(fun, scale=scale))(x), jnp.round(x / scale))\n    with self.assertRaisesRegex(UnexpectedTracerError, \"Found a JAX Tracer as a constant in the decomposition for the composite op 'my.consts'.\"):\n        jax.jit(fun)(x, scale)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, abstracted_axes=('n',))\ndef fun(x):\n    return jnp.sum(x)"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef fn(n, x):\n    return lax.broadcast_in_dim(x, (n,), ())"
  },
  {
    "test_code": "@jtu.sample_product([dict(base_shape=shape, axis=axis) for shape in [(4,), (3, 4), (2, 3, 4)] for axis in range(len(shape))], num_pieces=range(3), dtype=lax_test_util.default_dtypes)\ndef testSplit(self, axis, base_shape, dtype, num_pieces):\n    sizes = jtu.rand_int(self.rng(), 5)((num_pieces + 1,), np.int64)\n    shape = list(base_shape)\n    shape[axis] = np.sum(sizes)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(shape, dtype)]\n    op = lambda x: lax.split(x, sizes, axis=axis)\n\n    def numpy_op(x):\n        return np.split(x, np.cumsum(sizes[:-1]), axis=axis)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def cumsum(x):\n\n    def body(i, _):\n        return (i + 1, jnp.sum(x[:i + 1]))\n    _, ans = lax.scan(body, 0, None, length=len(x))\n    return ans"
  },
  {
    "test_code": "def testCumsumLengthOne(self):\n    x = lax.full((1,), 1)\n    out = lax.cumsum(x)\n    self.assertArraysEqual(out, x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def cumsum(x):\n\n    def body(i, _):\n        return (i + 1, jnp.sum(x[:i + 1]))\n    _, ans = lax.scan(body, 0, None, length=len(x))\n    return ans"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def testDotAlgorithmCasting(self):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('F32_F32_F32 is not supported on TPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F32_F32_F32')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertEqual(fun(lhs, rhs).dtype, np.float16)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef fun(x, y):\n    return cond(x < 3, None, lambda _: 2.0 * jnp.sin(y), x, lambda x: 2.0 * x)"
  },
  {
    "test_code": "@jtu.sample_product(op=['add', 'mul'], op_namespace=[lax, operator], arr_weak_type=[False, True], init_weak_type=[False, True])\ndef testReduceWeakType(self, op_namespace, op, arr_weak_type, init_weak_type):\n    op = getattr(op_namespace, op)\n    arr = lax_internal._convert_element_type(np.arange(10), int, weak_type=arr_weak_type)\n    init = lax_internal._convert_element_type(1, int, weak_type=init_weak_type)\n    fun = lambda arr, init: lax.reduce(arr, init, op, (0,))\n    out = fun(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out), arr_weak_type and init_weak_type)\n    out_jit = jax.jit(fun)(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), arr_weak_type and init_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef fun(x, y):\n    return cond(x < 3, None, lambda _: 2.0 * jnp.sin(y), x, lambda x: 2.0 * x)"
  },
  {
    "test_code": "def test_composite_with_tracer_consts(self):\n\n    def fun(x, scale):\n\n        @partial(lax.composite, name='my.consts')\n        def my_consts(y):\n            return jnp.round(y / scale)\n        return my_consts(x)\n    scale = jnp.array([0.5, 0.4, 0.3], dtype=jnp.float32)\n    x = jnp.array([1.0, 2.0, 3.0], dtype=jnp.float32)\n    self.assertAllClose(fun(x, scale), jnp.round(x / scale))\n    self.assertAllClose(jax.jit(partial(fun, scale=scale))(x), jnp.round(x / scale))\n    with self.assertRaisesRegex(UnexpectedTracerError, \"Found a JAX Tracer as a constant in the decomposition for the composite op 'my.consts'.\"):\n        jax.jit(fun)(x, scale)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef fun(x, y):\n    return cond(x < 3, None, lambda _: 2.0 * jnp.sin(y), x, lambda x: 2.0 * x)"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\ndef fn(a, b):\n    m1, v1 = a\n    m2, v2 = b\n    return (m1 + m2, jsp.linalg.solve(m1, v2) + jsp.linalg.solve(m2, v1))"
  },
  {
    "test_code": "def test_constant_folding_complex_to_real_scan_regression(self):\n\n    def g(hiddens):\n        hiddens_aug = jnp.vstack((hiddens[0], hiddens))\n        new_hiddens = hiddens_aug.copy()\n        diff = new_hiddens[:-1] - hiddens\n        diff = new_hiddens[:-1] - hiddens\n        out = jnp.trace(jnp.conj(diff).T @ diff).real\n        return jnp.array(out, dtype=jnp.complex64)\n\n    def _step(carry, arg):\n        primals, f_vjp = jax.vjp(g, jax.random.normal(jax.random.key(0), (9, 8), dtype=jnp.complex64))\n        out = f_vjp(np.array(1.0 + 0j, 'complex64'))[0]\n        return (carry, carry)\n    a, b = jax.lax.scan(_step, 0, jnp.arange(4, dtype=jnp.complex64))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def scan(y):\n\n    def body(carry, x):\n        return (carry, jnp.dot(x, x))\n    return jax.lax.scan(body, 1.0, y, unroll=False)"
  },
  {
    "test_code": "def test_scan_jaxpr(self):\n    ks = jax.jit(lambda: make((3, 4)))()\n    f = lambda ks: jax.lax.scan(lambda _, k: (None, bake(k)), None, ks)\n    jaxpr = jax.make_jaxpr(f)(ks).jaxpr\n    self.assertLen(jaxpr.invars, 1)\n    a, = jaxpr.invars\n    self.assertEqual(a.aval, core.ShapedArray((3, 4), FooTy()))\n    self.assertLen(jaxpr.eqns, 1)\n    e, = jaxpr.eqns\n    self.assertLen(e.outvars, 1)\n    b, = e.outvars\n    self.assertEqual(b.aval, core.ShapedArray((3, 4), FooTy()))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def scan(y):\n\n    def body(carry, x):\n        return (carry, jnp.dot(x, x))\n    return jax.lax.scan(body, 1.0, y, unroll=False)"
  },
  {
    "test_code": "def test_scan_jaxpr_split_transpose(self):\n\n    def stage(x, w):\n        x = x @ w\n        x = jnp.tanh(x)\n        return (x, ())\n\n    def loss(ws, x, split_transpose=False):\n        return jnp.sum(jax.lax.scan(stage, x, ws, _split_transpose=split_transpose)[0])\n\n    def fn(*args, split_transpose=False):\n        v, fn_transpose = jax.vjp(partial(loss, split_transpose=split_transpose), *args)\n        grads = fn_transpose(1.0)\n        return (*grads, v)\n    x = jax.random.uniform(jax.random.key(0), [256, 100])\n    wss = jax.random.uniform(jax.random.key(1), [7, 100, 100])\n    jaxpr = jax.make_jaxpr(partial(fn))(wss, x)\n    jaxpr_split_transpose = jax.make_jaxpr(partial(fn, split_transpose=True))(wss, x)\n    self.assertEqual(jaxpr.in_avals, jaxpr_split_transpose.in_avals)\n    self.assertEqual(jaxpr.out_avals, jaxpr_split_transpose.out_avals)\n    ct_ws = jaxpr_split_transpose.jaxpr.outvars[0]\n    ct_x = jaxpr_split_transpose.jaxpr.outvars[1]\n    backprop_scan = jaxpr_split_transpose.jaxpr.eqns[-2]\n    self.assertEqual(backprop_scan.primitive, jax.lax.scan_p)\n    param_gradient_map = jaxpr_split_transpose.jaxpr.eqns[-1]\n    self.assertEqual(param_gradient_map.primitive, jax.lax.scan_p)\n    self.assertEqual(param_gradient_map.params['num_consts'], 0)\n    self.assertEqual(param_gradient_map.params['num_carry'], 0)\n    self.assertEqual(ct_ws, param_gradient_map.outvars[0])\n    self.assertEqual(ct_x, backprop_scan.outvars[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def scan(y):\n\n    def body(carry, x):\n        return (carry, jnp.dot(x, x))\n    return jax.lax.scan(body, 1.0, y, unroll=False)"
  },
  {
    "test_code": "def test_scan_lowering(self):\n    ks = jax.jit(lambda: make((3, 4)))()\n    f = lambda ks: jax.lax.scan(lambda _, k: (None, bake(k)), None, ks)\n    _, out = jax.jit(f)(ks)\n    self.assertIsInstance(out, FooArray)\n    self.assertEqual(out.shape, (3, 4))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def scan(y):\n\n    def body(carry, x):\n        return (carry, jnp.dot(x, x))\n    return jax.lax.scan(body, 1.0, y, unroll=False)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "@jtu.sample_product([dict(base_shape=shape, axis=axis) for shape in [(4,), (3, 4), (2, 3, 4)] for axis in range(len(shape))], num_pieces=range(3), dtype=lax_test_util.default_dtypes)\ndef testSplit(self, axis, base_shape, dtype, num_pieces):\n    sizes = jtu.rand_int(self.rng(), 5)((num_pieces + 1,), np.int64)\n    shape = list(base_shape)\n    shape[axis] = np.sum(sizes)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(shape, dtype)]\n    op = lambda x: lax.split(x, sizes, axis=axis)\n\n    def numpy_op(x):\n        return np.split(x, np.cumsum(sizes[:-1]), axis=axis)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def cumsum(x):\n\n    def body(i, refs):\n        x_ref, accum_ref = refs\n        accum_ref[i + 1] = accum_ref[i] + x_ref[i]\n    accum = jnp.zeros(x.shape[0] + 1, x.dtype)\n    _, accum_out = for_impl(x.shape[0], body, (x, accum))\n    return accum_out[1:]"
  },
  {
    "test_code": "def testCumsumLengthOne(self):\n    x = lax.full((1,), 1)\n    out = lax.cumsum(x)\n    self.assertArraysEqual(out, x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def cumsum(x):\n\n    def body(i, refs):\n        x_ref, accum_ref = refs\n        accum_ref[i + 1] = accum_ref[i] + x_ref[i]\n    accum = jnp.zeros(x.shape[0] + 1, x.dtype)\n    _, accum_out = for_impl(x.shape[0], body, (x, accum))\n    return accum_out[1:]"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def testDotAlgorithmCasting(self):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('F32_F32_F32 is not supported on TPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F32_F32_F32')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertEqual(fun(lhs, rhs).dtype, np.float16)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun():\n    return jax.ffi.ffi_call('test', jax.ShapeDtypeStruct((), np.int64))()"
  },
  {
    "test_code": "@jtu.sample_product(op=['add', 'mul'], op_namespace=[lax, operator], arr_weak_type=[False, True], init_weak_type=[False, True])\ndef testReduceWeakType(self, op_namespace, op, arr_weak_type, init_weak_type):\n    op = getattr(op_namespace, op)\n    arr = lax_internal._convert_element_type(np.arange(10), int, weak_type=arr_weak_type)\n    init = lax_internal._convert_element_type(1, int, weak_type=init_weak_type)\n    fun = lambda arr, init: lax.reduce(arr, init, op, (0,))\n    out = fun(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out), arr_weak_type and init_weak_type)\n    out_jit = jax.jit(fun)(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), arr_weak_type and init_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun():\n    return jax.ffi.ffi_call('test', jax.ShapeDtypeStruct((), np.int64))()"
  },
  {
    "test_code": "def test_composite_with_tracer_consts(self):\n\n    def fun(x, scale):\n\n        @partial(lax.composite, name='my.consts')\n        def my_consts(y):\n            return jnp.round(y / scale)\n        return my_consts(x)\n    scale = jnp.array([0.5, 0.4, 0.3], dtype=jnp.float32)\n    x = jnp.array([1.0, 2.0, 3.0], dtype=jnp.float32)\n    self.assertAllClose(fun(x, scale), jnp.round(x / scale))\n    self.assertAllClose(jax.jit(partial(fun, scale=scale))(x), jnp.round(x / scale))\n    with self.assertRaisesRegex(UnexpectedTracerError, \"Found a JAX Tracer as a constant in the decomposition for the composite op 'my.consts'.\"):\n        jax.jit(fun)(x, scale)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun():\n    return jax.ffi.ffi_call('test', jax.ShapeDtypeStruct((), np.int64))()"
  },
  {
    "test_code": "def testDotAlgorithmCasting(self):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('F32_F32_F32 is not supported on TPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F32_F32_F32')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertEqual(fun(lhs, rhs).dtype, np.float16)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun(x, t):\n    return jnp.sum(jnp.power(jnp.maximum(x, 0.0), 2)) + t"
  },
  {
    "test_code": "@jtu.sample_product(op=['add', 'mul'], op_namespace=[lax, operator], arr_weak_type=[False, True], init_weak_type=[False, True])\ndef testReduceWeakType(self, op_namespace, op, arr_weak_type, init_weak_type):\n    op = getattr(op_namespace, op)\n    arr = lax_internal._convert_element_type(np.arange(10), int, weak_type=arr_weak_type)\n    init = lax_internal._convert_element_type(1, int, weak_type=init_weak_type)\n    fun = lambda arr, init: lax.reduce(arr, init, op, (0,))\n    out = fun(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out), arr_weak_type and init_weak_type)\n    out_jit = jax.jit(fun)(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), arr_weak_type and init_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun(x, t):\n    return jnp.sum(jnp.power(jnp.maximum(x, 0.0), 2)) + t"
  },
  {
    "test_code": "def test_composite_with_tracer_consts(self):\n\n    def fun(x, scale):\n\n        @partial(lax.composite, name='my.consts')\n        def my_consts(y):\n            return jnp.round(y / scale)\n        return my_consts(x)\n    scale = jnp.array([0.5, 0.4, 0.3], dtype=jnp.float32)\n    x = jnp.array([1.0, 2.0, 3.0], dtype=jnp.float32)\n    self.assertAllClose(fun(x, scale), jnp.round(x / scale))\n    self.assertAllClose(jax.jit(partial(fun, scale=scale))(x), jnp.round(x / scale))\n    with self.assertRaisesRegex(UnexpectedTracerError, \"Found a JAX Tracer as a constant in the decomposition for the composite op 'my.consts'.\"):\n        jax.jit(fun)(x, scale)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun(x, t):\n    return jnp.sum(jnp.power(jnp.maximum(x, 0.0), 2)) + t"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def testDotAlgorithmCasting(self):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('F32_F32_F32 is not supported on TPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F32_F32_F32')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertEqual(fun(lhs, rhs).dtype, np.float16)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, backend=backend)\ndef fun(x, y):\n    return jnp.matmul(x, y)"
  },
  {
    "test_code": "@jtu.sample_product(op=['add', 'mul'], op_namespace=[lax, operator], arr_weak_type=[False, True], init_weak_type=[False, True])\ndef testReduceWeakType(self, op_namespace, op, arr_weak_type, init_weak_type):\n    op = getattr(op_namespace, op)\n    arr = lax_internal._convert_element_type(np.arange(10), int, weak_type=arr_weak_type)\n    init = lax_internal._convert_element_type(1, int, weak_type=init_weak_type)\n    fun = lambda arr, init: lax.reduce(arr, init, op, (0,))\n    out = fun(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out), arr_weak_type and init_weak_type)\n    out_jit = jax.jit(fun)(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), arr_weak_type and init_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, backend=backend)\ndef fun(x, y):\n    return jnp.matmul(x, y)"
  },
  {
    "test_code": "def test_composite_with_tracer_consts(self):\n\n    def fun(x, scale):\n\n        @partial(lax.composite, name='my.consts')\n        def my_consts(y):\n            return jnp.round(y / scale)\n        return my_consts(x)\n    scale = jnp.array([0.5, 0.4, 0.3], dtype=jnp.float32)\n    x = jnp.array([1.0, 2.0, 3.0], dtype=jnp.float32)\n    self.assertAllClose(fun(x, scale), jnp.round(x / scale))\n    self.assertAllClose(jax.jit(partial(fun, scale=scale))(x), jnp.round(x / scale))\n    with self.assertRaisesRegex(UnexpectedTracerError, \"Found a JAX Tracer as a constant in the decomposition for the composite op 'my.consts'.\"):\n        jax.jit(fun)(x, scale)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, backend=backend)\ndef fun(x, y):\n    return jnp.matmul(x, y)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "@jtu.sample_product([dict(base_shape=shape, axis=axis) for shape in [(4,), (3, 4), (2, 3, 4)] for axis in range(len(shape))], num_pieces=range(3), dtype=lax_test_util.default_dtypes)\ndef testSplit(self, axis, base_shape, dtype, num_pieces):\n    sizes = jtu.rand_int(self.rng(), 5)((num_pieces + 1,), np.int64)\n    shape = list(base_shape)\n    shape[axis] = np.sum(sizes)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(shape, dtype)]\n    op = lambda x: lax.split(x, sizes, axis=axis)\n\n    def numpy_op(x):\n        return np.split(x, np.cumsum(sizes[:-1]), axis=axis)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "def testSplitErrors(self):\n    with self.assertRaisesRegex(ValueError, 'Sizes passed to split must be nonnegative'):\n        lax.split(np.arange(5), [-1])\n    with self.assertRaisesRegex(ValueError, 'Sum of sizes 6 must be equal'):\n        lax.split(np.arange(5), [6])\n    with self.assertRaisesRegex(ValueError, 'axis 1 is out of bounds'):\n        lax.split(np.arange(5), sizes=(), axis=1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(-np.inf, lax.max, [np.float32]), (np.inf, lax.min, [np.float32]), (0, lax.add, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowCustomSameAsMonoid(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(op_, operand_):\n        return lax.reduce_window(operand_, init_val, op_, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    args = args_maker()\n    operand = args[0]\n    rng = np.random.RandomState(0)\n    tangent = tree_map(partial(jtu.rand_like, rng), operand)\n    custom_equiv = {lax.max: _reduce_custom_max, lax.min: _reduce_custom_min, lax.add: _reduce_custom_add}\n    custom_op = custom_equiv[op]\n    custom_primals, custom_tangents = jax.jvp(partial(fun, custom_op), primals=(operand,), tangents=(tangent,))\n    lax_primals, lax_tangents = jax.jvp(partial(fun, op), primals=(operand,), tangents=(tangent,))\n    tol = None\n    jtu.check_close(lax_primals, custom_primals, atol=tol, rtol=tol, err_msg='Mismatched primal')\n    jtu.check_close(lax_tangents, custom_tangents, atol=tol, rtol=tol, err_msg='Mismatched tangents')\n    if init_val.item() in (np.inf, -np.inf):\n        return\n    op_bound_fn = partial(fun, op)\n    jtu.check_jvp(op_bound_fn, partial(jax.jvp, op_bound_fn), (operand,))\n    check_grads(partial(fun, op), [operand], 3, ['fwd'], eps=1.0)\n    check_grads(partial(fun, custom_op), [operand], 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def check_close(x, y, tol=0.001):\n    assert jnp.shape(x) == jnp.shape(y)\n    assert jnp.allclose(x, y, rtol=tol, atol=tol), f'Value mismatch:\\n{x}\\n  vs\\n{y}\\n'"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@custom_transpose_with_example_out(jnp.ones(2))\ndef fn(r, x):\n    tracer_spy.append(r)\n    tracer_spy.append(x['c'])\n    return dict(b=x['c'] / r)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(from_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, to_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, shape=[(), (2,), (2, 3)])\ndef testBitcastConvertType(self, from_dtype, to_dtype, shape):\n    rng = jtu.rand_default(self.rng())\n    nbits_in = dtypes.bit_width(from_dtype)\n    nbits_out = dtypes.bit_width(to_dtype)\n    if nbits_in < nbits_out:\n        shape = (*shape, nbits_out // nbits_in)\n    args_maker = lambda: [rng(shape, from_dtype)]\n    jnp_op = lambda x: lax.bitcast_convert_type(x, to_dtype)\n    self._CompileAndCheck(jnp_op, args_maker)\n    out = jnp_op(*args_maker())\n    if nbits_in == nbits_out:\n        expected_shape = shape\n    elif nbits_in < nbits_out:\n        expected_shape = shape[:-1]\n    else:\n        expected_shape = (*shape, nbits_in // nbits_out)\n    self.assertEqual(out.dtype, to_dtype)\n    self.assertEqual(out.shape, expected_shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@parameterized.parameters([(algorithm, dtype) for algorithm, test_dtypes in [(lax.DotAlgorithm(lhs_precision_type=np.float32, rhs_precision_type=np.float32, accumulation_type=np.float32, lhs_component_count=1, rhs_component_count=1, num_primitive_operations=1, allow_imprecise_accumulation=False), [np.float32]), (lax.DotAlgorithm(lhs_precision_type=np.float16, rhs_precision_type=np.float16, accumulation_type=np.float32), [np.float16]), ('F16_F16_F32', [np.float16]), (lax.DotAlgorithmPreset.DEFAULT, lax_test_util.float_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.F16_F16_F16, [np.float16]), (lax.DotAlgorithmPreset.F16_F16_F32, [np.float16]), (lax.DotAlgorithmPreset.BF16_BF16_BF16, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X6, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.F32_F32_F32, [np.float32]), (lax.DotAlgorithmPreset.F64_F64_F64, [np.float64])] for dtype in test_dtypes if jtu.dtypes.supported([dtype])])\ndef testDotAlgorithm(self, algorithm, dtype):\n    if jtu.test_device_matches(['cpu']):\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.F16_F16_F16, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on CPU.\")\n    if jtu.test_device_matches(['gpu']):\n        if algorithm in {lax.DotAlgorithmPreset.F16_F16_F32, lax.DotAlgorithmPreset.TF32_TF32_F32, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            if not jtu.is_cuda_compute_capability_at_least('8.0'):\n                raise SkipTest(f\"The dot algorithm '{algorithm}' requires CUDA compute capability >= 8.0.\")\n        elif algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on GPU.\")\n    if jtu.test_device_matches(['tpu']):\n        if not jtu.if_cloud_tpu_at_least(2024, 12, 19):\n            self.skipTest('Requires libtpu built after 2024-12-19')\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on TPU.\")\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    self._CompileAndCheck(partial(lax.dot, precision=algorithm), args_maker)\n    self.assertEqual(lax.dot(*args_maker(), precision=algorithm).dtype, dtype)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, dimensions=dimensions) for arg_shape, dimensions in [[(1,), (0,)], [(1,), (-1,)], [(2, 1, 4), (1,)], [(2, 1, 3, 1), (1,)], [(2, 1, 3, 1), (1, 3)], [(2, 1, 3, 1), (3,)]]])\ndef testSqueeze(self, arg_shape, dimensions):\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(arg_shape, np.float32)]\n    op = lambda x: lax.squeeze(x, dimensions)\n    numpy_op = lambda x: lax_reference.squeeze(x, dimensions)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)\n    check_grads(op, args_maker(), 3, ['fwd', 'rev'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(1, _reduce_custom_add, [np.float32]), (0, _reduce_custom_mul, [np.float32]), (0, _reduce_custom_sub, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowGeneralJVP(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(operand, init_val):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype), init_val]\n    self._CompileAndCheck(fun, args_maker)\n    args = args_maker()\n    init_val = args[1]\n\n    def fun2(operand):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CompileAndCheck(fun2, args_maker)\n    operand = args_maker()[0]\n    jtu.check_jvp(fun2, partial(jax.jvp, fun2), (operand,))\n    check_grads(fun2, (operand,), 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(-np.inf, lax.max, [np.float32]), (np.inf, lax.min, [np.float32]), (0, lax.add, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowCustomSameAsMonoid(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(op_, operand_):\n        return lax.reduce_window(operand_, init_val, op_, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    args = args_maker()\n    operand = args[0]\n    rng = np.random.RandomState(0)\n    tangent = tree_map(partial(jtu.rand_like, rng), operand)\n    custom_equiv = {lax.max: _reduce_custom_max, lax.min: _reduce_custom_min, lax.add: _reduce_custom_add}\n    custom_op = custom_equiv[op]\n    custom_primals, custom_tangents = jax.jvp(partial(fun, custom_op), primals=(operand,), tangents=(tangent,))\n    lax_primals, lax_tangents = jax.jvp(partial(fun, op), primals=(operand,), tangents=(tangent,))\n    tol = None\n    jtu.check_close(lax_primals, custom_primals, atol=tol, rtol=tol, err_msg='Mismatched primal')\n    jtu.check_close(lax_tangents, custom_tangents, atol=tol, rtol=tol, err_msg='Mismatched tangents')\n    if init_val.item() in (np.inf, -np.inf):\n        return\n    op_bound_fn = partial(fun, op)\n    jtu.check_jvp(op_bound_fn, partial(jax.jvp, op_bound_fn), (operand,))\n    check_grads(partial(fun, op), [operand], 3, ['fwd'], eps=1.0)\n    check_grads(partial(fun, custom_op), [operand], 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product(from_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, to_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, shape=[(), (2,), (2, 3)])\ndef testBitcastConvertType(self, from_dtype, to_dtype, shape):\n    rng = jtu.rand_default(self.rng())\n    nbits_in = dtypes.bit_width(from_dtype)\n    nbits_out = dtypes.bit_width(to_dtype)\n    if nbits_in < nbits_out:\n        shape = (*shape, nbits_out // nbits_in)\n    args_maker = lambda: [rng(shape, from_dtype)]\n    jnp_op = lambda x: lax.bitcast_convert_type(x, to_dtype)\n    self._CompileAndCheck(jnp_op, args_maker)\n    out = jnp_op(*args_maker())\n    if nbits_in == nbits_out:\n        expected_shape = shape\n    elif nbits_in < nbits_out:\n        expected_shape = shape[:-1]\n    else:\n        expected_shape = (*shape, nbits_in // nbits_out)\n    self.assertEqual(out.dtype, to_dtype)\n    self.assertEqual(out.shape, expected_shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def jnp_op(start, stop):\n    return jnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype, axis=axis)"
  },
  {
    "test_code": "@jtu.sample_product([dict(op=op, np_op=np_op) for op, np_op in [(lax.cumsum, np.cumsum), (lax.cumprod, np.cumprod), (lax.cummax, np.maximum.accumulate), (lax.cummin, np.minimum.accumulate)]], [dict(shape=shape, axis=axis) for shape in [[10], [3, 4, 5]] for axis in range(len(shape))], dtype=lax_test_util.default_dtypes, reverse=[False, True])\ndef testCumulativeReduce(self, op, np_op, shape, dtype, axis, reverse):\n    rng_factory = jtu.rand_default if dtypes.issubdtype(dtype, np.integer) else jtu.rand_small\n    rng = rng_factory(self.rng())\n    fun = partial(op, axis=axis, reverse=reverse)\n\n    def np_fun(x):\n        if reverse:\n            return np.flip(np_op(np.flip(x, axis), axis=axis, dtype=dtype), axis)\n        else:\n            return np_op(x, axis=axis, dtype=dtype)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CompileAndCheck(fun, args_maker)\n    self._CheckAgainstNumpy(np_fun, fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def np_op(start, stop):\n    start = start.astype(np.float32) if dtype == jnp.bfloat16 else start\n    stop = stop.astype(np.float32) if dtype == jnp.bfloat16 else stop\n    return np.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype if dtype != jnp.bfloat16 else np.float32, axis=axis).astype(dtype)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def testReshapeWithUnusualShapes(self):\n    ans = lax.reshape(np.ones((3,), np.float32), (lax.add(1, 2), 1))\n    self.assertAllClose(ans, np.ones((3, 1), np.float32))\n    self.assertRaisesRegex(TypeError, 'Shapes must be 1D sequences of concrete values of integer type.*', lambda: lax.reshape(np.ones(3), (np.array([3, 1]),)))\n    self.assertRaisesRegex(TypeError, 'Shapes must be 1D sequences of concrete values of integer type.*', lambda: lax.reshape(np.ones(3), (1.5, 2.0)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@staticmethod\ndef add(dt, x, y):\n    fromscale = partial(jax.lax.convert_element_type, new_dtype=dt.float_dtype)\n    toscale = partial(jax.lax.convert_element_type, new_dtype=dt)\n    return toscale(jax.lax.max(fromscale(x), fromscale(y)))"
  },
  {
    "test_code": "def test_primitive_jaxtype_error(self):\n    err_str = 'Error interpreting argument to .* as an abstract array. The problematic value is of type .* and was passed to the function at path args\\\\[1\\\\].'\n    with jax.enable_checks(False):\n        with self.assertRaisesRegex(TypeError, err_str):\n            lax.add(1, 'hi')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@staticmethod\ndef add(dt, x, y):\n    fromscale = partial(jax.lax.convert_element_type, new_dtype=dt.float_dtype)\n    toscale = partial(jax.lax.convert_element_type, new_dtype=dt)\n    return toscale(jax.lax.max(fromscale(x), fromscale(y)))"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@staticmethod\ndef add(dt, x, y):\n    fromscale = partial(jax.lax.convert_element_type, new_dtype=dt.float_dtype)\n    toscale = partial(jax.lax.convert_element_type, new_dtype=dt)\n    return toscale(jax.lax.max(fromscale(x), fromscale(y)))"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@staticmethod\ndef add(dt, x, y):\n    fromscale = partial(jax.lax.convert_element_type, new_dtype=dt.float_dtype)\n    toscale = partial(jax.lax.convert_element_type, new_dtype=dt)\n    return toscale(jax.lax.max(fromscale(x), fromscale(y)))"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "@jtu.sample_product(from_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, to_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, shape=[(), (2,), (2, 3)])\ndef testBitcastConvertType(self, from_dtype, to_dtype, shape):\n    rng = jtu.rand_default(self.rng())\n    nbits_in = dtypes.bit_width(from_dtype)\n    nbits_out = dtypes.bit_width(to_dtype)\n    if nbits_in < nbits_out:\n        shape = (*shape, nbits_out // nbits_in)\n    args_maker = lambda: [rng(shape, from_dtype)]\n    jnp_op = lambda x: lax.bitcast_convert_type(x, to_dtype)\n    self._CompileAndCheck(jnp_op, args_maker)\n    out = jnp_op(*args_maker())\n    if nbits_in == nbits_out:\n        expected_shape = shape\n    elif nbits_in < nbits_out:\n        expected_shape = shape[:-1]\n    else:\n        expected_shape = (*shape, nbits_in // nbits_out)\n    self.assertEqual(out.dtype, to_dtype)\n    self.assertEqual(out.shape, expected_shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@parameterized.parameters([(algorithm, dtype) for algorithm, test_dtypes in [(lax.DotAlgorithm(lhs_precision_type=np.float32, rhs_precision_type=np.float32, accumulation_type=np.float32, lhs_component_count=1, rhs_component_count=1, num_primitive_operations=1, allow_imprecise_accumulation=False), [np.float32]), (lax.DotAlgorithm(lhs_precision_type=np.float16, rhs_precision_type=np.float16, accumulation_type=np.float32), [np.float16]), ('F16_F16_F32', [np.float16]), (lax.DotAlgorithmPreset.DEFAULT, lax_test_util.float_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.F16_F16_F16, [np.float16]), (lax.DotAlgorithmPreset.F16_F16_F32, [np.float16]), (lax.DotAlgorithmPreset.BF16_BF16_BF16, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X6, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.F32_F32_F32, [np.float32]), (lax.DotAlgorithmPreset.F64_F64_F64, [np.float64])] for dtype in test_dtypes if jtu.dtypes.supported([dtype])])\ndef testDotAlgorithm(self, algorithm, dtype):\n    if jtu.test_device_matches(['cpu']):\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.F16_F16_F16, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on CPU.\")\n    if jtu.test_device_matches(['gpu']):\n        if algorithm in {lax.DotAlgorithmPreset.F16_F16_F32, lax.DotAlgorithmPreset.TF32_TF32_F32, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            if not jtu.is_cuda_compute_capability_at_least('8.0'):\n                raise SkipTest(f\"The dot algorithm '{algorithm}' requires CUDA compute capability >= 8.0.\")\n        elif algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on GPU.\")\n    if jtu.test_device_matches(['tpu']):\n        if not jtu.if_cloud_tpu_at_least(2024, 12, 19):\n            self.skipTest('Requires libtpu built after 2024-12-19')\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on TPU.\")\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    self._CompileAndCheck(partial(lax.dot, precision=algorithm), args_maker)\n    self.assertEqual(lax.dot(*args_maker(), precision=algorithm).dtype, dtype)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, dimensions=dimensions) for arg_shape, dimensions in [[(1,), (0,)], [(1,), (-1,)], [(2, 1, 4), (1,)], [(2, 1, 3, 1), (1,)], [(2, 1, 3, 1), (1, 3)], [(2, 1, 3, 1), (3,)]]])\ndef testSqueeze(self, arg_shape, dimensions):\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(arg_shape, np.float32)]\n    op = lambda x: lax.squeeze(x, dimensions)\n    numpy_op = lambda x: lax_reference.squeeze(x, dimensions)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)\n    check_grads(op, args_maker(), 3, ['fwd', 'rev'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(1, _reduce_custom_add, [np.float32]), (0, _reduce_custom_mul, [np.float32]), (0, _reduce_custom_sub, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowGeneralJVP(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(operand, init_val):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype), init_val]\n    self._CompileAndCheck(fun, args_maker)\n    args = args_maker()\n    init_val = args[1]\n\n    def fun2(operand):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CompileAndCheck(fun2, args_maker)\n    operand = args_maker()[0]\n    jtu.check_jvp(fun2, partial(jax.jvp, fun2), (operand,))\n    check_grads(fun2, (operand,), 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(-np.inf, lax.max, [np.float32]), (np.inf, lax.min, [np.float32]), (0, lax.add, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowCustomSameAsMonoid(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(op_, operand_):\n        return lax.reduce_window(operand_, init_val, op_, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    args = args_maker()\n    operand = args[0]\n    rng = np.random.RandomState(0)\n    tangent = tree_map(partial(jtu.rand_like, rng), operand)\n    custom_equiv = {lax.max: _reduce_custom_max, lax.min: _reduce_custom_min, lax.add: _reduce_custom_add}\n    custom_op = custom_equiv[op]\n    custom_primals, custom_tangents = jax.jvp(partial(fun, custom_op), primals=(operand,), tangents=(tangent,))\n    lax_primals, lax_tangents = jax.jvp(partial(fun, op), primals=(operand,), tangents=(tangent,))\n    tol = None\n    jtu.check_close(lax_primals, custom_primals, atol=tol, rtol=tol, err_msg='Mismatched primal')\n    jtu.check_close(lax_tangents, custom_tangents, atol=tol, rtol=tol, err_msg='Mismatched tangents')\n    if init_val.item() in (np.inf, -np.inf):\n        return\n    op_bound_fn = partial(fun, op)\n    jtu.check_jvp(op_bound_fn, partial(jax.jvp, op_bound_fn), (operand,))\n    check_grads(partial(fun, op), [operand], 3, ['fwd'], eps=1.0)\n    check_grads(partial(fun, custom_op), [operand], 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product(from_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, to_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, shape=[(), (2,), (2, 3)])\ndef testBitcastConvertType(self, from_dtype, to_dtype, shape):\n    rng = jtu.rand_default(self.rng())\n    nbits_in = dtypes.bit_width(from_dtype)\n    nbits_out = dtypes.bit_width(to_dtype)\n    if nbits_in < nbits_out:\n        shape = (*shape, nbits_out // nbits_in)\n    args_maker = lambda: [rng(shape, from_dtype)]\n    jnp_op = lambda x: lax.bitcast_convert_type(x, to_dtype)\n    self._CompileAndCheck(jnp_op, args_maker)\n    out = jnp_op(*args_maker())\n    if nbits_in == nbits_out:\n        expected_shape = shape\n    elif nbits_in < nbits_out:\n        expected_shape = shape[:-1]\n    else:\n        expected_shape = (*shape, nbits_in // nbits_out)\n    self.assertEqual(out.dtype, to_dtype)\n    self.assertEqual(out.shape, expected_shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def jnp_op(start, stop):\n    return jnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype, axis=axis)"
  },
  {
    "test_code": "@jtu.sample_product([dict(op=op, np_op=np_op) for op, np_op in [(lax.cumsum, np.cumsum), (lax.cumprod, np.cumprod), (lax.cummax, np.maximum.accumulate), (lax.cummin, np.minimum.accumulate)]], [dict(shape=shape, axis=axis) for shape in [[10], [3, 4, 5]] for axis in range(len(shape))], dtype=lax_test_util.default_dtypes, reverse=[False, True])\ndef testCumulativeReduce(self, op, np_op, shape, dtype, axis, reverse):\n    rng_factory = jtu.rand_default if dtypes.issubdtype(dtype, np.integer) else jtu.rand_small\n    rng = rng_factory(self.rng())\n    fun = partial(op, axis=axis, reverse=reverse)\n\n    def np_fun(x):\n        if reverse:\n            return np.flip(np_op(np.flip(x, axis), axis=axis, dtype=dtype), axis)\n        else:\n            return np_op(x, axis=axis, dtype=dtype)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CompileAndCheck(fun, args_maker)\n    self._CheckAgainstNumpy(np_fun, fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def np_op(start, stop):\n    start = start.astype(np.float32) if dtype == jnp.bfloat16 else start\n    stop = stop.astype(np.float32) if dtype == jnp.bfloat16 else stop\n    return np.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype if dtype != jnp.bfloat16 else np.float32, axis=axis).astype(dtype)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@jtu.sample_product(from_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, to_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, shape=[(), (2,), (2, 3)])\ndef testBitcastConvertType(self, from_dtype, to_dtype, shape):\n    rng = jtu.rand_default(self.rng())\n    nbits_in = dtypes.bit_width(from_dtype)\n    nbits_out = dtypes.bit_width(to_dtype)\n    if nbits_in < nbits_out:\n        shape = (*shape, nbits_out // nbits_in)\n    args_maker = lambda: [rng(shape, from_dtype)]\n    jnp_op = lambda x: lax.bitcast_convert_type(x, to_dtype)\n    self._CompileAndCheck(jnp_op, args_maker)\n    out = jnp_op(*args_maker())\n    if nbits_in == nbits_out:\n        expected_shape = shape\n    elif nbits_in < nbits_out:\n        expected_shape = shape[:-1]\n    else:\n        expected_shape = (*shape, nbits_in // nbits_out)\n    self.assertEqual(out.dtype, to_dtype)\n    self.assertEqual(out.shape, expected_shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    x = jnp.array(rng(shape, dtype))\n    if out_dtype in unsigned_dtypes:\n        x = 10 * jnp.abs(x)\n    return [x]"
  },
  {
    "test_code": "@parameterized.parameters([(algorithm, dtype) for algorithm, test_dtypes in [(lax.DotAlgorithm(lhs_precision_type=np.float32, rhs_precision_type=np.float32, accumulation_type=np.float32, lhs_component_count=1, rhs_component_count=1, num_primitive_operations=1, allow_imprecise_accumulation=False), [np.float32]), (lax.DotAlgorithm(lhs_precision_type=np.float16, rhs_precision_type=np.float16, accumulation_type=np.float32), [np.float16]), ('F16_F16_F32', [np.float16]), (lax.DotAlgorithmPreset.DEFAULT, lax_test_util.float_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.F16_F16_F16, [np.float16]), (lax.DotAlgorithmPreset.F16_F16_F32, [np.float16]), (lax.DotAlgorithmPreset.BF16_BF16_BF16, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X6, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.F32_F32_F32, [np.float32]), (lax.DotAlgorithmPreset.F64_F64_F64, [np.float64])] for dtype in test_dtypes if jtu.dtypes.supported([dtype])])\ndef testDotAlgorithm(self, algorithm, dtype):\n    if jtu.test_device_matches(['cpu']):\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.F16_F16_F16, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on CPU.\")\n    if jtu.test_device_matches(['gpu']):\n        if algorithm in {lax.DotAlgorithmPreset.F16_F16_F32, lax.DotAlgorithmPreset.TF32_TF32_F32, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            if not jtu.is_cuda_compute_capability_at_least('8.0'):\n                raise SkipTest(f\"The dot algorithm '{algorithm}' requires CUDA compute capability >= 8.0.\")\n        elif algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on GPU.\")\n    if jtu.test_device_matches(['tpu']):\n        if not jtu.if_cloud_tpu_at_least(2024, 12, 19):\n            self.skipTest('Requires libtpu built after 2024-12-19')\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on TPU.\")\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    self._CompileAndCheck(partial(lax.dot, precision=algorithm), args_maker)\n    self.assertEqual(lax.dot(*args_maker(), precision=algorithm).dtype, dtype)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    x = jnp.array(rng(shape, dtype))\n    if out_dtype in unsigned_dtypes:\n        x = 10 * jnp.abs(x)\n    return [x]"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, dimensions=dimensions) for arg_shape, dimensions in [[(1,), (0,)], [(1,), (-1,)], [(2, 1, 4), (1,)], [(2, 1, 3, 1), (1,)], [(2, 1, 3, 1), (1, 3)], [(2, 1, 3, 1), (3,)]]])\ndef testSqueeze(self, arg_shape, dimensions):\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(arg_shape, np.float32)]\n    op = lambda x: lax.squeeze(x, dimensions)\n    numpy_op = lambda x: lax_reference.squeeze(x, dimensions)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)\n    check_grads(op, args_maker(), 3, ['fwd', 'rev'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    x = jnp.array(rng(shape, dtype))\n    if out_dtype in unsigned_dtypes:\n        x = 10 * jnp.abs(x)\n    return [x]"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(1, _reduce_custom_add, [np.float32]), (0, _reduce_custom_mul, [np.float32]), (0, _reduce_custom_sub, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowGeneralJVP(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(operand, init_val):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype), init_val]\n    self._CompileAndCheck(fun, args_maker)\n    args = args_maker()\n    init_val = args[1]\n\n    def fun2(operand):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CompileAndCheck(fun2, args_maker)\n    operand = args_maker()[0]\n    jtu.check_jvp(fun2, partial(jax.jvp, fun2), (operand,))\n    check_grads(fun2, (operand,), 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    x = jnp.array(rng(shape, dtype))\n    if out_dtype in unsigned_dtypes:\n        x = 10 * jnp.abs(x)\n    return [x]"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(-np.inf, lax.max, [np.float32]), (np.inf, lax.min, [np.float32]), (0, lax.add, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowCustomSameAsMonoid(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(op_, operand_):\n        return lax.reduce_window(operand_, init_val, op_, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    args = args_maker()\n    operand = args[0]\n    rng = np.random.RandomState(0)\n    tangent = tree_map(partial(jtu.rand_like, rng), operand)\n    custom_equiv = {lax.max: _reduce_custom_max, lax.min: _reduce_custom_min, lax.add: _reduce_custom_add}\n    custom_op = custom_equiv[op]\n    custom_primals, custom_tangents = jax.jvp(partial(fun, custom_op), primals=(operand,), tangents=(tangent,))\n    lax_primals, lax_tangents = jax.jvp(partial(fun, op), primals=(operand,), tangents=(tangent,))\n    tol = None\n    jtu.check_close(lax_primals, custom_primals, atol=tol, rtol=tol, err_msg='Mismatched primal')\n    jtu.check_close(lax_tangents, custom_tangents, atol=tol, rtol=tol, err_msg='Mismatched tangents')\n    if init_val.item() in (np.inf, -np.inf):\n        return\n    op_bound_fn = partial(fun, op)\n    jtu.check_jvp(op_bound_fn, partial(jax.jvp, op_bound_fn), (operand,))\n    check_grads(partial(fun, op), [operand], 3, ['fwd'], eps=1.0)\n    check_grads(partial(fun, custom_op), [operand], 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    x = jnp.array(rng(shape, dtype))\n    if out_dtype in unsigned_dtypes:\n        x = 10 * jnp.abs(x)\n    return [x]"
  },
  {
    "test_code": "@jtu.sample_product([dict(op=op, np_op=np_op) for op, np_op in [(lax.cumsum, np.cumsum), (lax.cumprod, np.cumprod), (lax.cummax, np.maximum.accumulate), (lax.cummin, np.minimum.accumulate)]], [dict(shape=shape, axis=axis) for shape in [[10], [3, 4, 5]] for axis in range(len(shape))], dtype=lax_test_util.default_dtypes, reverse=[False, True])\ndef testCumulativeReduce(self, op, np_op, shape, dtype, axis, reverse):\n    rng_factory = jtu.rand_default if dtypes.issubdtype(dtype, np.integer) else jtu.rand_small\n    rng = rng_factory(self.rng())\n    fun = partial(op, axis=axis, reverse=reverse)\n\n    def np_fun(x):\n        if reverse:\n            return np.flip(np_op(np.flip(x, axis), axis=axis, dtype=dtype), axis)\n        else:\n            return np_op(x, axis=axis, dtype=dtype)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CompileAndCheck(fun, args_maker)\n    self._CheckAgainstNumpy(np_fun, fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def np_op(x, axis=None, dtype=None, include_initial=False):\n    axis = axis or 0\n    out = np.cumprod(x, axis=axis, dtype=dtype or x.dtype)\n    if include_initial:\n        ones_shape = list(x.shape)\n        ones_shape[axis] = 1\n        out = jnp.concat([jnp.ones(ones_shape, dtype=out.dtype), out], axis=axis)\n    return out"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_composite_attribute_dtypes(self):\n\n    @jax.jit\n    def my_tangent_composite_with_attributes(x):\n\n        def decomposition(x, **_):\n            return lax.sin(x) / lax.cos(x)\n        return lax.composite(decomposition, 'my.tangent')(x, dtype=np.dtype(np.float32), int=1, omit=None, str='bar', tensor=np.zeros((1, 2), dtype=np.float32), tensor_r1=np.zeros((2,), dtype=np.float32))\n    pi = jnp.pi\n    x = jnp.array([0.0, pi / 4, 3 * pi / 4, pi], dtype=jnp.float32)\n    output = my_tangent_composite_with_attributes(x)\n    self.assertArraysAllClose(output, jnp.array([0.0, 1.0, -1.0, 0.0], dtype=jnp.float32))\n    mlir_module = my_tangent_composite_with_attributes.lower(x).as_text()\n    self.assertIn('stablehlo.composite \"my.tangent\" %arg0 {composite_attributes = {dtype = f32, int = 1 : i64, str = \"bar\", tensor = dense<0.000000e+00> : tensor<1x2xf32>, tensor_r1 = dense<0.000000e+00> : tensor<2xf32>}, decomposition = @my.tangent} : (tensor<4xf32>) -> tensor<4xf32>', mlir_module)\n    self.assertIn('func.func private @my.tangent', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_jvp\ndef sin(x):\n    return jax.pure_callback(np.sin, x, x)"
  },
  {
    "test_code": "def test_composite_unsupported_attribute_dtypes(self):\n\n    def my_tangent_composite_with_attributes(x):\n\n        def decomposition(x, **_):\n            return lax.sin(x) / lax.cos(x)\n        return lax.composite(decomposition, 'my.tangent')(x, tensor=jnp.zeros((1, 2), dtype=jnp.float32))\n    pi = jnp.pi\n    x = jnp.array([0.0, pi / 4, 3 * pi / 4, pi], dtype=jnp.float32)\n    with self.assertRaisesRegex(UnexpectedTracerError, 'Note: If you are passing jax arrays as attributes, use numpy arrays instead.'):\n        jax.jit(my_tangent_composite_with_attributes).lower(x).as_text()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_jvp\ndef sin(x):\n    return jax.pure_callback(np.sin, x, x)"
  },
  {
    "test_code": "def testDotAlgorithmCasting(self):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('F32_F32_F32 is not supported on TPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F32_F32_F32')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertEqual(fun(lhs, rhs).dtype, np.float16)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun(x):\n    self.assertEqual(x.dtype, jnp.complex64)\n    out_type = (jax.ShapeDtypeStruct(x.shape[:-1], x.dtype), jax.ShapeDtypeStruct(x.shape, x.dtype))\n    return jax.pure_callback(callback, out_type, x)"
  },
  {
    "test_code": "@jtu.sample_product(op=['add', 'mul'], op_namespace=[lax, operator], arr_weak_type=[False, True], init_weak_type=[False, True])\ndef testReduceWeakType(self, op_namespace, op, arr_weak_type, init_weak_type):\n    op = getattr(op_namespace, op)\n    arr = lax_internal._convert_element_type(np.arange(10), int, weak_type=arr_weak_type)\n    init = lax_internal._convert_element_type(1, int, weak_type=init_weak_type)\n    fun = lambda arr, init: lax.reduce(arr, init, op, (0,))\n    out = fun(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out), arr_weak_type and init_weak_type)\n    out_jit = jax.jit(fun)(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), arr_weak_type and init_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun(x):\n    self.assertEqual(x.dtype, jnp.complex64)\n    out_type = (jax.ShapeDtypeStruct(x.shape[:-1], x.dtype), jax.ShapeDtypeStruct(x.shape, x.dtype))\n    return jax.pure_callback(callback, out_type, x)"
  },
  {
    "test_code": "def test_composite_with_tracer_consts(self):\n\n    def fun(x, scale):\n\n        @partial(lax.composite, name='my.consts')\n        def my_consts(y):\n            return jnp.round(y / scale)\n        return my_consts(x)\n    scale = jnp.array([0.5, 0.4, 0.3], dtype=jnp.float32)\n    x = jnp.array([1.0, 2.0, 3.0], dtype=jnp.float32)\n    self.assertAllClose(fun(x, scale), jnp.round(x / scale))\n    self.assertAllClose(jax.jit(partial(fun, scale=scale))(x), jnp.round(x / scale))\n    with self.assertRaisesRegex(UnexpectedTracerError, \"Found a JAX Tracer as a constant in the decomposition for the composite op 'my.consts'.\"):\n        jax.jit(fun)(x, scale)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun(x):\n    self.assertEqual(x.dtype, jnp.complex64)\n    out_type = (jax.ShapeDtypeStruct(x.shape[:-1], x.dtype), jax.ShapeDtypeStruct(x.shape, x.dtype))\n    return jax.pure_callback(callback, out_type, x)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "@jtu.sample_product(from_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, to_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, shape=[(), (2,), (2, 3)])\ndef testBitcastConvertType(self, from_dtype, to_dtype, shape):\n    rng = jtu.rand_default(self.rng())\n    nbits_in = dtypes.bit_width(from_dtype)\n    nbits_out = dtypes.bit_width(to_dtype)\n    if nbits_in < nbits_out:\n        shape = (*shape, nbits_out // nbits_in)\n    args_maker = lambda: [rng(shape, from_dtype)]\n    jnp_op = lambda x: lax.bitcast_convert_type(x, to_dtype)\n    self._CompileAndCheck(jnp_op, args_maker)\n    out = jnp_op(*args_maker())\n    if nbits_in == nbits_out:\n        expected_shape = shape\n    elif nbits_in < nbits_out:\n        expected_shape = shape[:-1]\n    else:\n        expected_shape = (*shape, nbits_in // nbits_out)\n    self.assertEqual(out.dtype, to_dtype)\n    self.assertEqual(out.shape, expected_shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    factor_shape = shape[:-1] + (2 * shape[-1],)\n    a = rng(factor_shape, dtype)\n    return [np.matmul(a, jnp.conj(T(a)))]"
  },
  {
    "test_code": "@parameterized.parameters([(algorithm, dtype) for algorithm, test_dtypes in [(lax.DotAlgorithm(lhs_precision_type=np.float32, rhs_precision_type=np.float32, accumulation_type=np.float32, lhs_component_count=1, rhs_component_count=1, num_primitive_operations=1, allow_imprecise_accumulation=False), [np.float32]), (lax.DotAlgorithm(lhs_precision_type=np.float16, rhs_precision_type=np.float16, accumulation_type=np.float32), [np.float16]), ('F16_F16_F32', [np.float16]), (lax.DotAlgorithmPreset.DEFAULT, lax_test_util.float_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.F16_F16_F16, [np.float16]), (lax.DotAlgorithmPreset.F16_F16_F32, [np.float16]), (lax.DotAlgorithmPreset.BF16_BF16_BF16, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X6, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.F32_F32_F32, [np.float32]), (lax.DotAlgorithmPreset.F64_F64_F64, [np.float64])] for dtype in test_dtypes if jtu.dtypes.supported([dtype])])\ndef testDotAlgorithm(self, algorithm, dtype):\n    if jtu.test_device_matches(['cpu']):\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.F16_F16_F16, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on CPU.\")\n    if jtu.test_device_matches(['gpu']):\n        if algorithm in {lax.DotAlgorithmPreset.F16_F16_F32, lax.DotAlgorithmPreset.TF32_TF32_F32, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            if not jtu.is_cuda_compute_capability_at_least('8.0'):\n                raise SkipTest(f\"The dot algorithm '{algorithm}' requires CUDA compute capability >= 8.0.\")\n        elif algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on GPU.\")\n    if jtu.test_device_matches(['tpu']):\n        if not jtu.if_cloud_tpu_at_least(2024, 12, 19):\n            self.skipTest('Requires libtpu built after 2024-12-19')\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on TPU.\")\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    self._CompileAndCheck(partial(lax.dot, precision=algorithm), args_maker)\n    self.assertEqual(lax.dot(*args_maker(), precision=algorithm).dtype, dtype)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    factor_shape = shape[:-1] + (2 * shape[-1],)\n    a = rng(factor_shape, dtype)\n    return [np.matmul(a, jnp.conj(T(a)))]"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, dimensions=dimensions) for arg_shape, dimensions in [[(1,), (0,)], [(1,), (-1,)], [(2, 1, 4), (1,)], [(2, 1, 3, 1), (1,)], [(2, 1, 3, 1), (1, 3)], [(2, 1, 3, 1), (3,)]]])\ndef testSqueeze(self, arg_shape, dimensions):\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(arg_shape, np.float32)]\n    op = lambda x: lax.squeeze(x, dimensions)\n    numpy_op = lambda x: lax_reference.squeeze(x, dimensions)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)\n    check_grads(op, args_maker(), 3, ['fwd', 'rev'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    factor_shape = shape[:-1] + (2 * shape[-1],)\n    a = rng(factor_shape, dtype)\n    return [np.matmul(a, jnp.conj(T(a)))]"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(1, _reduce_custom_add, [np.float32]), (0, _reduce_custom_mul, [np.float32]), (0, _reduce_custom_sub, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowGeneralJVP(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(operand, init_val):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype), init_val]\n    self._CompileAndCheck(fun, args_maker)\n    args = args_maker()\n    init_val = args[1]\n\n    def fun2(operand):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CompileAndCheck(fun2, args_maker)\n    operand = args_maker()[0]\n    jtu.check_jvp(fun2, partial(jax.jvp, fun2), (operand,))\n    check_grads(fun2, (operand,), 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    factor_shape = shape[:-1] + (2 * shape[-1],)\n    a = rng(factor_shape, dtype)\n    return [np.matmul(a, jnp.conj(T(a)))]"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(-np.inf, lax.max, [np.float32]), (np.inf, lax.min, [np.float32]), (0, lax.add, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowCustomSameAsMonoid(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(op_, operand_):\n        return lax.reduce_window(operand_, init_val, op_, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    args = args_maker()\n    operand = args[0]\n    rng = np.random.RandomState(0)\n    tangent = tree_map(partial(jtu.rand_like, rng), operand)\n    custom_equiv = {lax.max: _reduce_custom_max, lax.min: _reduce_custom_min, lax.add: _reduce_custom_add}\n    custom_op = custom_equiv[op]\n    custom_primals, custom_tangents = jax.jvp(partial(fun, custom_op), primals=(operand,), tangents=(tangent,))\n    lax_primals, lax_tangents = jax.jvp(partial(fun, op), primals=(operand,), tangents=(tangent,))\n    tol = None\n    jtu.check_close(lax_primals, custom_primals, atol=tol, rtol=tol, err_msg='Mismatched primal')\n    jtu.check_close(lax_tangents, custom_tangents, atol=tol, rtol=tol, err_msg='Mismatched tangents')\n    if init_val.item() in (np.inf, -np.inf):\n        return\n    op_bound_fn = partial(fun, op)\n    jtu.check_jvp(op_bound_fn, partial(jax.jvp, op_bound_fn), (operand,))\n    check_grads(partial(fun, op), [operand], 3, ['fwd'], eps=1.0)\n    check_grads(partial(fun, custom_op), [operand], 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    factor_shape = shape[:-1] + (2 * shape[-1],)\n    a = rng(factor_shape, dtype)\n    return [np.matmul(a, jnp.conj(T(a)))]"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, dimensions=dimensions) for arg_shape, dimensions in [[(1,), (0,)], [(1,), (-1,)], [(2, 1, 4), (1,)], [(2, 1, 3, 1), (1,)], [(2, 1, 3, 1), (1, 3)], [(2, 1, 3, 1), (3,)]]])\ndef testSqueeze(self, arg_shape, dimensions):\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(arg_shape, np.float32)]\n    op = lambda x: lax.squeeze(x, dimensions)\n    numpy_op = lambda x: lax_reference.squeeze(x, dimensions)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)\n    check_grads(op, args_maker(), 3, ['fwd', 'rev'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def check_grads(f, args, order, atol=None, rtol=None, eps=None):\n    default_tol = 1e-06 if config.enable_x64.value else 0.01\n    atol = atol or default_tol\n    rtol = rtol or default_tol\n    eps = eps or default_tol\n    jtu.check_jvp(f, partial(jax.jvp, f), args, atol, rtol, eps)\n    jtu.check_vjp(f, partial(jax.vjp, f), args, atol, rtol, eps)"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(1, _reduce_custom_add, [np.float32]), (0, _reduce_custom_mul, [np.float32]), (0, _reduce_custom_sub, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowGeneralJVP(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(operand, init_val):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype), init_val]\n    self._CompileAndCheck(fun, args_maker)\n    args = args_maker()\n    init_val = args[1]\n\n    def fun2(operand):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CompileAndCheck(fun2, args_maker)\n    operand = args_maker()[0]\n    jtu.check_jvp(fun2, partial(jax.jvp, fun2), (operand,))\n    check_grads(fun2, (operand,), 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def check_grads(f, args, order, atol=None, rtol=None, eps=None):\n    default_tol = 1e-06 if config.enable_x64.value else 0.01\n    atol = atol or default_tol\n    rtol = rtol or default_tol\n    eps = eps or default_tol\n    jtu.check_jvp(f, partial(jax.jvp, f), args, atol, rtol, eps)\n    jtu.check_vjp(f, partial(jax.vjp, f), args, atol, rtol, eps)"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(-np.inf, lax.max, [np.float32]), (np.inf, lax.min, [np.float32]), (0, lax.add, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowCustomSameAsMonoid(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(op_, operand_):\n        return lax.reduce_window(operand_, init_val, op_, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    args = args_maker()\n    operand = args[0]\n    rng = np.random.RandomState(0)\n    tangent = tree_map(partial(jtu.rand_like, rng), operand)\n    custom_equiv = {lax.max: _reduce_custom_max, lax.min: _reduce_custom_min, lax.add: _reduce_custom_add}\n    custom_op = custom_equiv[op]\n    custom_primals, custom_tangents = jax.jvp(partial(fun, custom_op), primals=(operand,), tangents=(tangent,))\n    lax_primals, lax_tangents = jax.jvp(partial(fun, op), primals=(operand,), tangents=(tangent,))\n    tol = None\n    jtu.check_close(lax_primals, custom_primals, atol=tol, rtol=tol, err_msg='Mismatched primal')\n    jtu.check_close(lax_tangents, custom_tangents, atol=tol, rtol=tol, err_msg='Mismatched tangents')\n    if init_val.item() in (np.inf, -np.inf):\n        return\n    op_bound_fn = partial(fun, op)\n    jtu.check_jvp(op_bound_fn, partial(jax.jvp, op_bound_fn), (operand,))\n    check_grads(partial(fun, op), [operand], 3, ['fwd'], eps=1.0)\n    check_grads(partial(fun, custom_op), [operand], 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def check_grads(f, args, order, atol=None, rtol=None, eps=None):\n    default_tol = 1e-06 if config.enable_x64.value else 0.01\n    atol = atol or default_tol\n    rtol = rtol or default_tol\n    eps = eps or default_tol\n    jtu.check_jvp(f, partial(jax.jvp, f), args, atol, rtol, eps)\n    jtu.check_vjp(f, partial(jax.vjp, f), args, atol, rtol, eps)"
  },
  {
    "test_code": "@jtu.sample_product(index_dtype=jtu.dtypes.all_inexact + jtu.dtypes.boolean, jax_fn=[lax.argmin, lax.argmax])\ndef testArgMinMaxIndexDtypeError(self, jax_fn, index_dtype):\n    with self.assertRaisesRegex(TypeError, 'index_dtype must be an integer type'):\n        jax_fn(np.ones((2, 2)), axis=0, index_dtype=index_dtype)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def jax_fn(op, indexer, x, y, indices_are_sorted=False, unique_indices=False, mode=None):\n    x = jnp.array(x)\n    return {UpdateOps.UPDATE: x.at[indexer].set, UpdateOps.ADD: x.at[indexer].add, UpdateOps.SUB: x.at[indexer].subtract, UpdateOps.MUL: x.at[indexer].multiply, UpdateOps.DIV: x.at[indexer].divide, UpdateOps.POW: x.at[indexer].power, UpdateOps.MIN: x.at[indexer].min, UpdateOps.MAX: x.at[indexer].max}[op](y, indices_are_sorted=indices_are_sorted, unique_indices=unique_indices, mode=mode)"
  },
  {
    "test_code": "@parameterized.parameters([lax.argmin, lax.argmax])\ndef testArgMinMaxEmptyError(self, jax_fn):\n    with self.assertRaisesRegex(ValueError, 'require non-empty reduced dimension'):\n        jax_fn(np.ones((0, 2)), axis=0, index_dtype=np.int32)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def jax_fn(op, indexer, x, y, indices_are_sorted=False, unique_indices=False, mode=None):\n    x = jnp.array(x)\n    return {UpdateOps.UPDATE: x.at[indexer].set, UpdateOps.ADD: x.at[indexer].add, UpdateOps.SUB: x.at[indexer].subtract, UpdateOps.MUL: x.at[indexer].multiply, UpdateOps.DIV: x.at[indexer].divide, UpdateOps.POW: x.at[indexer].power, UpdateOps.MIN: x.at[indexer].min, UpdateOps.MAX: x.at[indexer].max}[op](y, indices_are_sorted=indices_are_sorted, unique_indices=unique_indices, mode=mode)"
  },
  {
    "test_code": "@parameterized.parameters([lax.argmin, lax.argmax])\ndef testArgMinMaxInvalidAxisError(self, jax_fn):\n    with self.assertRaisesRegex(ValueError, 'Invalid axis -1 for operand'):\n        jax_fn(np.ones((2, 3)), axis=-1, index_dtype=np.int32)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def jax_fn(op, indexer, x, y, indices_are_sorted=False, unique_indices=False, mode=None):\n    x = jnp.array(x)\n    return {UpdateOps.UPDATE: x.at[indexer].set, UpdateOps.ADD: x.at[indexer].add, UpdateOps.SUB: x.at[indexer].subtract, UpdateOps.MUL: x.at[indexer].multiply, UpdateOps.DIV: x.at[indexer].divide, UpdateOps.POW: x.at[indexer].power, UpdateOps.MIN: x.at[indexer].min, UpdateOps.MAX: x.at[indexer].max}[op](y, indices_are_sorted=indices_are_sorted, unique_indices=unique_indices, mode=mode)"
  },
  {
    "test_code": "@jtu.sample_product(jax_fn=[lax.argmin, lax.argmax], weak_type=[False, True])\ndef testArgMinMaxWeakType(self, jax_fn, weak_type):\n    op = lambda x: jax_fn(x, axis=0, index_dtype=np.int32)\n    x_in = lax_internal._convert_element_type(np.ones((2, 2)), weak_type=weak_type)\n    self.assertEqual(dtypes.is_weakly_typed(x_in), weak_type)\n    x_out = op(x_in)\n    self.assertEqual(dtypes.is_weakly_typed(x_out), False)\n    x_out_jit = jax.jit(op)(x_in)\n    self.assertEqual(dtypes.is_weakly_typed(x_out_jit), False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def jax_fn(op, indexer, x, y, indices_are_sorted=False, unique_indices=False, mode=None):\n    x = jnp.array(x)\n    return {UpdateOps.UPDATE: x.at[indexer].set, UpdateOps.ADD: x.at[indexer].add, UpdateOps.SUB: x.at[indexer].subtract, UpdateOps.MUL: x.at[indexer].multiply, UpdateOps.DIV: x.at[indexer].divide, UpdateOps.POW: x.at[indexer].power, UpdateOps.MIN: x.at[indexer].min, UpdateOps.MAX: x.at[indexer].max}[op](y, indices_are_sorted=indices_are_sorted, unique_indices=unique_indices, mode=mode)"
  },
  {
    "test_code": "@jtu.sample_product(from_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, to_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, shape=[(), (2,), (2, 3)])\ndef testBitcastConvertType(self, from_dtype, to_dtype, shape):\n    rng = jtu.rand_default(self.rng())\n    nbits_in = dtypes.bit_width(from_dtype)\n    nbits_out = dtypes.bit_width(to_dtype)\n    if nbits_in < nbits_out:\n        shape = (*shape, nbits_out // nbits_in)\n    args_maker = lambda: [rng(shape, from_dtype)]\n    jnp_op = lambda x: lax.bitcast_convert_type(x, to_dtype)\n    self._CompileAndCheck(jnp_op, args_maker)\n    out = jnp_op(*args_maker())\n    if nbits_in == nbits_out:\n        expected_shape = shape\n    elif nbits_in < nbits_out:\n        expected_shape = shape[:-1]\n    else:\n        expected_shape = (*shape, nbits_in // nbits_out)\n    self.assertEqual(out.dtype, to_dtype)\n    self.assertEqual(out.shape, expected_shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def jnp_op(x, idx):\n    return jnp.asarray(x).at[idx].apply(jnp_func)"
  },
  {
    "test_code": "def testDotAlgorithmCasting(self):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('F32_F32_F32 is not supported on TPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F32_F32_F32')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertEqual(fun(lhs, rhs).dtype, np.float16)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef fun(unpacked_indexer, x):\n    indexer = pack_indexer(unpacked_indexer)\n    return x[indexer]"
  },
  {
    "test_code": "@jtu.sample_product(op=['add', 'mul'], op_namespace=[lax, operator], arr_weak_type=[False, True], init_weak_type=[False, True])\ndef testReduceWeakType(self, op_namespace, op, arr_weak_type, init_weak_type):\n    op = getattr(op_namespace, op)\n    arr = lax_internal._convert_element_type(np.arange(10), int, weak_type=arr_weak_type)\n    init = lax_internal._convert_element_type(1, int, weak_type=init_weak_type)\n    fun = lambda arr, init: lax.reduce(arr, init, op, (0,))\n    out = fun(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out), arr_weak_type and init_weak_type)\n    out_jit = jax.jit(fun)(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), arr_weak_type and init_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef fun(unpacked_indexer, x):\n    indexer = pack_indexer(unpacked_indexer)\n    return x[indexer]"
  },
  {
    "test_code": "def test_composite_with_tracer_consts(self):\n\n    def fun(x, scale):\n\n        @partial(lax.composite, name='my.consts')\n        def my_consts(y):\n            return jnp.round(y / scale)\n        return my_consts(x)\n    scale = jnp.array([0.5, 0.4, 0.3], dtype=jnp.float32)\n    x = jnp.array([1.0, 2.0, 3.0], dtype=jnp.float32)\n    self.assertAllClose(fun(x, scale), jnp.round(x / scale))\n    self.assertAllClose(jax.jit(partial(fun, scale=scale))(x), jnp.round(x / scale))\n    with self.assertRaisesRegex(UnexpectedTracerError, \"Found a JAX Tracer as a constant in the decomposition for the composite op 'my.consts'.\"):\n        jax.jit(fun)(x, scale)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef fun(unpacked_indexer, x):\n    indexer = pack_indexer(unpacked_indexer)\n    return x[indexer]"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fn(data, segment_ids):\n    return jax.ops.segment_sum(data, segment_ids, num_segments).sum()"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@compute_on('device_host')\ndef fn():\n    k = jax.random.key(0)\n    return jax.nn.initializers.lecun_normal()(k, (2, 2), jnp.float32)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@compute_on('device_host')\n@jax.jit\ndef eq(x, y):\n    return (x == y).astype(jnp.float32)"
  },
  {
    "test_code": "def test_equality(self):\n    eq = jax.jit(lambda k1, k2: k1 == k2)\n    ne = jax.jit(lambda k1, k2: k1 != k2)\n    k1 = jax.jit(lambda: make(()))()\n    k2 = jax.jit(lambda: jake(make(())))()\n    self.assertTrue(eq(k1, k1))\n    self.assertFalse(eq(k1, k2))\n    self.assertTrue(ne(k1, k2))\n    self.assertFalse(ne(k1, k1))\n    size = 5\n    idx = slice(2, 4)\n    ks = jax.jit(lambda k: jake(make((size,))).at[idx].set(k))(k1)\n    expected = jnp.zeros(size, dtype=bool).at[idx].set(True)\n    self.assertArraysEqual(eq(k1, ks), expected)\n    self.assertArraysEqual(ne(k1, ks), ~expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@compute_on('device_host')\n@jax.jit\ndef eq(x, y):\n    return (x == y).astype(jnp.float32)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "@jtu.sample_product([dict(lhs_shape=lhs_shape, filter_shape=filter_shape, strides=strides, padding=padding, dimension_numbers=dim_nums) for lhs_shape, filter_shape, strides, padding, dim_nums in [((2, 5), (), (), [], ('NC', 'OI', 'CN')), ((2, 3, 4), (2,), (2,), [(0, 2)], ('CNH', 'OHI', 'HNC')), ((3, 1, 4, 5), (1, 3), (1, 3), [(3, 1), (2, 2)], ('NCHW', 'OIHW', 'NCHW')), ((3, 2, 5, 6), (4, 3), (4, 3), [(5, 2), (2, 4)], None), ((1, 2, 3, 4), (1, 1), (1, 1), [(0, 0), (0, 0)], ('NCWH', 'OHWI', 'CNHW')), ((1, 2, 3, 4), (3, 2), (1, 1), [(0, 0), (0, 0)], ('CWHN', 'HOWI', 'NCHW')), ((2, 3, 4, 5, 6), (2, 1, 3), (2, 1, 3), [(1, 2), (5, 3), (3, 5)], ('NHWDC', 'HDIWO', 'DCWNH'))]], dtype=lax_test_util.all_dtypes, precision=[None, lax.Precision.DEFAULT, lax.Precision.HIGH, lax.Precision.HIGHEST])\ndef testConvGeneralDilatedPatchesNonOverlapping(self, lhs_shape, filter_shape, dtype, strides, padding, dimension_numbers, precision):\n    if np.issubdtype(dtype, np.integer) or np.issubdtype(dtype, np.bool_):\n        if jtu.test_device_matches(['gpu']):\n            raise SkipTest('Integer convolution not yet supported on GPU')\n    rng = jtu.rand_small(self.rng())\n    lhs = rng(lhs_shape, dtype)\n    if dimension_numbers is None:\n        lhs_spec, rhs_spec, out_spec = ('NCHW', 'OIHW', 'NCHW')\n    else:\n        lhs_spec, rhs_spec, out_spec = dimension_numbers\n    filter_spec = ''.join((c for c in rhs_spec if c not in ('I', 'O')))\n    patches_spec = out_spec.replace('C', 'C' + filter_spec.lower())\n    full_padding = []\n    for c in lhs_spec:\n        if c in ('N', 'C'):\n            full_padding += [(0, 0)]\n        else:\n            full_padding += [padding[filter_spec.index(c)]]\n    lhs_padded = np.pad(lhs, full_padding, 'constant')\n    out = lax.transpose(lhs_padded, [lhs_spec.index(c) for c in out_spec])\n    patches = lax.conv_general_dilated_patches(lhs=lhs, filter_shape=filter_shape, window_strides=strides, padding=padding, dimension_numbers=dimension_numbers, precision=precision)\n    source = []\n    for c in out_spec:\n        out_c = out.shape[out_spec.index(c)]\n        patch_c = patches.shape[out_spec.index(c)]\n        if c == 'N':\n            self.assertEqual(out_c, patch_c)\n        elif c == 'C':\n            self.assertEqual(out_c * math.prod(filter_shape), patch_c)\n        else:\n            self.assertEqual(out_c, patch_c * filter_shape[filter_spec.index(c)])\n            source += [patches_spec.index(c), patches_spec.index(c.lower())]\n    c = out_spec.index('C')\n    patches = patches.reshape(patches.shape[:c] + (lhs_shape[lhs_spec.index('C')],) + filter_shape + patches.shape[c + 1:])\n    patches = np.moveaxis(patches, source, range(len(source)))\n    for i in range(len(filter_shape)):\n        patches = patches.reshape(patches.shape[:i] + (-1,) + patches.shape[2 + i:])\n    patches = np.moveaxis(patches, range(len(filter_shape)), [out_spec.index(c) for c in out_spec if c not in ('N', 'C')])\n    tol = None\n    if jtu.test_device_matches(['tpu']) and precision in (None, lax.Precision.DEFAULT):\n        tol = 0.001\n    self.assertAllClose(out, patches, atol=tol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def testDotAlgorithmAllowedOutputStorage(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Only supported on GPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F16_F16_F32', preferred_element_type=np.float16)\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertNotIn('convert', jax.jit(fun).lower(lhs, rhs).as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def testDotAlgorithmConfig(self):\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float32), rng(rhs_shape, np.float32))\n    expected = 'algorithm = <lhs_precision_type = f32, rhs_precision_type = f32, accumulation_type = f32'\n    with jax.default_matmul_precision('F32_F32_F32'):\n        hlo = jax.jit(lax.dot).lower(lhs, rhs).as_text()\n        self.assertRegex(hlo, expected)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_composite(self):\n\n    def my_square_impl(x):\n        return x ** 2\n    my_square = lax.composite(my_square_impl, name='my.square')\n    x = jnp.array(2.0, dtype=jnp.float32)\n    output = my_square(x)\n    self.assertEqual(output, jnp.array(4.0, dtype=jnp.float32))\n    mlir_module = jax.jit(my_square).lower(x).as_text()\n    self.assertIn('stablehlo.composite \"my.square\" %arg0 {decomposition = @my.square} : (tensor<f32>) -> tensor<f32>', mlir_module)\n    self.assertIn('@my.square(%arg0: tensor<f32>) -> tensor<f32> {', mlir_module)\n    self.assertIn('stablehlo.multiply %arg0, %arg0 : tensor<f32>', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_composite_decorator(self):\n\n    @partial(lax.composite, name='my.square')\n    def my_square(x):\n        return x ** 2\n    x = jnp.array(2.0, dtype=jnp.float32)\n    output = my_square(x)\n    self.assertEqual(output, jnp.array(4.0, dtype=jnp.float32))\n    mlir_module = jax.jit(my_square).lower(x).as_text()\n    self.assertIn('stablehlo.composite \"my.square\" %arg0 {decomposition = @my.square} : (tensor<f32>) -> tensor<f32>', mlir_module)\n    self.assertIn('@my.square(%arg0: tensor<f32>) -> tensor<f32> {', mlir_module)\n    self.assertIn('stablehlo.multiply %arg0, %arg0 : tensor<f32>', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_composite_with_jit_function(self):\n\n    def my_square_impl(x):\n        return x ** 2\n    my_square = jax.jit(lax.composite(my_square_impl, name='my.square'))\n    x = jnp.array(2.0, dtype=jnp.float32)\n    output = my_square(x)\n    self.assertEqual(output, jnp.array(4.0, dtype=jnp.float32))\n    mlir_module = my_square.lower(x).as_text()\n    self.assertIn('stablehlo.composite \"my.square\" %arg0 {decomposition = @my.square} : (tensor<f32>) -> tensor<f32>', mlir_module)\n    self.assertIn('@my.square(%arg0: tensor<f32>) -> tensor<f32> {', mlir_module)\n    self.assertIn('stablehlo.multiply %arg0, %arg0 : tensor<f32>', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_composite_with_attributes(self):\n\n    @partial(jax.jit, static_argnames=['k'])\n    @partial(lax.composite, name='my.top_k')\n    def my_top_k(x, *, k):\n        return lax.top_k(x, k)\n    x = jnp.array([1.0, 2.0, 3.0, 4.0, 5.0], dtype=jnp.float32)\n    output, indices = my_top_k(x, k=3)\n    self.assertArraysEqual(output, jnp.array([5.0, 4.0, 3.0], dtype=jnp.float32))\n    self.assertArraysEqual(indices, jnp.array([4, 3, 2], dtype=jnp.int32))\n    mlir_module = my_top_k.lower(x, k=3).as_text()\n    self.assertIn('stablehlo.composite \"my.top_k\" %arg0 {composite_attributes = {k = 3 : i64}, decomposition = @my.top_k} : (tensor<5xf32>) -> (tensor<3xf32>, tensor<3xi32>)', mlir_module)\n    self.assertIn('@my.top_k(%arg0: tensor<5xf32>) -> (tensor<3xf32>, tensor<3xi32>) {', mlir_module)\n    self.assertIn('chlo.top_k(%arg0, k = 3) : tensor<5xf32> -> (tensor<3xf32>, tensor<3xi32>)', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_composite_attribute_dtypes(self):\n\n    @jax.jit\n    def my_tangent_composite_with_attributes(x):\n\n        def decomposition(x, **_):\n            return lax.sin(x) / lax.cos(x)\n        return lax.composite(decomposition, 'my.tangent')(x, dtype=np.dtype(np.float32), int=1, omit=None, str='bar', tensor=np.zeros((1, 2), dtype=np.float32), tensor_r1=np.zeros((2,), dtype=np.float32))\n    pi = jnp.pi\n    x = jnp.array([0.0, pi / 4, 3 * pi / 4, pi], dtype=jnp.float32)\n    output = my_tangent_composite_with_attributes(x)\n    self.assertArraysAllClose(output, jnp.array([0.0, 1.0, -1.0, 0.0], dtype=jnp.float32))\n    mlir_module = my_tangent_composite_with_attributes.lower(x).as_text()\n    self.assertIn('stablehlo.composite \"my.tangent\" %arg0 {composite_attributes = {dtype = f32, int = 1 : i64, str = \"bar\", tensor = dense<0.000000e+00> : tensor<1x2xf32>, tensor_r1 = dense<0.000000e+00> : tensor<2xf32>}, decomposition = @my.tangent} : (tensor<4xf32>) -> tensor<4xf32>', mlir_module)\n    self.assertIn('func.func private @my.tangent', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_composite_unsupported_attribute_dtypes(self):\n\n    def my_tangent_composite_with_attributes(x):\n\n        def decomposition(x, **_):\n            return lax.sin(x) / lax.cos(x)\n        return lax.composite(decomposition, 'my.tangent')(x, tensor=jnp.zeros((1, 2), dtype=jnp.float32))\n    pi = jnp.pi\n    x = jnp.array([0.0, pi / 4, 3 * pi / 4, pi], dtype=jnp.float32)\n    with self.assertRaisesRegex(UnexpectedTracerError, 'Note: If you are passing jax arrays as attributes, use numpy arrays instead.'):\n        jax.jit(my_tangent_composite_with_attributes).lower(x).as_text()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_composite_with_non_default_version(self):\n\n    @partial(lax.composite, name='my.square', version=1)\n    def my_square_with_version(x):\n        return x ** 2\n    x = jnp.array(2.0, dtype=jnp.float32)\n    out = my_square_with_version(x)\n    self.assertEqual(out, 4.0)\n    mlir_module = jax.jit(my_square_with_version).lower(x).as_text()\n    self.assertIn('stablehlo.composite \"my.square\" %arg0 {decomposition = @my.square, version = 1 : i32} : (tensor<f32>) -> tensor<f32>', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_composite_with_no_args(self):\n\n    @partial(lax.composite, name='my.one')\n    def one():\n        return jnp.array(1.0, dtype=jnp.float32)\n    out = one()\n    self.assertEqual(out, jnp.array(1.0, dtype=jnp.float32))\n    mlir_module = jax.jit(one).lower().as_text()\n    self.assertIn('stablehlo.composite \"my.one\"', mlir_module)\n    self.assertIn('{decomposition = @my.one} : () -> tensor<f32>', mlir_module)\n    self.assertIn('@my.one() -> tensor<f32>', mlir_module)\n    self.assertIn('stablehlo.constant dense<1.000000e+00> : tensor<f32>', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_composite_with_variadic_input_output(self):\n\n    @partial(lax.composite, name='my.ident')\n    def ident(*args):\n        return args\n    x = jnp.array(1.0, dtype=jnp.float32)\n    y = jnp.array(2.0, dtype=jnp.float32)\n    z = jnp.array(3.0, dtype=jnp.float32)\n    a, b, c = ident(x, y, z)\n    self.assertEqual(a, x)\n    self.assertEqual(b, y)\n    self.assertEqual(c, z)\n    mlir_module = jax.jit(ident).lower(x, y, z).as_text()\n    self.assertIn('stablehlo.composite \"my.ident\" %arg0, %arg1, %arg2 {decomposition = @my.ident} : (tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<f32>, tensor<f32>, tensor<f32>)', mlir_module)\n    self.assertIn('@my.ident(%arg0: tensor<f32>, %arg1: tensor<f32>, %arg2: tensor<f32>) -> (tensor<f32>, tensor<f32>, tensor<f32>)', mlir_module)\n    self.assertIn('return %arg0, %arg1, %arg2 : tensor<f32>, tensor<f32>, tensor<f32>', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_composite_with_array_consts(self):\n\n    @partial(lax.composite, name='my.consts')\n    def my_consts(x, /, *, scale):\n        return jnp.round(x / scale)\n    scale = np.array([0.5, 0.4, 0.3], dtype=np.float32)\n    x = jnp.array([1.0, 2.0, 3.0], dtype=jnp.float32)\n    self.assertAllClose(my_consts(x, scale=scale), jnp.round(x / scale))\n    mlir_module = jax.jit(partial(my_consts, scale=scale)).lower(x).as_text()\n    self.assertIn('@my.consts(%arg0: tensor<3xf32>) -> tensor<3xf32>', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_constant_folding_complex_to_real_scan_regression(self):\n\n    def g(hiddens):\n        hiddens_aug = jnp.vstack((hiddens[0], hiddens))\n        new_hiddens = hiddens_aug.copy()\n        diff = new_hiddens[:-1] - hiddens\n        diff = new_hiddens[:-1] - hiddens\n        out = jnp.trace(jnp.conj(diff).T @ diff).real\n        return jnp.array(out, dtype=jnp.complex64)\n\n    def _step(carry, arg):\n        primals, f_vjp = jax.vjp(g, jax.random.normal(jax.random.key(0), (9, 8), dtype=jnp.complex64))\n        out = f_vjp(np.array(1.0 + 0j, 'complex64'))[0]\n        return (carry, carry)\n    a, b = jax.lax.scan(_step, 0, jnp.arange(4, dtype=jnp.complex64))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def trace(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).trace(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fn(indices):\n    return jnp.equal(indices, jnp.arange(3)).astype(jnp.float32)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef fn(key):\n    x = jnp.arange(113003)\n    x = with_sharding_constraint(x, P('data'))\n    y = jnp.arange(65536)\n    y = with_sharding_constraint(y.reshape(-1), P('data'))\n    z = jnp.concatenate([x, y], axis=0)\n    z = with_sharding_constraint(z, P('data'))\n    return (x, y, z)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def testReshapeWithUnusualShapes(self):\n    ans = lax.reshape(np.ones((3,), np.float32), (lax.add(1, 2), 1))\n    self.assertAllClose(ans, np.ones((3, 1), np.float32))\n    self.assertRaisesRegex(TypeError, 'Shapes must be 1D sequences of concrete values of integer type.*', lambda: lax.reshape(np.ones(3), (np.array([3, 1]),)))\n    self.assertRaisesRegex(TypeError, 'Shapes must be 1D sequences of concrete values of integer type.*', lambda: lax.reshape(np.ones(3), (1.5, 2.0)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def add(self, x: jax.Array) -> jax.Array:\n    self.value += np.asarray(x)\n    return jax.device_put(self.value, x.sharding)"
  },
  {
    "test_code": "def test_primitive_jaxtype_error(self):\n    err_str = 'Error interpreting argument to .* as an abstract array. The problematic value is of type .* and was passed to the function at path args\\\\[1\\\\].'\n    with jax.enable_checks(False):\n        with self.assertRaisesRegex(TypeError, err_str):\n            lax.add(1, 'hi')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def add(self, x: jax.Array) -> jax.Array:\n    self.value += np.asarray(x)\n    return jax.device_put(self.value, x.sharding)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def add(self, x: jax.Array) -> jax.Array:\n    self.value += np.asarray(x)\n    return jax.device_put(self.value, x.sharding)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def add(self, x: jax.Array) -> jax.Array:\n    self.value += np.asarray(x)\n    return jax.device_put(self.value, x.sharding)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "@jtu.sample_product(from_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, to_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, shape=[(), (2,), (2, 3)])\ndef testBitcastConvertType(self, from_dtype, to_dtype, shape):\n    rng = jtu.rand_default(self.rng())\n    nbits_in = dtypes.bit_width(from_dtype)\n    nbits_out = dtypes.bit_width(to_dtype)\n    if nbits_in < nbits_out:\n        shape = (*shape, nbits_out // nbits_in)\n    args_maker = lambda: [rng(shape, from_dtype)]\n    jnp_op = lambda x: lax.bitcast_convert_type(x, to_dtype)\n    self._CompileAndCheck(jnp_op, args_maker)\n    out = jnp_op(*args_maker())\n    if nbits_in == nbits_out:\n        expected_shape = shape\n    elif nbits_in < nbits_out:\n        expected_shape = shape[:-1]\n    else:\n        expected_shape = (*shape, nbits_in // nbits_out)\n    self.assertEqual(out.dtype, to_dtype)\n    self.assertEqual(out.shape, expected_shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    p = rng((length,), dtype)\n    return [jnp.concatenate([jnp.zeros(leading, p.dtype), p, jnp.zeros(trailing, p.dtype)])]"
  },
  {
    "test_code": "@parameterized.parameters([(algorithm, dtype) for algorithm, test_dtypes in [(lax.DotAlgorithm(lhs_precision_type=np.float32, rhs_precision_type=np.float32, accumulation_type=np.float32, lhs_component_count=1, rhs_component_count=1, num_primitive_operations=1, allow_imprecise_accumulation=False), [np.float32]), (lax.DotAlgorithm(lhs_precision_type=np.float16, rhs_precision_type=np.float16, accumulation_type=np.float32), [np.float16]), ('F16_F16_F32', [np.float16]), (lax.DotAlgorithmPreset.DEFAULT, lax_test_util.float_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.F16_F16_F16, [np.float16]), (lax.DotAlgorithmPreset.F16_F16_F32, [np.float16]), (lax.DotAlgorithmPreset.BF16_BF16_BF16, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X6, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.F32_F32_F32, [np.float32]), (lax.DotAlgorithmPreset.F64_F64_F64, [np.float64])] for dtype in test_dtypes if jtu.dtypes.supported([dtype])])\ndef testDotAlgorithm(self, algorithm, dtype):\n    if jtu.test_device_matches(['cpu']):\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.F16_F16_F16, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on CPU.\")\n    if jtu.test_device_matches(['gpu']):\n        if algorithm in {lax.DotAlgorithmPreset.F16_F16_F32, lax.DotAlgorithmPreset.TF32_TF32_F32, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            if not jtu.is_cuda_compute_capability_at_least('8.0'):\n                raise SkipTest(f\"The dot algorithm '{algorithm}' requires CUDA compute capability >= 8.0.\")\n        elif algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on GPU.\")\n    if jtu.test_device_matches(['tpu']):\n        if not jtu.if_cloud_tpu_at_least(2024, 12, 19):\n            self.skipTest('Requires libtpu built after 2024-12-19')\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on TPU.\")\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    self._CompileAndCheck(partial(lax.dot, precision=algorithm), args_maker)\n    self.assertEqual(lax.dot(*args_maker(), precision=algorithm).dtype, dtype)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    p = rng((length,), dtype)\n    return [jnp.concatenate([jnp.zeros(leading, p.dtype), p, jnp.zeros(trailing, p.dtype)])]"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, dimensions=dimensions) for arg_shape, dimensions in [[(1,), (0,)], [(1,), (-1,)], [(2, 1, 4), (1,)], [(2, 1, 3, 1), (1,)], [(2, 1, 3, 1), (1, 3)], [(2, 1, 3, 1), (3,)]]])\ndef testSqueeze(self, arg_shape, dimensions):\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(arg_shape, np.float32)]\n    op = lambda x: lax.squeeze(x, dimensions)\n    numpy_op = lambda x: lax_reference.squeeze(x, dimensions)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)\n    check_grads(op, args_maker(), 3, ['fwd', 'rev'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    p = rng((length,), dtype)\n    return [jnp.concatenate([jnp.zeros(leading, p.dtype), p, jnp.zeros(trailing, p.dtype)])]"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(1, _reduce_custom_add, [np.float32]), (0, _reduce_custom_mul, [np.float32]), (0, _reduce_custom_sub, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowGeneralJVP(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(operand, init_val):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype), init_val]\n    self._CompileAndCheck(fun, args_maker)\n    args = args_maker()\n    init_val = args[1]\n\n    def fun2(operand):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CompileAndCheck(fun2, args_maker)\n    operand = args_maker()[0]\n    jtu.check_jvp(fun2, partial(jax.jvp, fun2), (operand,))\n    check_grads(fun2, (operand,), 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    p = rng((length,), dtype)\n    return [jnp.concatenate([jnp.zeros(leading, p.dtype), p, jnp.zeros(trailing, p.dtype)])]"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(-np.inf, lax.max, [np.float32]), (np.inf, lax.min, [np.float32]), (0, lax.add, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowCustomSameAsMonoid(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(op_, operand_):\n        return lax.reduce_window(operand_, init_val, op_, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    args = args_maker()\n    operand = args[0]\n    rng = np.random.RandomState(0)\n    tangent = tree_map(partial(jtu.rand_like, rng), operand)\n    custom_equiv = {lax.max: _reduce_custom_max, lax.min: _reduce_custom_min, lax.add: _reduce_custom_add}\n    custom_op = custom_equiv[op]\n    custom_primals, custom_tangents = jax.jvp(partial(fun, custom_op), primals=(operand,), tangents=(tangent,))\n    lax_primals, lax_tangents = jax.jvp(partial(fun, op), primals=(operand,), tangents=(tangent,))\n    tol = None\n    jtu.check_close(lax_primals, custom_primals, atol=tol, rtol=tol, err_msg='Mismatched primal')\n    jtu.check_close(lax_tangents, custom_tangents, atol=tol, rtol=tol, err_msg='Mismatched tangents')\n    if init_val.item() in (np.inf, -np.inf):\n        return\n    op_bound_fn = partial(fun, op)\n    jtu.check_jvp(op_bound_fn, partial(jax.jvp, op_bound_fn), (operand,))\n    check_grads(partial(fun, op), [operand], 3, ['fwd'], eps=1.0)\n    check_grads(partial(fun, custom_op), [operand], 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    p = rng((length,), dtype)\n    return [jnp.concatenate([jnp.zeros(leading, p.dtype), p, jnp.zeros(trailing, p.dtype)])]"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\ndef fn(x):\n    R1 = jnp.array([[x[0], 0, 0], [0, x[0], 0], [0, 0, x[0]]])\n    R2 = jnp.array([[x[0], 0, 0], [0, x[1], 0], [0, 0, x[2]]])\n    H = jnp.eye(4)\n    H = H.at[:3, :3].set(R2.T)\n    pos = H @ jnp.concatenate([x, jnp.array([1.0])])\n    return (pos, R1)"
  },
  {
    "test_code": "@jtu.sample_product(from_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, to_dtype=['int4', 'uint4'] + jtu.dtypes.all_floating + jtu.dtypes.all_integer + jtu.dtypes.all_unsigned, shape=[(), (2,), (2, 3)])\ndef testBitcastConvertType(self, from_dtype, to_dtype, shape):\n    rng = jtu.rand_default(self.rng())\n    nbits_in = dtypes.bit_width(from_dtype)\n    nbits_out = dtypes.bit_width(to_dtype)\n    if nbits_in < nbits_out:\n        shape = (*shape, nbits_out // nbits_in)\n    args_maker = lambda: [rng(shape, from_dtype)]\n    jnp_op = lambda x: lax.bitcast_convert_type(x, to_dtype)\n    self._CompileAndCheck(jnp_op, args_maker)\n    out = jnp_op(*args_maker())\n    if nbits_in == nbits_out:\n        expected_shape = shape\n    elif nbits_in < nbits_out:\n        expected_shape = shape[:-1]\n    else:\n        expected_shape = (*shape, nbits_in // nbits_out)\n    self.assertEqual(out.dtype, to_dtype)\n    self.assertEqual(out.shape, expected_shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    M = sprng(shape, dtype)\n    new_indices = jnp.concatenate([M.indices, M.indices], axis=n_batch)\n    new_data = jnp.concatenate([M.data, M.data], axis=n_batch)\n    return [sparse.BCOO((new_data, new_indices), shape=M.shape)]"
  },
  {
    "test_code": "@parameterized.parameters([(algorithm, dtype) for algorithm, test_dtypes in [(lax.DotAlgorithm(lhs_precision_type=np.float32, rhs_precision_type=np.float32, accumulation_type=np.float32, lhs_component_count=1, rhs_component_count=1, num_primitive_operations=1, allow_imprecise_accumulation=False), [np.float32]), (lax.DotAlgorithm(lhs_precision_type=np.float16, rhs_precision_type=np.float16, accumulation_type=np.float32), [np.float16]), ('F16_F16_F32', [np.float16]), (lax.DotAlgorithmPreset.DEFAULT, lax_test_util.float_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.F16_F16_F16, [np.float16]), (lax.DotAlgorithmPreset.F16_F16_F32, [np.float16]), (lax.DotAlgorithmPreset.BF16_BF16_BF16, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X6, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.F32_F32_F32, [np.float32]), (lax.DotAlgorithmPreset.F64_F64_F64, [np.float64])] for dtype in test_dtypes if jtu.dtypes.supported([dtype])])\ndef testDotAlgorithm(self, algorithm, dtype):\n    if jtu.test_device_matches(['cpu']):\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.F16_F16_F16, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on CPU.\")\n    if jtu.test_device_matches(['gpu']):\n        if algorithm in {lax.DotAlgorithmPreset.F16_F16_F32, lax.DotAlgorithmPreset.TF32_TF32_F32, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            if not jtu.is_cuda_compute_capability_at_least('8.0'):\n                raise SkipTest(f\"The dot algorithm '{algorithm}' requires CUDA compute capability >= 8.0.\")\n        elif algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on GPU.\")\n    if jtu.test_device_matches(['tpu']):\n        if not jtu.if_cloud_tpu_at_least(2024, 12, 19):\n            self.skipTest('Requires libtpu built after 2024-12-19')\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on TPU.\")\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    self._CompileAndCheck(partial(lax.dot, precision=algorithm), args_maker)\n    self.assertEqual(lax.dot(*args_maker(), precision=algorithm).dtype, dtype)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    M = sprng(shape, dtype)\n    new_indices = jnp.concatenate([M.indices, M.indices], axis=n_batch)\n    new_data = jnp.concatenate([M.data, M.data], axis=n_batch)\n    return [sparse.BCOO((new_data, new_indices), shape=M.shape)]"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, dimensions=dimensions) for arg_shape, dimensions in [[(1,), (0,)], [(1,), (-1,)], [(2, 1, 4), (1,)], [(2, 1, 3, 1), (1,)], [(2, 1, 3, 1), (1, 3)], [(2, 1, 3, 1), (3,)]]])\ndef testSqueeze(self, arg_shape, dimensions):\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(arg_shape, np.float32)]\n    op = lambda x: lax.squeeze(x, dimensions)\n    numpy_op = lambda x: lax_reference.squeeze(x, dimensions)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)\n    check_grads(op, args_maker(), 3, ['fwd', 'rev'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    M = sprng(shape, dtype)\n    new_indices = jnp.concatenate([M.indices, M.indices], axis=n_batch)\n    new_data = jnp.concatenate([M.data, M.data], axis=n_batch)\n    return [sparse.BCOO((new_data, new_indices), shape=M.shape)]"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(1, _reduce_custom_add, [np.float32]), (0, _reduce_custom_mul, [np.float32]), (0, _reduce_custom_sub, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowGeneralJVP(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(operand, init_val):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype), init_val]\n    self._CompileAndCheck(fun, args_maker)\n    args = args_maker()\n    init_val = args[1]\n\n    def fun2(operand):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CompileAndCheck(fun2, args_maker)\n    operand = args_maker()[0]\n    jtu.check_jvp(fun2, partial(jax.jvp, fun2), (operand,))\n    check_grads(fun2, (operand,), 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    M = sprng(shape, dtype)\n    new_indices = jnp.concatenate([M.indices, M.indices], axis=n_batch)\n    new_data = jnp.concatenate([M.data, M.data], axis=n_batch)\n    return [sparse.BCOO((new_data, new_indices), shape=M.shape)]"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(-np.inf, lax.max, [np.float32]), (np.inf, lax.min, [np.float32]), (0, lax.add, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\n@jtu.skip_on_devices('gpu')\n@jtu.skip_on_devices('tpu')\ndef testReduceWindowCustomSameAsMonoid(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(op_, operand_):\n        return lax.reduce_window(operand_, init_val, op_, dims, strides, padding, base_dilation, window_dilation)\n    args_maker = lambda: [rng(shape, dtype)]\n    args = args_maker()\n    operand = args[0]\n    rng = np.random.RandomState(0)\n    tangent = tree_map(partial(jtu.rand_like, rng), operand)\n    custom_equiv = {lax.max: _reduce_custom_max, lax.min: _reduce_custom_min, lax.add: _reduce_custom_add}\n    custom_op = custom_equiv[op]\n    custom_primals, custom_tangents = jax.jvp(partial(fun, custom_op), primals=(operand,), tangents=(tangent,))\n    lax_primals, lax_tangents = jax.jvp(partial(fun, op), primals=(operand,), tangents=(tangent,))\n    tol = None\n    jtu.check_close(lax_primals, custom_primals, atol=tol, rtol=tol, err_msg='Mismatched primal')\n    jtu.check_close(lax_tangents, custom_tangents, atol=tol, rtol=tol, err_msg='Mismatched tangents')\n    if init_val.item() in (np.inf, -np.inf):\n        return\n    op_bound_fn = partial(fun, op)\n    jtu.check_jvp(op_bound_fn, partial(jax.jvp, op_bound_fn), (operand,))\n    check_grads(partial(fun, op), [operand], 3, ['fwd'], eps=1.0)\n    check_grads(partial(fun, custom_op), [operand], 3, ['fwd'], eps=1.0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def args_maker():\n    M = sprng(shape, dtype)\n    new_indices = jnp.concatenate([M.indices, M.indices], axis=n_batch)\n    new_data = jnp.concatenate([M.data, M.data], axis=n_batch)\n    return [sparse.BCOO((new_data, new_indices), shape=M.shape)]"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_composite_attribute_dtypes(self):\n\n    @jax.jit\n    def my_tangent_composite_with_attributes(x):\n\n        def decomposition(x, **_):\n            return lax.sin(x) / lax.cos(x)\n        return lax.composite(decomposition, 'my.tangent')(x, dtype=np.dtype(np.float32), int=1, omit=None, str='bar', tensor=np.zeros((1, 2), dtype=np.float32), tensor_r1=np.zeros((2,), dtype=np.float32))\n    pi = jnp.pi\n    x = jnp.array([0.0, pi / 4, 3 * pi / 4, pi], dtype=jnp.float32)\n    output = my_tangent_composite_with_attributes(x)\n    self.assertArraysAllClose(output, jnp.array([0.0, 1.0, -1.0, 0.0], dtype=jnp.float32))\n    mlir_module = my_tangent_composite_with_attributes.lower(x).as_text()\n    self.assertIn('stablehlo.composite \"my.tangent\" %arg0 {composite_attributes = {dtype = f32, int = 1 : i64, str = \"bar\", tensor = dense<0.000000e+00> : tensor<1x2xf32>, tensor_r1 = dense<0.000000e+00> : tensor<2xf32>}, decomposition = @my.tangent} : (tensor<4xf32>) -> tensor<4xf32>', mlir_module)\n    self.assertIn('func.func private @my.tangent', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_vjp\ndef sin(x):\n    return jnp.sin(x)"
  },
  {
    "test_code": "def test_composite_unsupported_attribute_dtypes(self):\n\n    def my_tangent_composite_with_attributes(x):\n\n        def decomposition(x, **_):\n            return lax.sin(x) / lax.cos(x)\n        return lax.composite(decomposition, 'my.tangent')(x, tensor=jnp.zeros((1, 2), dtype=jnp.float32))\n    pi = jnp.pi\n    x = jnp.array([0.0, pi / 4, 3 * pi / 4, pi], dtype=jnp.float32)\n    with self.assertRaisesRegex(UnexpectedTracerError, 'Note: If you are passing jax arrays as attributes, use numpy arrays instead.'):\n        jax.jit(my_tangent_composite_with_attributes).lower(x).as_text()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_vjp\ndef sin(x):\n    return jnp.sin(x)"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fn(x: jax.Array):\n    checkify.check(jnp.all(x > 0), 'x must be positive')\n    return x + 1"
  },
  {
    "test_code": "def testDotAlgorithmCasting(self):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('F32_F32_F32 is not supported on TPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F32_F32_F32')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertEqual(fun(lhs, rhs).dtype, np.float16)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\ndef fun(x):\n    return lax.while_loop(cond, body, x)"
  },
  {
    "test_code": "@jtu.sample_product(op=['add', 'mul'], op_namespace=[lax, operator], arr_weak_type=[False, True], init_weak_type=[False, True])\ndef testReduceWeakType(self, op_namespace, op, arr_weak_type, init_weak_type):\n    op = getattr(op_namespace, op)\n    arr = lax_internal._convert_element_type(np.arange(10), int, weak_type=arr_weak_type)\n    init = lax_internal._convert_element_type(1, int, weak_type=init_weak_type)\n    fun = lambda arr, init: lax.reduce(arr, init, op, (0,))\n    out = fun(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out), arr_weak_type and init_weak_type)\n    out_jit = jax.jit(fun)(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), arr_weak_type and init_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\ndef fun(x):\n    return lax.while_loop(cond, body, x)"
  },
  {
    "test_code": "def test_composite_with_tracer_consts(self):\n\n    def fun(x, scale):\n\n        @partial(lax.composite, name='my.consts')\n        def my_consts(y):\n            return jnp.round(y / scale)\n        return my_consts(x)\n    scale = jnp.array([0.5, 0.4, 0.3], dtype=jnp.float32)\n    x = jnp.array([1.0, 2.0, 3.0], dtype=jnp.float32)\n    self.assertAllClose(fun(x, scale), jnp.round(x / scale))\n    self.assertAllClose(jax.jit(partial(fun, scale=scale))(x), jnp.round(x / scale))\n    with self.assertRaisesRegex(UnexpectedTracerError, \"Found a JAX Tracer as a constant in the decomposition for the composite op 'my.consts'.\"):\n        jax.jit(fun)(x, scale)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.vmap\ndef fun(x):\n    return lax.while_loop(cond, body, x)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef fn(x):\n    return x * x"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n    return bits + x"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, P('x')), out_shardings=NamedSharding(mesh, P('x')))\ndef f(x, y):\n    z = x @ y\n    return z @ y"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    debugging.inspect_array_sharding(x, callback=_cb)\n    return jnp.square(x)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@partial(jax.jit, inline=True)\ndef f(x):\n    return lax.add(x, 3)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f():\n    key = jax.random.key(0)\n    return jax.random.bits(key) + jax.random.bits(key)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(x):\n    nonlocal num_traces\n    num_traces += 1\n    return x + x"
  },
  {
    "test_code": "def testRngBitGenerator(self):\n    if not config.enable_x64.value:\n        raise SkipTest('RngBitGenerator requires 64bit key')\n    key = np.array((1, 2)).astype(np.uint64)\n\n    def fn(k):\n        return lax.rng_bit_generator(k, shape=(5, 7), algorithm=lax.RandomAlgorithm.RNG_THREE_FRY)\n    out = fn(key)\n    out_jit = jax.jit(fn)(key)\n    self.assertEqual(out[0].shape, (2,))\n    self.assertEqual(out[1].shape, (5, 7))\n    self.assertArraysEqual(out[0], out_jit[0])\n    self.assertArraysEqual(out[1], out_jit[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@custom_transpose(jnp.ones(2))\ndef fn(r, x):\n    return x / r"
  },
  {
    "test_code": "def testDotAlgorithmCasting(self):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('F32_F32_F32 is not supported on TPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F32_F32_F32')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertEqual(fun(lhs, rhs).dtype, np.float16)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun(X):\n    return jnp.sum(proj(X) ** 2)"
  },
  {
    "test_code": "@jtu.sample_product(op=['add', 'mul'], op_namespace=[lax, operator], arr_weak_type=[False, True], init_weak_type=[False, True])\ndef testReduceWeakType(self, op_namespace, op, arr_weak_type, init_weak_type):\n    op = getattr(op_namespace, op)\n    arr = lax_internal._convert_element_type(np.arange(10), int, weak_type=arr_weak_type)\n    init = lax_internal._convert_element_type(1, int, weak_type=init_weak_type)\n    fun = lambda arr, init: lax.reduce(arr, init, op, (0,))\n    out = fun(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out), arr_weak_type and init_weak_type)\n    out_jit = jax.jit(fun)(arr, init)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), arr_weak_type and init_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun(X):\n    return jnp.sum(proj(X) ** 2)"
  },
  {
    "test_code": "def test_composite_with_tracer_consts(self):\n\n    def fun(x, scale):\n\n        @partial(lax.composite, name='my.consts')\n        def my_consts(y):\n            return jnp.round(y / scale)\n        return my_consts(x)\n    scale = jnp.array([0.5, 0.4, 0.3], dtype=jnp.float32)\n    x = jnp.array([1.0, 2.0, 3.0], dtype=jnp.float32)\n    self.assertAllClose(fun(x, scale), jnp.round(x / scale))\n    self.assertAllClose(jax.jit(partial(fun, scale=scale))(x), jnp.round(x / scale))\n    with self.assertRaisesRegex(UnexpectedTracerError, \"Found a JAX Tracer as a constant in the decomposition for the composite op 'my.consts'.\"):\n        jax.jit(fun)(x, scale)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def fun(X):\n    return jnp.sum(proj(X) ** 2)"
  },
  {
    "test_code": "def testReshapeWithUnusualShapes(self):\n    ans = lax.reshape(np.ones((3,), np.float32), (lax.add(1, 2), 1))\n    self.assertAllClose(ans, np.ones((3, 1), np.float32))\n    self.assertRaisesRegex(TypeError, 'Shapes must be 1D sequences of concrete values of integer type.*', lambda: lax.reshape(np.ones(3), (np.array([3, 1]),)))\n    self.assertRaisesRegex(TypeError, 'Shapes must be 1D sequences of concrete values of integer type.*', lambda: lax.reshape(np.ones(3), (1.5, 2.0)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef add(x):\n    return x * 2"
  },
  {
    "test_code": "def test_primitive_jaxtype_error(self):\n    err_str = 'Error interpreting argument to .* as an abstract array. The problematic value is of type .* and was passed to the function at path args\\\\[1\\\\].'\n    with jax.enable_checks(False):\n        with self.assertRaisesRegex(TypeError, err_str):\n            lax.add(1, 'hi')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef add(x):\n    return x * 2"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef add(x):\n    return x * 2"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef add(x):\n    return x * 2"
  },
  {
    "test_code": "def test_composite_attribute_dtypes(self):\n\n    @jax.jit\n    def my_tangent_composite_with_attributes(x):\n\n        def decomposition(x, **_):\n            return lax.sin(x) / lax.cos(x)\n        return lax.composite(decomposition, 'my.tangent')(x, dtype=np.dtype(np.float32), int=1, omit=None, str='bar', tensor=np.zeros((1, 2), dtype=np.float32), tensor_r1=np.zeros((2,), dtype=np.float32))\n    pi = jnp.pi\n    x = jnp.array([0.0, pi / 4, 3 * pi / 4, pi], dtype=jnp.float32)\n    output = my_tangent_composite_with_attributes(x)\n    self.assertArraysAllClose(output, jnp.array([0.0, 1.0, -1.0, 0.0], dtype=jnp.float32))\n    mlir_module = my_tangent_composite_with_attributes.lower(x).as_text()\n    self.assertIn('stablehlo.composite \"my.tangent\" %arg0 {composite_attributes = {dtype = f32, int = 1 : i64, str = \"bar\", tensor = dense<0.000000e+00> : tensor<1x2xf32>, tensor_r1 = dense<0.000000e+00> : tensor<2xf32>}, decomposition = @my.tangent} : (tensor<4xf32>) -> tensor<4xf32>', mlir_module)\n    self.assertIn('func.func private @my.tangent', mlir_module)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_jvp\ndef sin(x):\n    return jnp.sin(x)"
  },
  {
    "test_code": "def test_composite_unsupported_attribute_dtypes(self):\n\n    def my_tangent_composite_with_attributes(x):\n\n        def decomposition(x, **_):\n            return lax.sin(x) / lax.cos(x)\n        return lax.composite(decomposition, 'my.tangent')(x, tensor=jnp.zeros((1, 2), dtype=jnp.float32))\n    pi = jnp.pi\n    x = jnp.array([0.0, pi / 4, 3 * pi / 4, pi], dtype=jnp.float32)\n    with self.assertRaisesRegex(UnexpectedTracerError, 'Note: If you are passing jax arrays as attributes, use numpy arrays instead.'):\n        jax.jit(my_tangent_composite_with_attributes).lower(x).as_text()",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_jvp\ndef sin(x):\n    return jnp.sin(x)"
  },
  {
    "test_code": "@jtu.sample_product([dict(base_shape=shape, axis=axis) for shape in [(4,), (3, 4), (2, 3, 4)] for axis in range(len(shape))], num_pieces=range(3), dtype=lax_test_util.default_dtypes)\ndef testSplit(self, axis, base_shape, dtype, num_pieces):\n    sizes = jtu.rand_int(self.rng(), 5)((num_pieces + 1,), np.int64)\n    shape = list(base_shape)\n    shape[axis] = np.sum(sizes)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(shape, dtype)]\n    op = lambda x: lax.split(x, sizes, axis=axis)\n\n    def numpy_op(x):\n        return np.split(x, np.cumsum(sizes[:-1]), axis=axis)\n    self._CompileAndCheck(op, args_maker)\n    self._CheckAgainstNumpy(numpy_op, op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_jvp\ndef sum(x):\n    return jnp.sum(x, axis=0)"
  },
  {
    "test_code": "def testBroadcastInDimOperandShapeTranspose(self):\n\n    def f(x):\n        return lax.broadcast_in_dim(x, (2, 3, 4), broadcast_dimensions=(0, 1, 2)).sum()\n\n    def g(x):\n        return lax.broadcast_in_dim(x.reshape((3,)), (2, 3, 4), broadcast_dimensions=(1,)).sum()\n    x = np.ones((1, 3, 1))\n    self.assertArraysEqual(jax.grad(f)(x), jax.grad(g)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_jvp\ndef sum(x):\n    return jnp.sum(x, axis=0)"
  },
  {
    "test_code": "def test_scan_jaxpr_split_transpose(self):\n\n    def stage(x, w):\n        x = x @ w\n        x = jnp.tanh(x)\n        return (x, ())\n\n    def loss(ws, x, split_transpose=False):\n        return jnp.sum(jax.lax.scan(stage, x, ws, _split_transpose=split_transpose)[0])\n\n    def fn(*args, split_transpose=False):\n        v, fn_transpose = jax.vjp(partial(loss, split_transpose=split_transpose), *args)\n        grads = fn_transpose(1.0)\n        return (*grads, v)\n    x = jax.random.uniform(jax.random.key(0), [256, 100])\n    wss = jax.random.uniform(jax.random.key(1), [7, 100, 100])\n    jaxpr = jax.make_jaxpr(partial(fn))(wss, x)\n    jaxpr_split_transpose = jax.make_jaxpr(partial(fn, split_transpose=True))(wss, x)\n    self.assertEqual(jaxpr.in_avals, jaxpr_split_transpose.in_avals)\n    self.assertEqual(jaxpr.out_avals, jaxpr_split_transpose.out_avals)\n    ct_ws = jaxpr_split_transpose.jaxpr.outvars[0]\n    ct_x = jaxpr_split_transpose.jaxpr.outvars[1]\n    backprop_scan = jaxpr_split_transpose.jaxpr.eqns[-2]\n    self.assertEqual(backprop_scan.primitive, jax.lax.scan_p)\n    param_gradient_map = jaxpr_split_transpose.jaxpr.eqns[-1]\n    self.assertEqual(param_gradient_map.primitive, jax.lax.scan_p)\n    self.assertEqual(param_gradient_map.params['num_consts'], 0)\n    self.assertEqual(param_gradient_map.params['num_carry'], 0)\n    self.assertEqual(ct_ws, param_gradient_map.outvars[0])\n    self.assertEqual(ct_x, backprop_scan.outvars[0])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_jvp\ndef sum(x):\n    return jnp.sum(x, axis=0)"
  },
  {
    "test_code": "@parameterized.parameters([(algorithm, dtype) for algorithm, test_dtypes in [(lax.DotAlgorithm(lhs_precision_type=np.float32, rhs_precision_type=np.float32, accumulation_type=np.float32, lhs_component_count=1, rhs_component_count=1, num_primitive_operations=1, allow_imprecise_accumulation=False), [np.float32]), (lax.DotAlgorithm(lhs_precision_type=np.float16, rhs_precision_type=np.float16, accumulation_type=np.float32), [np.float16]), ('F16_F16_F32', [np.float16]), (lax.DotAlgorithmPreset.DEFAULT, lax_test_util.float_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, dtypes._float8_dtypes), (lax.DotAlgorithmPreset.F16_F16_F16, [np.float16]), (lax.DotAlgorithmPreset.F16_F16_F32, [np.float16]), (lax.DotAlgorithmPreset.BF16_BF16_BF16, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32, [dtypes.bfloat16]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.BF16_BF16_F32_X6, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32, [np.float32]), (lax.DotAlgorithmPreset.TF32_TF32_F32_X3, [np.float32]), (lax.DotAlgorithmPreset.F32_F32_F32, [np.float32]), (lax.DotAlgorithmPreset.F64_F64_F64, [np.float64])] for dtype in test_dtypes if jtu.dtypes.supported([dtype])])\ndef testDotAlgorithm(self, algorithm, dtype):\n    if jtu.test_device_matches(['cpu']):\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.F16_F16_F16, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on CPU.\")\n    if jtu.test_device_matches(['gpu']):\n        if algorithm in {lax.DotAlgorithmPreset.F16_F16_F32, lax.DotAlgorithmPreset.TF32_TF32_F32, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            if not jtu.is_cuda_compute_capability_at_least('8.0'):\n                raise SkipTest(f\"The dot algorithm '{algorithm}' requires CUDA compute capability >= 8.0.\")\n        elif algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32, lax.DotAlgorithmPreset.ANY_F8_ANY_F8_F32_FAST_ACCUM, lax.DotAlgorithmPreset.F32_F32_F32, lax.DotAlgorithmPreset.F64_F64_F64}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on GPU.\")\n    if jtu.test_device_matches(['tpu']):\n        if not jtu.if_cloud_tpu_at_least(2024, 12, 19):\n            self.skipTest('Requires libtpu built after 2024-12-19')\n        if algorithm not in {lax.DotAlgorithmPreset.DEFAULT, lax.DotAlgorithmPreset.BF16_BF16_F32, lax.DotAlgorithmPreset.BF16_BF16_F32_X3, lax.DotAlgorithmPreset.BF16_BF16_F32_X6}:\n            raise SkipTest(f\"The dot algorithm '{algorithm}' is not supported on TPU.\")\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    self._CompileAndCheck(partial(lax.dot, precision=algorithm), args_maker)\n    self.assertEqual(lax.dot(*args_maker(), precision=algorithm).dtype, dtype)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_vjp\ndef dot(x):\n    return jnp.dot(x, x)"
  },
  {
    "test_code": "def testDotAlgorithmInvalidFloat8Type(self):\n    if jtu.test_device_matches(['cpu']):\n        raise SkipTest('Not supported on CPU.')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float32), rng(rhs_shape, dtypes.float8_e4m3fn))\n    with self.assertRaisesRegex(ValueError, 'The dot algorithm'):\n        lax.dot(lhs, rhs, precision='ANY_F8_ANY_F8_F32')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_vjp\ndef dot(x):\n    return jnp.dot(x, x)"
  },
  {
    "test_code": "def testDotAlgorithmCasting(self):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('F32_F32_F32 is not supported on TPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F32_F32_F32')\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertEqual(fun(lhs, rhs).dtype, np.float16)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_vjp\ndef dot(x):\n    return jnp.dot(x, x)"
  },
  {
    "test_code": "def testDotAlgorithmAllowedOutputStorage(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Only supported on GPU.')\n\n    def fun(lhs, rhs):\n        return lax.dot(lhs, rhs, precision='F16_F16_F32', preferred_element_type=np.float16)\n    lhs_shape = (3, 4)\n    rhs_shape = (4, 3)\n    rng = jtu.rand_default(self.rng())\n    lhs, rhs = (rng(lhs_shape, np.float16), rng(rhs_shape, np.float16))\n    self.assertNotIn('convert', jax.jit(fun).lower(lhs, rhs).as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_vjp\ndef dot(x):\n    return jnp.dot(x, x)"
  },
  {
    "test_code": "@jtu.sample_product([dict(lhs_shape=lhs_shape, rhs_shape=rhs_shape) for lhs_shape in [(3,), (4, 3)] for rhs_shape in [(3,), (3, 6)]], [dict(dtype=d, preferred_element_type=p) for d, p in preferred_type_combinations])\ndef testDotPreferredElement(self, lhs_shape, rhs_shape, dtype, preferred_element_type):\n    if not config.enable_x64.value and (dtype == np.float64 or preferred_element_type == np.float64 or dtype == np.int64 or (preferred_element_type == np.int64)):\n        raise SkipTest('64-bit mode disabled')\n    if jtu.test_device_matches(['tpu']) and (dtype == np.complex128 or preferred_element_type == np.complex128):\n        raise SkipTest('np.complex128 is not yet supported on TPU')\n    if jtu.test_device_matches(['gpu']):\n        raise SkipTest('dot_general with preferred_element_type returns NaN non-deterministically on GPU')\n    rng = jtu.rand_default(self.rng())\n    x = rng(lhs_shape, dtype)\n    y = rng(rhs_shape, dtype)\n    result_with_preferred_type = lax.dot(x, y, preferred_element_type=preferred_element_type)\n    result_with_upcast_inputs = lax.dot(x.astype(preferred_element_type), y.astype(preferred_element_type))\n    self.assertArraysAllClose(result_with_preferred_type, result_with_upcast_inputs)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_vjp\ndef dot(x):\n    return jnp.dot(x, x)"
  },
  {
    "test_code": "@jtu.sample_product([dict(lhs_shape=lhs_shape, rhs_shape=rhs_shape) for lhs_shape in [(3,), (4, 3)] for rhs_shape in [(3,), (3, 6)]], [dict(dtype_lhs=dtype_lhs, dtype_rhs=dtype_rhs) for dtype_lhs, dtype_rhs in [(dtypes.float8_e4m3fn, dtypes.float8_e5m2), (dtypes.float8_e5m2, dtypes.float8_e4m3fn), (dtypes.float8_e4m3fnuz, dtypes.float8_e5m2fnuz), (dtypes.float8_e5m2fnuz, dtypes.float8_e4m3fnuz)]])\ndef test_mixed_fp8_dot_general(self, lhs_shape, rhs_shape, dtype_lhs, dtype_rhs):\n    if jtu.test_device_matches(['tpu']):\n        raise SkipTest('Mixed fp8 precision matmul is not yet supported on TPU')\n    if not jtu.is_device_rocm() and (dtype_lhs in [dtypes.float8_e4m3fnuz, dtypes.float8_e5m2fnuz] or dtype_rhs in [dtypes.float8_e4m3fnuz, dtypes.float8_e5m2fnuz]):\n        raise SkipTest('float8_e4m3fnuz and float8_e5m2fnuz types are only supported on ROCm')\n    rng = jtu.rand_default(self.rng())\n    lhs = rng(lhs_shape, dtype=dtype_lhs)\n    rhs = rng(rhs_shape, dtype=dtype_rhs)\n    dot_general_result = lax.dot(lhs, rhs, preferred_element_type=jnp.float32)\n    lhs_upcasted = lhs.astype(jnp.float32)\n    rhs_upcasted = rhs.astype(jnp.float32)\n    dot_general_result_upcasted = lax.dot(lhs_upcasted, rhs_upcasted, preferred_element_type=jnp.float32)\n    self.assertArraysAllClose(dot_general_result, dot_general_result_upcasted, rtol=0.001, atol=0.001)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.custom_vjp\ndef dot(x):\n    return jnp.dot(x, x)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(a, b):\n    with set_xla_metadata(key2='val2'):\n        return a + b"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "@jax.jit\ndef f(n):\n    token = lax.create_token(n)\n    token = lax.fori_loop(0, n, doubler, token)\n    return n"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x):\n    return jnp.full_like(x, 2.0)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(b):\n    return jax.scipy.sparse.linalg.cg(matvec, (b, b))[0]"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(x, y):\n\n    @jax.jit\n    def g(x):\n        return x * y\n    return g(x) + g(y)"
  },
  {
    "test_code": "def testRngBitGenerator2(self):\n\n    def f(key):\n        return lax.rng_bit_generator(key, shape=(5, 7))\n    key = np.array((1, 2, 3, 4)).astype(np.uint32)\n    out1 = f(key)\n    out2 = jax.jit(f)(key)\n    self.assertEqual(out1[0].shape, (4,))\n    self.assertEqual(out1[1].shape, (5, 7))\n    self.assertArraysEqual(out1[0], out2[0])\n    self.assertArraysEqual(out1[1], out2[1])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def testRegressionIssue5728(self):\n\n    @jax.jit\n    def f(inputs):\n        out_action_2 = lax.slice_in_dim(inputs, 0, 15, axis=-1)\n        mask = lax.slice_in_dim(inputs, 7, 22, axis=-1)\n        out_action_2 = lax.select(lax.eq(mask, np.float32(0)), lax.broadcast(np.float32(42), (1, 15)), out_action_2)\n        return lax.pad(out_action_2, np.float32(42), [(0, 0, 0), (0, 15, 0)])\n    self.assertArraysEqual(np.full((1, 30), np.float32(42)), f(np.zeros((1, 24), dtype=np.float32)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_jit_closure(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f():\n        jnp.add(1, 1)\n        return k\n    y = f()\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_jit_identity(self):\n    k = FooArray((), jnp.arange(2, dtype='uint32'))\n\n    @jax.jit\n    def f(k):\n        jnp.add(1, 1)\n        return k\n    y = f(k)\n    self.assertIsInstance(y, FooArray)\n    self.assertEqual(y.shape, ())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_jit_multiple_primitives(self):\n\n    @jax.jit\n    def f():\n        k1 = make((3,))\n        k2 = bake(k1)\n        y = take(k2)\n        return y\n    y = f()\n    self.assertArraysAllClose(y, jnp.array([3.0, 3.0, 3.0]), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  },
  {
    "test_code": "def test_xla_reverse_bug(self):\n\n    def f(x):\n        y = jnp.array([2, 5])\n        return lax.rev(x * y, (0,))\n    x = jnp.array([1, 2])\n    self.assertArraysEqual(f(x), jax.jit(f)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_test.py",
    "function": "def f(Xtree, y):\n    if deep:\n        out = Xtree['deep']['X'] @ y\n    else:\n        out = Xtree['X'] @ y\n    if bias:\n        out += Xtree['list'][1][0]\n    out = jnp.sum(out)\n    if has_aux:\n        return (out, {'y': y.shape})\n    else:\n        return out"
  }
]