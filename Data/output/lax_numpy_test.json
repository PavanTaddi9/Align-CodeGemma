[
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty, jnp.zeros, jnp.ones, jnp.full], shape=array_shapes, dtype=default_dtypes)\ndef testArrayCreationWithDevice(self, func, shape, dtype):\n    device = jax.devices()[-1]\n    kwds = {'fill_value': 1} if func is jnp.full else {}\n    out = func(**kwds, shape=shape, dtype=dtype, device=device)\n    self.assertEqual(out.devices(), {device})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    x, = promote_dtypes_complex(x)\n    return jnp.fft.irfft(jnp.concatenate([jnp.zeros_like(x, shape=1), x[:2] + 1j * x[2:]]))"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty, jnp.zeros, jnp.ones, jnp.full], shape=array_shapes, dtype=default_dtypes)\ndef testArrayCreationWithSharding(self, func, shape, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    kwds = {'fill_value': 1} if func is jnp.full else {}\n    out = func(**kwds, shape=shape, dtype=dtype, device=sharding)\n    self.assertEqual(out.sharding, sharding)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    x, = promote_dtypes_complex(x)\n    return jnp.fft.irfft(jnp.concatenate([jnp.zeros_like(x, shape=1), x[:2] + 1j * x[2:]]))"
  },
  {
    "test_code": "@jtu.sample_product(func=[lambda dtype, device: jnp.arange(5, dtype=dtype, device=device), lambda dtype, device: jnp.eye(5, 6, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, retstep=True, dtype=dtype, device=device), lambda dtype, device: jnp.array([1, 2, 3, 4, 5], dtype=dtype, device=device)], dtype=default_dtypes)\ndef testArangeEyeLinspaceArrayWithDevice(self, func, dtype):\n    device = jax.devices()[-1]\n    output = func(dtype=dtype, device=device)\n    if isinstance(output, tuple):\n        self.assertEqual(output[0].devices(), {device})\n    else:\n        self.assertEqual(output.devices(), {device})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    x, = promote_dtypes_complex(x)\n    return jnp.fft.irfft(jnp.concatenate([jnp.zeros_like(x, shape=1), x[:2] + 1j * x[2:]]))"
  },
  {
    "test_code": "@jtu.sample_product(func=[lambda dtype, device: jnp.arange(5, dtype=dtype, device=device), lambda dtype, device: jnp.eye(5, 6, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, retstep=True, dtype=dtype, device=device), lambda dtype, device: jnp.array([1, 2, 3, 4, 5], dtype=dtype, device=device)], dtype=default_dtypes)\ndef testArangeEyeLinspaceArrayWithSharding(self, func, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    output = func(dtype=dtype, device=sharding)\n    if isinstance(output, tuple):\n        self.assertEqual(output[0].sharding, sharding)\n    else:\n        self.assertEqual(output.sharding, sharding)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    x, = promote_dtypes_complex(x)\n    return jnp.fft.irfft(jnp.concatenate([jnp.zeros_like(x, shape=1), x[:2] + 1j * x[2:]]))"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty_like, jnp.zeros_like, jnp.ones_like, jnp.full_like], shape=array_shapes, dtype=default_dtypes)\ndef testFullLikeWithDevice(self, func, shape, dtype):\n    device = jax.devices()[-1]\n    rng = jtu.rand_default(self.rng())\n    x = rng(shape, dtype)\n    kwds = {'fill_value': 1} if func is jnp.full_like else {}\n    with self.subTest('device from keyword'):\n        out = func(x, **kwds, device=device)\n        self.assertEqual(out.devices(), {device})\n    with self.subTest('device from input array'):\n        out2 = func(out, **kwds)\n        self.assertEqual(out2.devices(), out.devices())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    x, = promote_dtypes_complex(x)\n    return jnp.fft.irfft(jnp.concatenate([jnp.zeros_like(x, shape=1), x[:2] + 1j * x[2:]]))"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty_like, jnp.zeros_like, jnp.ones_like, jnp.full_like], shape=array_shapes, dtype=default_dtypes)\ndef testFullLikeWithSharding(self, func, shape, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    rng = jtu.rand_default(self.rng())\n    x = rng(shape, dtype)\n    kwds = {'fill_value': 1} if func is jnp.full_like else {}\n    with self.subTest('device from keyword'):\n        out = func(x, **kwds, device=sharding)\n        self.assertEqual(out.sharding, sharding)\n    with self.subTest('device from input array'):\n        out2 = func(out, **kwds)\n        self.assertEqual(out2.devices(), out.devices())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    x, = promote_dtypes_complex(x)\n    return jnp.fft.irfft(jnp.concatenate([jnp.zeros_like(x, shape=1), x[:2] + 1j * x[2:]]))"
  },
  {
    "test_code": "@jtu.sample_product(funcname=['array', 'asarray'], dtype=[int, float, None], val=[0, 1], input_type=[int, float, np.int32, np.float32])\ndef testArrayWeakType(self, funcname, input_type, val, dtype):\n    func = lambda x: getattr(jnp, funcname)(x, dtype=dtype)\n    fjit = jax.jit(func)\n    val = input_type(val)\n    expected_weak_type = dtype is None and input_type in set(dtypes._weak_types)\n    self.assertEqual(dtypes.is_weakly_typed(func(val)), expected_weak_type)\n    self.assertEqual(dtypes.is_weakly_typed(fjit(val)), expected_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    x, = promote_dtypes_complex(x)\n    return jnp.fft.irfft(jnp.concatenate([jnp.zeros_like(x, shape=1), x[:2] + 1j * x[2:]]))"
  },
  {
    "test_code": "@jtu.sample_product(copy=[None, True, False])\ndef testAsarrayCopy(self, copy):\n    x_jax = jnp.arange(4)\n    x_np = np.arange(4)\n    x_list = [0, 1, 2, 3]\n    x_buf = make_python_array('l', x_list)\n    func = partial(jnp.asarray, copy=copy)\n    self.assertArraysEqual(x_jax, func(x_jax))\n    self.assertArraysEqual(x_jax, func(x_list), check_dtypes=False)\n    if copy is False and jax.default_backend() != 'cpu':\n        self.assertRaises(ValueError, func, x_np)\n        self.assertRaises(ValueError, func, x_buf)\n    else:\n        self.assertArraysEqual(x_jax, func(x_np), check_dtypes=False)\n        self.assertArraysEqual(x_jax, func(x_buf), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    x, = promote_dtypes_complex(x)\n    return jnp.fft.irfft(jnp.concatenate([jnp.zeros_like(x, shape=1), x[:2] + 1j * x[2:]]))"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "@jtu.sample_product([dict(name=rec.name, np_op=getattr(np, rec.name), jnp_op=getattr(jnp, rec.name)) for rec in JAX_ARGMINMAX_RECORDS])\ndef testArgMinMaxEmpty(self, name, np_op, jnp_op):\n    name = name[3:] if name.startswith('nan') else name\n    msg = f'attempt to get {name} of an empty sequence'\n    with self.assertRaisesRegex(ValueError, msg):\n        jnp_op(np.array([]))\n    with self.assertRaisesRegex(ValueError, msg):\n        jnp_op(np.zeros((2, 0)), axis=1)\n    np_fun = jtu.with_jax_dtype_defaults(partial(np_op, axis=0))\n    jnp_fun = partial(jnp_op, axis=0)\n    args_maker = lambda: [np.zeros((2, 0))]\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product(shape=nonempty_array_shapes, dtype=all_dtypes)\ndef testExtractSize(self, shape, dtype):\n    rng = jtu.rand_some_zero(self.rng())\n    args_maker = lambda: [rng(shape, jnp.float32), rng(shape, dtype)]\n\n    def jnp_fun(condition, arr):\n        return jnp.extract(condition, arr, size=jnp.size(arr) - 1)\n\n    def np_fun(condition, arr):\n        size = jnp.size(arr) - 1\n        out = np.extract(condition, arr)\n        result = np.zeros(np.size(arr) - 1, dtype=dtype)\n        size = min(len(out), size)\n        result[:size] = out[:size]\n        return result\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, perm=perm) for shape in array_shapes for perm in [None, tuple(np.random.RandomState(0).permutation(np.zeros(shape).ndim)), tuple(np.random.RandomState(0).permutation(np.zeros(shape).ndim) - np.zeros(shape).ndim)]], dtype=default_dtypes, arg_type=['splat', 'value'])\ndef testTransposeTuple(self, shape, dtype, perm, arg_type):\n    rng = jtu.rand_some_zero(self.rng())\n    args_maker = lambda: [rng(shape, dtype)]\n    if arg_type == 'value':\n        np_fun = lambda x: x.transpose(perm)\n        jnp_fun = lambda x: jnp.array(x).transpose(perm)\n    else:\n        np_fun = lambda x: x.transpose(*(perm or ()))\n        jnp_fun = lambda x: jnp.array(x).transpose(*(perm or ()))\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(jnp_fun, args_maker, check_dtypes=True)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis) for shape in nonempty_nonscalar_array_shapes for axis in [None] + list(range(-len(shape), len(shape)))], dtype=all_dtypes, idx_shape=all_shapes)\ndef testDeleteIndexArray(self, shape, dtype, axis, idx_shape):\n    rng = jtu.rand_default(self.rng())\n    max_idx = np.zeros(shape).size if axis is None else np.zeros(shape).shape[axis]\n    idx = jtu.rand_int(self.rng(), low=-max_idx, high=max_idx)(idx_shape, int)\n    args_maker = lambda: [rng(shape, dtype)]\n    np_fun = lambda arg: np.delete(arg, idx, axis=axis)\n    jnp_fun = lambda arg: jnp.delete(arg, idx, axis=axis)\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis) for shape in nonempty_nonscalar_array_shapes for axis in [None] + list(range(-len(shape), len(shape)))], dtype=all_dtypes, idx_shape=all_shapes)\ndef testDeleteUniqueIndices(self, shape, dtype, axis, idx_shape):\n    rng = jtu.rand_default(self.rng())\n    max_idx = np.zeros(shape).size if axis is None else np.zeros(shape).shape[axis]\n    idx_size = np.zeros(idx_shape).size\n    if idx_size > max_idx:\n        self.skipTest('Too many indices to be unique')\n\n    def args_maker():\n        x = rng(shape, dtype)\n        idx = self.rng().choice(max_idx, idx_shape, replace=False)\n        return (x, idx)\n    np_fun = partial(np.delete, axis=axis)\n    jnp_fun = partial(jnp.delete, axis=axis, assume_unique_indices=True)\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis) for shape in nonempty_nonscalar_array_shapes for axis in [None] + list(range(-len(shape), len(shape)))], dtype=all_dtypes)\ndef testDeleteMaskArray(self, shape, dtype, axis):\n    rng = jtu.rand_default(self.rng())\n    mask_size = np.zeros(shape).size if axis is None else np.zeros(shape).shape[axis]\n    mask = jtu.rand_int(self.rng(), low=0, high=2)(mask_size, bool)\n    if numpy_version == (1, 23, 0) and mask.shape == (1,):\n        self.skipTest('test fails for numpy v1.23.0')\n    args_maker = lambda: [rng(shape, dtype)]\n    np_fun = lambda arg: np.delete(arg, mask, axis=axis)\n    jnp_fun = lambda arg: jnp.delete(arg, mask, axis=axis)\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, dtype=dtype, axis=axis) for shape, dtype in _shape_and_dtypes(all_shapes, default_dtypes) for axis in [None] + list(range(-len(shape), max(1, len(shape))))], repeats=[0, 1, 2], fixed_size=[False, True])\ndef testRepeat(self, axis, shape, dtype, repeats, fixed_size):\n    rng = jtu.rand_default(self.rng())\n    np_fun = lambda arg: np.repeat(arg, repeats=repeats, axis=axis)\n    np_fun = jtu.promote_like_jnp(np_fun)\n    if fixed_size:\n        total_repeat_length = np.repeat(np.zeros(shape), repeats, axis).shape[axis or 0]\n        jnp_fun = lambda arg, rep: jnp.repeat(arg, repeats=rep, axis=axis, total_repeat_length=total_repeat_length)\n        jnp_args_maker = lambda: [rng(shape, dtype), repeats]\n        clo_fun = lambda arg: jnp.repeat(arg, repeats=repeats, axis=axis, total_repeat_length=total_repeat_length)\n        clo_fun_args_maker = lambda: [rng(shape, dtype)]\n        self._CompileAndCheck(jnp_fun, jnp_args_maker)\n        self._CheckAgainstNumpy(np_fun, clo_fun, clo_fun_args_maker)\n    else:\n        jnp_fun = lambda arg: jnp.repeat(arg, repeats=repeats, axis=axis)\n        args_maker = lambda: [rng(shape, dtype)]\n        self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n        self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, dtype=dtype, axis=axis) for shape, dtype in _shape_and_dtypes(nonempty_nonscalar_array_shapes, default_dtypes) for axis in list(range(-len(shape), max(1, len(shape))))], prepend=[None, 1, 0], append=[None, 1, 0], n=[0, 1, 2])\ndef testDiff(self, shape, dtype, n, axis, prepend, append):\n    prepend = np.zeros(shape, dtype=dtype) if prepend == 0 else prepend\n    append = np.zeros(shape, dtype=dtype) if append == 0 else append\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(shape, dtype)]\n\n    def np_fun(x, n=n, axis=axis, prepend=prepend, append=append):\n        if prepend is None:\n            prepend = np._NoValue\n        elif not np.isscalar(prepend) and prepend.dtype == jnp.bfloat16:\n            prepend = prepend.astype(np.float32)\n        if append is None:\n            append = np._NoValue\n        elif not np.isscalar(append) and append.dtype == jnp.bfloat16:\n            append = append.astype(np.float32)\n        if x.dtype == jnp.bfloat16:\n            return np.diff(x.astype(np.float32), n=n, axis=axis, prepend=prepend, append=append).astype(jnp.bfloat16)\n        else:\n            return np.diff(x, n=n, axis=axis, prepend=prepend, append=append)\n    jnp_fun = lambda x: jnp.diff(x, n=n, axis=axis, prepend=prepend, append=append)\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, check_dtypes=False)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testDuckTypedLike(self):\n    x = jax.ShapeDtypeStruct((1, 2, 3), np.dtype('int32'))\n    self.assertArraysEqual(jnp.zeros_like(x), jnp.zeros(x.shape, x.dtype))\n    self.assertArraysEqual(jnp.ones_like(x), jnp.ones(x.shape, x.dtype))\n    self.assertArraysEqual(jnp.empty_like(x), jnp.empty(x.shape, x.dtype))\n    self.assertArraysEqual(jnp.full_like(x, 2), jnp.full(x.shape, 2, x.dtype))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testSplitTypeError(self):\n    self.assertEqual(3, len(jnp.split(jnp.zeros(3), jnp.array([1, 2]))))\n    CONCRETIZATION_MSG = 'Abstract tracer value encountered where concrete value is expected.'\n    with self.assertRaisesRegex(TypeError, CONCRETIZATION_MSG):\n        jax.jit(lambda idx: jnp.split(jnp.zeros((12, 2)), idx))(2.0)\n    with self.assertRaisesRegex(TypeError, CONCRETIZATION_MSG):\n        jax.jit(lambda idx: jnp.split(jnp.zeros((12, 2)), [2, idx]))(2.0)\n    jax.jvp(lambda idx: jnp.split(jnp.zeros((12, 2)), idx), (2.0,), (1.0,))\n    jax.jvp(lambda idx: jnp.split(jnp.zeros((12, 2)), (1, idx.astype(np.int32))), (2.0,), (1.0,))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product(input=[3, [3], [np.array(3)], [np.array([3])], [[np.array(3)]], [[np.array([3])]], [3, 4, 5], [[np.eye(2, dtype=np.int32) * 2, np.zeros((2, 3), dtype=np.int32)], [np.ones((3, 2), dtype=np.int32), np.eye(3, dtype=np.int32) * 3]], [np.array([1, 2, 3]), np.array([2, 3, 4]), 10], [np.ones((2, 2), dtype=np.int32), np.zeros((2, 2), dtype=np.int32)], [[np.array([1, 2, 3])], [np.array([2, 3, 4])]]])\ndef testBlock(self, input):\n    args_maker = lambda: [input]\n    self._CheckAgainstNumpy(np.block, jnp.block, args_maker)\n    self._CompileAndCheck(jnp.block, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testIssue967(self):\n    self.assertRaises(TypeError, lambda: jnp.zeros(1.5))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testStackArrayArgument(self):\n\n    @jax.jit\n    def foo(x):\n        return jnp.stack(x)\n    foo(np.zeros(2))\n\n    @jax.jit\n    def foo(x):\n        return jnp.concatenate(x)\n    foo(np.zeros((2, 2)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testReluGradientConstants(self):\n\n    def body(i, xy):\n        x, y = xy\n        y = y + jax.grad(lambda z: jnp.sum(jnp.maximum(z, 0.0)))(x)\n        return (x, y)\n    f = lambda y: lax.fori_loop(0, 5, body, (y, y))\n    jaxpr = jax.make_jaxpr(f)(np.zeros((3, 4), np.float32))\n    self.assertFalse(any((np.array_equal(x, np.full((3, 4), 2.0, dtype=np.float32)) for x in jaxpr.consts)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testBroadcastToInvalidShape(self):\n    x = jnp.zeros((3, 4, 5))\n    with self.assertRaisesRegex(ValueError, 'Cannot broadcast to shape with fewer dimensions'):\n        jnp.broadcast_to(x, (4, 5))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def testZerosShapeErrors(self):\n    self.assertRaisesRegex(TypeError, 'Shapes must be 1D sequences of concrete values of integer type.*', lambda: jnp.zeros(1.0))\n    self.assertRaisesRegex(TypeError, 'Shapes must be 1D sequences of concrete values of integer type.*\\\\nIf using `jit`, try using `static_argnums` or applying `jit` to smaller subfunctions.', lambda: jax.jit(jnp.zeros)(2))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.sample_product(dtype=inexact_dtypes, side=['left', 'right'], method=['sort', 'scan', 'compare_all'])\ndef testSearchsortedNans(self, dtype, side, method):\n    if np.issubdtype(dtype, np.complexfloating):\n        raise SkipTest('Known failure for complex inputs; see #9107')\n    x = np.array([-np.inf, -1.0, 0.0, -0.0, 1.0, np.inf, np.nan, -np.nan], dtype=dtype)\n    x_equiv = np.array([0, 1, 2, 2, 3, 4, 5, 5])\n    if jnp.issubdtype(dtype, jnp.complexfloating):\n        x = np.array([complex(r, c) for r, c in itertools.product(x, repeat=2)])\n        x_equiv = np.array([complex(r, c) for r, c in itertools.product(x_equiv, repeat=2)])\n    fun = partial(jnp.searchsorted, side=side, method=method)\n    self.assertArraysEqual(fun(x, x), fun(x_equiv, x_equiv))\n    self.assertArraysEqual(jax.jit(fun)(x, x), fun(x_equiv, x_equiv))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=('n',))\ndef fun(x):\n    return jnp.sum(x)"
  },
  {
    "test_code": "@jtu.sample_product([dict(func=func, args=args) for func, args in [('full_like', (-100,)), ('ones_like', ()), ('zeros_like', ())]], shape=array_shapes, in_dtype=[np.int32, np.float32, np.complex64], weak_type=[True, False], out_shape=[None, (), (10,)], out_dtype=[None, float])\ndef testZerosOnesFullLikeWeakType(self, func, args, shape, in_dtype, weak_type, out_shape, out_dtype):\n    rng = jtu.rand_default(self.rng())\n    x = lax_internal._convert_element_type(rng(shape, in_dtype), weak_type=weak_type)\n    fun = lambda x: getattr(jnp, func)(x, *args, dtype=out_dtype, shape=out_shape)\n    expected_weak_type = weak_type and out_dtype is None\n    self.assertEqual(dtypes.is_weakly_typed(fun(x)), expected_weak_type)\n    self.assertEqual(dtypes.is_weakly_typed(jax.jit(fun)(x)), expected_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=('n',))\ndef fun(x):\n    return jnp.sum(x)"
  },
  {
    "test_code": "def testZeroStridesConstantHandler(self):\n    raw_const = self.rng().randn(1, 2, 1, 1, 5, 1)\n    const = np.broadcast_to(raw_const, (3, 2, 3, 4, 5, 6))\n\n    def fun(x):\n        return x * const\n    fun = jax.jit(fun)\n    out_val = fun(3.0)\n    self.assertAllClose(out_val, 3.0 * const, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, abstracted_axes=('n',))\ndef fun(x):\n    return jnp.sum(x)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis, num_sections=num_sections) for shape, axis, num_sections in [((12, 4), 0, 4), ((12,), 1, 2), ((2, 3, 4), 2, 2), ((4, 3, 4), 0, 2)]], dtype=default_dtypes)\ndef testHVDSplit(self, shape, num_sections, axis, dtype):\n    rng = jtu.rand_default(self.rng())\n\n    def fn(module, axis):\n        if axis == 0:\n            return module.vsplit\n        elif axis == 1:\n            return module.hsplit\n        else:\n            assert axis == 2\n            return module.dsplit\n    np_fun = lambda x: fn(np, axis)(x, num_sections)\n    jnp_fun = lambda x: fn(jnp, axis)(x, num_sections)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [
      "assert axis == 2"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef fn(n, x):\n    return lax.broadcast_in_dim(x, (n,), ())"
  },
  {
    "test_code": "@parameterized.named_parameters(('ones', jnp.ones), ('zeros', jnp.zeros), ('empty', jnp.empty))\ndef test_error_hint(self, fn):\n    with self.assertRaisesRegex(TypeError, 'Did you accidentally write `jax\\\\.numpy\\\\..*?\\\\(2, 3\\\\)` when you meant `jax\\\\.numpy\\\\..*?\\\\(\\\\(2, 3\\\\)\\\\)`'):\n        fn(2, 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef fn(n, x):\n    return lax.broadcast_in_dim(x, (n,), ())"
  },
  {
    "test_code": "def testStackArrayArgument(self):\n\n    @jax.jit\n    def foo(x):\n        return jnp.stack(x)\n    foo(np.zeros(2))\n\n    @jax.jit\n    def foo(x):\n        return jnp.concatenate(x)\n    foo(np.zeros((2, 2)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def foo(x, y):\n    z = jax.vmap(jax.vmap(jnp.sin))(x) * y\n    return jax.vmap(jax.vmap(jnp.add))(x, z)"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty, jnp.zeros, jnp.ones, jnp.full], shape=array_shapes, dtype=default_dtypes)\ndef testArrayCreationWithDevice(self, func, shape, dtype):\n    device = jax.devices()[-1]\n    kwds = {'fill_value': 1} if func is jnp.full else {}\n    out = func(**kwds, shape=shape, dtype=dtype, device=device)\n    self.assertEqual(out.devices(), {device})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(size):\n    lhs_one_d = jnp.arange(size, dtype='int32') + 1\n    lhs_two_d = jax.lax.broadcast_in_dim(lhs_one_d, (size, 2), (0,))\n    rhs = jax.lax.broadcasted_iota('int32', (2, 4), 0) + 1\n    return jnp.dot(lhs_two_d, rhs)"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty, jnp.zeros, jnp.ones, jnp.full], shape=array_shapes, dtype=default_dtypes)\ndef testArrayCreationWithSharding(self, func, shape, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    kwds = {'fill_value': 1} if func is jnp.full else {}\n    out = func(**kwds, shape=shape, dtype=dtype, device=sharding)\n    self.assertEqual(out.sharding, sharding)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(size):\n    lhs_one_d = jnp.arange(size, dtype='int32') + 1\n    lhs_two_d = jax.lax.broadcast_in_dim(lhs_one_d, (size, 2), (0,))\n    rhs = jax.lax.broadcasted_iota('int32', (2, 4), 0) + 1\n    return jnp.dot(lhs_two_d, rhs)"
  },
  {
    "test_code": "@jtu.sample_product(func=[lambda dtype, device: jnp.arange(5, dtype=dtype, device=device), lambda dtype, device: jnp.eye(5, 6, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, retstep=True, dtype=dtype, device=device), lambda dtype, device: jnp.array([1, 2, 3, 4, 5], dtype=dtype, device=device)], dtype=default_dtypes)\ndef testArangeEyeLinspaceArrayWithDevice(self, func, dtype):\n    device = jax.devices()[-1]\n    output = func(dtype=dtype, device=device)\n    if isinstance(output, tuple):\n        self.assertEqual(output[0].devices(), {device})\n    else:\n        self.assertEqual(output.devices(), {device})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(size):\n    lhs_one_d = jnp.arange(size, dtype='int32') + 1\n    lhs_two_d = jax.lax.broadcast_in_dim(lhs_one_d, (size, 2), (0,))\n    rhs = jax.lax.broadcasted_iota('int32', (2, 4), 0) + 1\n    return jnp.dot(lhs_two_d, rhs)"
  },
  {
    "test_code": "@jtu.sample_product(func=[lambda dtype, device: jnp.arange(5, dtype=dtype, device=device), lambda dtype, device: jnp.eye(5, 6, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, retstep=True, dtype=dtype, device=device), lambda dtype, device: jnp.array([1, 2, 3, 4, 5], dtype=dtype, device=device)], dtype=default_dtypes)\ndef testArangeEyeLinspaceArrayWithSharding(self, func, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    output = func(dtype=dtype, device=sharding)\n    if isinstance(output, tuple):\n        self.assertEqual(output[0].sharding, sharding)\n    else:\n        self.assertEqual(output.sharding, sharding)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(size):\n    lhs_one_d = jnp.arange(size, dtype='int32') + 1\n    lhs_two_d = jax.lax.broadcast_in_dim(lhs_one_d, (size, 2), (0,))\n    rhs = jax.lax.broadcasted_iota('int32', (2, 4), 0) + 1\n    return jnp.dot(lhs_two_d, rhs)"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty_like, jnp.zeros_like, jnp.ones_like, jnp.full_like], shape=array_shapes, dtype=default_dtypes)\ndef testFullLikeWithDevice(self, func, shape, dtype):\n    device = jax.devices()[-1]\n    rng = jtu.rand_default(self.rng())\n    x = rng(shape, dtype)\n    kwds = {'fill_value': 1} if func is jnp.full_like else {}\n    with self.subTest('device from keyword'):\n        out = func(x, **kwds, device=device)\n        self.assertEqual(out.devices(), {device})\n    with self.subTest('device from input array'):\n        out2 = func(out, **kwds)\n        self.assertEqual(out2.devices(), out.devices())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(size):\n    lhs_one_d = jnp.arange(size, dtype='int32') + 1\n    lhs_two_d = jax.lax.broadcast_in_dim(lhs_one_d, (size, 2), (0,))\n    rhs = jax.lax.broadcasted_iota('int32', (2, 4), 0) + 1\n    return jnp.dot(lhs_two_d, rhs)"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty_like, jnp.zeros_like, jnp.ones_like, jnp.full_like], shape=array_shapes, dtype=default_dtypes)\ndef testFullLikeWithSharding(self, func, shape, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    rng = jtu.rand_default(self.rng())\n    x = rng(shape, dtype)\n    kwds = {'fill_value': 1} if func is jnp.full_like else {}\n    with self.subTest('device from keyword'):\n        out = func(x, **kwds, device=sharding)\n        self.assertEqual(out.sharding, sharding)\n    with self.subTest('device from input array'):\n        out2 = func(out, **kwds)\n        self.assertEqual(out2.devices(), out.devices())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(size):\n    lhs_one_d = jnp.arange(size, dtype='int32') + 1\n    lhs_two_d = jax.lax.broadcast_in_dim(lhs_one_d, (size, 2), (0,))\n    rhs = jax.lax.broadcasted_iota('int32', (2, 4), 0) + 1\n    return jnp.dot(lhs_two_d, rhs)"
  },
  {
    "test_code": "@jtu.sample_product(funcname=['array', 'asarray'], dtype=[int, float, None], val=[0, 1], input_type=[int, float, np.int32, np.float32])\ndef testArrayWeakType(self, funcname, input_type, val, dtype):\n    func = lambda x: getattr(jnp, funcname)(x, dtype=dtype)\n    fjit = jax.jit(func)\n    val = input_type(val)\n    expected_weak_type = dtype is None and input_type in set(dtypes._weak_types)\n    self.assertEqual(dtypes.is_weakly_typed(func(val)), expected_weak_type)\n    self.assertEqual(dtypes.is_weakly_typed(fjit(val)), expected_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(size):\n    lhs_one_d = jnp.arange(size, dtype='int32') + 1\n    lhs_two_d = jax.lax.broadcast_in_dim(lhs_one_d, (size, 2), (0,))\n    rhs = jax.lax.broadcasted_iota('int32', (2, 4), 0) + 1\n    return jnp.dot(lhs_two_d, rhs)"
  },
  {
    "test_code": "@jtu.sample_product(copy=[None, True, False])\ndef testAsarrayCopy(self, copy):\n    x_jax = jnp.arange(4)\n    x_np = np.arange(4)\n    x_list = [0, 1, 2, 3]\n    x_buf = make_python_array('l', x_list)\n    func = partial(jnp.asarray, copy=copy)\n    self.assertArraysEqual(x_jax, func(x_jax))\n    self.assertArraysEqual(x_jax, func(x_list), check_dtypes=False)\n    if copy is False and jax.default_backend() != 'cpu':\n        self.assertRaises(ValueError, func, x_np)\n        self.assertRaises(ValueError, func, x_buf)\n    else:\n        self.assertArraysEqual(x_jax, func(x_np), check_dtypes=False)\n        self.assertArraysEqual(x_jax, func(x_buf), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(size):\n    lhs_one_d = jnp.arange(size, dtype='int32') + 1\n    lhs_two_d = jax.lax.broadcast_in_dim(lhs_one_d, (size, 2), (0,))\n    rhs = jax.lax.broadcasted_iota('int32', (2, 4), 0) + 1\n    return jnp.dot(lhs_two_d, rhs)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef g():\n    return jnp.zeros(n) + x"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef g():\n    return jnp.zeros(n) + x"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty, jnp.zeros, jnp.ones, jnp.full], shape=array_shapes, dtype=default_dtypes)\ndef testArrayCreationWithDevice(self, func, shape, dtype):\n    device = jax.devices()[-1]\n    kwds = {'fill_value': 1} if func is jnp.full else {}\n    out = func(**kwds, shape=shape, dtype=dtype, device=device)\n    self.assertEqual(out.devices(), {device})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    return jax.random.uniform(x, (2, 4), dtype=np.float32)"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty, jnp.zeros, jnp.ones, jnp.full], shape=array_shapes, dtype=default_dtypes)\ndef testArrayCreationWithSharding(self, func, shape, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    kwds = {'fill_value': 1} if func is jnp.full else {}\n    out = func(**kwds, shape=shape, dtype=dtype, device=sharding)\n    self.assertEqual(out.sharding, sharding)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    return jax.random.uniform(x, (2, 4), dtype=np.float32)"
  },
  {
    "test_code": "@jtu.sample_product(func=[lambda dtype, device: jnp.arange(5, dtype=dtype, device=device), lambda dtype, device: jnp.eye(5, 6, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, retstep=True, dtype=dtype, device=device), lambda dtype, device: jnp.array([1, 2, 3, 4, 5], dtype=dtype, device=device)], dtype=default_dtypes)\ndef testArangeEyeLinspaceArrayWithDevice(self, func, dtype):\n    device = jax.devices()[-1]\n    output = func(dtype=dtype, device=device)\n    if isinstance(output, tuple):\n        self.assertEqual(output[0].devices(), {device})\n    else:\n        self.assertEqual(output.devices(), {device})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    return jax.random.uniform(x, (2, 4), dtype=np.float32)"
  },
  {
    "test_code": "@jtu.sample_product(func=[lambda dtype, device: jnp.arange(5, dtype=dtype, device=device), lambda dtype, device: jnp.eye(5, 6, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, retstep=True, dtype=dtype, device=device), lambda dtype, device: jnp.array([1, 2, 3, 4, 5], dtype=dtype, device=device)], dtype=default_dtypes)\ndef testArangeEyeLinspaceArrayWithSharding(self, func, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    output = func(dtype=dtype, device=sharding)\n    if isinstance(output, tuple):\n        self.assertEqual(output[0].sharding, sharding)\n    else:\n        self.assertEqual(output.sharding, sharding)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    return jax.random.uniform(x, (2, 4), dtype=np.float32)"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty_like, jnp.zeros_like, jnp.ones_like, jnp.full_like], shape=array_shapes, dtype=default_dtypes)\ndef testFullLikeWithDevice(self, func, shape, dtype):\n    device = jax.devices()[-1]\n    rng = jtu.rand_default(self.rng())\n    x = rng(shape, dtype)\n    kwds = {'fill_value': 1} if func is jnp.full_like else {}\n    with self.subTest('device from keyword'):\n        out = func(x, **kwds, device=device)\n        self.assertEqual(out.devices(), {device})\n    with self.subTest('device from input array'):\n        out2 = func(out, **kwds)\n        self.assertEqual(out2.devices(), out.devices())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    return jax.random.uniform(x, (2, 4), dtype=np.float32)"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty_like, jnp.zeros_like, jnp.ones_like, jnp.full_like], shape=array_shapes, dtype=default_dtypes)\ndef testFullLikeWithSharding(self, func, shape, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    rng = jtu.rand_default(self.rng())\n    x = rng(shape, dtype)\n    kwds = {'fill_value': 1} if func is jnp.full_like else {}\n    with self.subTest('device from keyword'):\n        out = func(x, **kwds, device=sharding)\n        self.assertEqual(out.sharding, sharding)\n    with self.subTest('device from input array'):\n        out2 = func(out, **kwds)\n        self.assertEqual(out2.devices(), out.devices())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    return jax.random.uniform(x, (2, 4), dtype=np.float32)"
  },
  {
    "test_code": "@jtu.sample_product(funcname=['array', 'asarray'], dtype=[int, float, None], val=[0, 1], input_type=[int, float, np.int32, np.float32])\ndef testArrayWeakType(self, funcname, input_type, val, dtype):\n    func = lambda x: getattr(jnp, funcname)(x, dtype=dtype)\n    fjit = jax.jit(func)\n    val = input_type(val)\n    expected_weak_type = dtype is None and input_type in set(dtypes._weak_types)\n    self.assertEqual(dtypes.is_weakly_typed(func(val)), expected_weak_type)\n    self.assertEqual(dtypes.is_weakly_typed(fjit(val)), expected_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    return jax.random.uniform(x, (2, 4), dtype=np.float32)"
  },
  {
    "test_code": "@jtu.sample_product(copy=[None, True, False])\ndef testAsarrayCopy(self, copy):\n    x_jax = jnp.arange(4)\n    x_np = np.arange(4)\n    x_list = [0, 1, 2, 3]\n    x_buf = make_python_array('l', x_list)\n    func = partial(jnp.asarray, copy=copy)\n    self.assertArraysEqual(x_jax, func(x_jax))\n    self.assertArraysEqual(x_jax, func(x_list), check_dtypes=False)\n    if copy is False and jax.default_backend() != 'cpu':\n        self.assertRaises(ValueError, func, x_np)\n        self.assertRaises(ValueError, func, x_buf)\n    else:\n        self.assertArraysEqual(x_jax, func(x_np), check_dtypes=False)\n        self.assertArraysEqual(x_jax, func(x_buf), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(x):\n    return jax.random.uniform(x, (2, 4), dtype=np.float32)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "@jtu.sample_product(dtype=inexact_dtypes, side=['left', 'right'], method=['sort', 'scan', 'compare_all'])\ndef testSearchsortedNans(self, dtype, side, method):\n    if np.issubdtype(dtype, np.complexfloating):\n        raise SkipTest('Known failure for complex inputs; see #9107')\n    x = np.array([-np.inf, -1.0, 0.0, -0.0, 1.0, np.inf, np.nan, -np.nan], dtype=dtype)\n    x_equiv = np.array([0, 1, 2, 2, 3, 4, 5, 5])\n    if jnp.issubdtype(dtype, jnp.complexfloating):\n        x = np.array([complex(r, c) for r, c in itertools.product(x, repeat=2)])\n        x_equiv = np.array([complex(r, c) for r, c in itertools.product(x_equiv, repeat=2)])\n    fun = partial(jnp.searchsorted, side=side, method=method)\n    self.assertArraysEqual(fun(x, x), fun(x_equiv, x_equiv))\n    self.assertArraysEqual(jax.jit(fun)(x, x), fun(x_equiv, x_equiv))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef fun(x, y):\n    return cond(x < 3, None, lambda _: 2.0 * jnp.sin(y), x, lambda x: 2.0 * x)"
  },
  {
    "test_code": "@jtu.sample_product([dict(func=func, args=args) for func, args in [('full_like', (-100,)), ('ones_like', ()), ('zeros_like', ())]], shape=array_shapes, in_dtype=[np.int32, np.float32, np.complex64], weak_type=[True, False], out_shape=[None, (), (10,)], out_dtype=[None, float])\ndef testZerosOnesFullLikeWeakType(self, func, args, shape, in_dtype, weak_type, out_shape, out_dtype):\n    rng = jtu.rand_default(self.rng())\n    x = lax_internal._convert_element_type(rng(shape, in_dtype), weak_type=weak_type)\n    fun = lambda x: getattr(jnp, func)(x, *args, dtype=out_dtype, shape=out_shape)\n    expected_weak_type = weak_type and out_dtype is None\n    self.assertEqual(dtypes.is_weakly_typed(fun(x)), expected_weak_type)\n    self.assertEqual(dtypes.is_weakly_typed(jax.jit(fun)(x)), expected_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef fun(x, y):\n    return cond(x < 3, None, lambda _: 2.0 * jnp.sin(y), x, lambda x: 2.0 * x)"
  },
  {
    "test_code": "def testZeroStridesConstantHandler(self):\n    raw_const = self.rng().randn(1, 2, 1, 1, 5, 1)\n    const = np.broadcast_to(raw_const, (3, 2, 3, 4, 5, 6))\n\n    def fun(x):\n        return x * const\n    fun = jax.jit(fun)\n    out_val = fun(3.0)\n    self.assertAllClose(out_val, 3.0 * const, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef fun(x, y):\n    return cond(x < 3, None, lambda _: 2.0 * jnp.sin(y), x, lambda x: 2.0 * x)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def g():\n    return jax.lax.cond(True, lambda: data[0], lambda: data[1])"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def g():\n    return jax.lax.cond(True, lambda: data[0], lambda: data[1])"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis, num_sections=num_sections) for shape, axis, num_sections in [((12, 4), 0, 4), ((12,), 1, 2), ((2, 3, 4), 2, 2), ((4, 3, 4), 0, 2)]], dtype=default_dtypes)\ndef testHVDSplit(self, shape, num_sections, axis, dtype):\n    rng = jtu.rand_default(self.rng())\n\n    def fn(module, axis):\n        if axis == 0:\n            return module.vsplit\n        elif axis == 1:\n            return module.hsplit\n        else:\n            assert axis == 2\n            return module.dsplit\n    np_fun = lambda x: fn(np, axis)(x, num_sections)\n    jnp_fun = lambda x: fn(jnp, axis)(x, num_sections)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [
      "assert axis == 2"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\ndef fn(a, b):\n    m1, v1 = a\n    m2, v2 = b\n    return (m1 + m2, jsp.linalg.solve(m1, v2) + jsp.linalg.solve(m2, v1))"
  },
  {
    "test_code": "@parameterized.named_parameters(('ones', jnp.ones), ('zeros', jnp.zeros), ('empty', jnp.empty))\ndef test_error_hint(self, fn):\n    with self.assertRaisesRegex(TypeError, 'Did you accidentally write `jax\\\\.numpy\\\\..*?\\\\(2, 3\\\\)` when you meant `jax\\\\.numpy\\\\..*?\\\\(\\\\(2, 3\\\\)\\\\)`'):\n        fn(2, 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\ndef fn(a, b):\n    m1, v1 = a\n    m2, v2 = b\n    return (m1 + m2, jsp.linalg.solve(m1, v2) + jsp.linalg.solve(m2, v1))"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef g():\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef g():\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def g(a, b):\n    c = jnp.zeros_like(a)\n    _, b, c, _ = for_impl(5, body2, (a, b, c, 0))\n    return (b, c)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def g(a, b):\n    c = jnp.zeros_like(a)\n    _, b, c, _ = for_impl(5, body2, (a, b, c, 0))\n    return (b, c)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "@jtu.sample_product(dtype=inexact_dtypes, side=['left', 'right'], method=['sort', 'scan', 'compare_all'])\ndef testSearchsortedNans(self, dtype, side, method):\n    if np.issubdtype(dtype, np.complexfloating):\n        raise SkipTest('Known failure for complex inputs; see #9107')\n    x = np.array([-np.inf, -1.0, 0.0, -0.0, 1.0, np.inf, np.nan, -np.nan], dtype=dtype)\n    x_equiv = np.array([0, 1, 2, 2, 3, 4, 5, 5])\n    if jnp.issubdtype(dtype, jnp.complexfloating):\n        x = np.array([complex(r, c) for r, c in itertools.product(x, repeat=2)])\n        x_equiv = np.array([complex(r, c) for r, c in itertools.product(x_equiv, repeat=2)])\n    fun = partial(jnp.searchsorted, side=side, method=method)\n    self.assertArraysEqual(fun(x, x), fun(x_equiv, x_equiv))\n    self.assertArraysEqual(jax.jit(fun)(x, x), fun(x_equiv, x_equiv))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def fun():\n    return jax.ffi.ffi_call('test', jax.ShapeDtypeStruct((), np.int64))()"
  },
  {
    "test_code": "@jtu.sample_product([dict(func=func, args=args) for func, args in [('full_like', (-100,)), ('ones_like', ()), ('zeros_like', ())]], shape=array_shapes, in_dtype=[np.int32, np.float32, np.complex64], weak_type=[True, False], out_shape=[None, (), (10,)], out_dtype=[None, float])\ndef testZerosOnesFullLikeWeakType(self, func, args, shape, in_dtype, weak_type, out_shape, out_dtype):\n    rng = jtu.rand_default(self.rng())\n    x = lax_internal._convert_element_type(rng(shape, in_dtype), weak_type=weak_type)\n    fun = lambda x: getattr(jnp, func)(x, *args, dtype=out_dtype, shape=out_shape)\n    expected_weak_type = weak_type and out_dtype is None\n    self.assertEqual(dtypes.is_weakly_typed(fun(x)), expected_weak_type)\n    self.assertEqual(dtypes.is_weakly_typed(jax.jit(fun)(x)), expected_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def fun():\n    return jax.ffi.ffi_call('test', jax.ShapeDtypeStruct((), np.int64))()"
  },
  {
    "test_code": "def testZeroStridesConstantHandler(self):\n    raw_const = self.rng().randn(1, 2, 1, 1, 5, 1)\n    const = np.broadcast_to(raw_const, (3, 2, 3, 4, 5, 6))\n\n    def fun(x):\n        return x * const\n    fun = jax.jit(fun)\n    out_val = fun(3.0)\n    self.assertAllClose(out_val, 3.0 * const, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def fun():\n    return jax.ffi.ffi_call('test', jax.ShapeDtypeStruct((), np.int64))()"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty, jnp.zeros, jnp.ones, jnp.full], shape=array_shapes, dtype=default_dtypes)\ndef testArrayCreationWithDevice(self, func, shape, dtype):\n    device = jax.devices()[-1]\n    kwds = {'fill_value': 1} if func is jnp.full else {}\n    out = func(**kwds, shape=shape, dtype=dtype, device=device)\n    self.assertEqual(out.devices(), {device})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(xs):\n    return jnp.array(list(xs))"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty, jnp.zeros, jnp.ones, jnp.full], shape=array_shapes, dtype=default_dtypes)\ndef testArrayCreationWithSharding(self, func, shape, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    kwds = {'fill_value': 1} if func is jnp.full else {}\n    out = func(**kwds, shape=shape, dtype=dtype, device=sharding)\n    self.assertEqual(out.sharding, sharding)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(xs):\n    return jnp.array(list(xs))"
  },
  {
    "test_code": "@jtu.sample_product(func=[lambda dtype, device: jnp.arange(5, dtype=dtype, device=device), lambda dtype, device: jnp.eye(5, 6, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, retstep=True, dtype=dtype, device=device), lambda dtype, device: jnp.array([1, 2, 3, 4, 5], dtype=dtype, device=device)], dtype=default_dtypes)\ndef testArangeEyeLinspaceArrayWithDevice(self, func, dtype):\n    device = jax.devices()[-1]\n    output = func(dtype=dtype, device=device)\n    if isinstance(output, tuple):\n        self.assertEqual(output[0].devices(), {device})\n    else:\n        self.assertEqual(output.devices(), {device})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(xs):\n    return jnp.array(list(xs))"
  },
  {
    "test_code": "@jtu.sample_product(func=[lambda dtype, device: jnp.arange(5, dtype=dtype, device=device), lambda dtype, device: jnp.eye(5, 6, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, dtype=dtype, device=device), lambda dtype, device: jnp.linspace(5, 6, 7, retstep=True, dtype=dtype, device=device), lambda dtype, device: jnp.array([1, 2, 3, 4, 5], dtype=dtype, device=device)], dtype=default_dtypes)\ndef testArangeEyeLinspaceArrayWithSharding(self, func, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    output = func(dtype=dtype, device=sharding)\n    if isinstance(output, tuple):\n        self.assertEqual(output[0].sharding, sharding)\n    else:\n        self.assertEqual(output.sharding, sharding)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(xs):\n    return jnp.array(list(xs))"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty_like, jnp.zeros_like, jnp.ones_like, jnp.full_like], shape=array_shapes, dtype=default_dtypes)\ndef testFullLikeWithDevice(self, func, shape, dtype):\n    device = jax.devices()[-1]\n    rng = jtu.rand_default(self.rng())\n    x = rng(shape, dtype)\n    kwds = {'fill_value': 1} if func is jnp.full_like else {}\n    with self.subTest('device from keyword'):\n        out = func(x, **kwds, device=device)\n        self.assertEqual(out.devices(), {device})\n    with self.subTest('device from input array'):\n        out2 = func(out, **kwds)\n        self.assertEqual(out2.devices(), out.devices())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(xs):\n    return jnp.array(list(xs))"
  },
  {
    "test_code": "@jtu.sample_product(func=[jnp.empty_like, jnp.zeros_like, jnp.ones_like, jnp.full_like], shape=array_shapes, dtype=default_dtypes)\ndef testFullLikeWithSharding(self, func, shape, dtype):\n    sharding = SingleDeviceSharding(jax.devices()[-1])\n    rng = jtu.rand_default(self.rng())\n    x = rng(shape, dtype)\n    kwds = {'fill_value': 1} if func is jnp.full_like else {}\n    with self.subTest('device from keyword'):\n        out = func(x, **kwds, device=sharding)\n        self.assertEqual(out.sharding, sharding)\n    with self.subTest('device from input array'):\n        out2 = func(out, **kwds)\n        self.assertEqual(out2.devices(), out.devices())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(xs):\n    return jnp.array(list(xs))"
  },
  {
    "test_code": "@jtu.sample_product(funcname=['array', 'asarray'], dtype=[int, float, None], val=[0, 1], input_type=[int, float, np.int32, np.float32])\ndef testArrayWeakType(self, funcname, input_type, val, dtype):\n    func = lambda x: getattr(jnp, funcname)(x, dtype=dtype)\n    fjit = jax.jit(func)\n    val = input_type(val)\n    expected_weak_type = dtype is None and input_type in set(dtypes._weak_types)\n    self.assertEqual(dtypes.is_weakly_typed(func(val)), expected_weak_type)\n    self.assertEqual(dtypes.is_weakly_typed(fjit(val)), expected_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(xs):\n    return jnp.array(list(xs))"
  },
  {
    "test_code": "@jtu.sample_product(copy=[None, True, False])\ndef testAsarrayCopy(self, copy):\n    x_jax = jnp.arange(4)\n    x_np = np.arange(4)\n    x_list = [0, 1, 2, 3]\n    x_buf = make_python_array('l', x_list)\n    func = partial(jnp.asarray, copy=copy)\n    self.assertArraysEqual(x_jax, func(x_jax))\n    self.assertArraysEqual(x_jax, func(x_list), check_dtypes=False)\n    if copy is False and jax.default_backend() != 'cpu':\n        self.assertRaises(ValueError, func, x_np)\n        self.assertRaises(ValueError, func, x_buf)\n    else:\n        self.assertArraysEqual(x_jax, func(x_np), check_dtypes=False)\n        self.assertArraysEqual(x_jax, func(x_buf), check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def func(xs):\n    return jnp.array(list(xs))"
  },
  {
    "test_code": "@jtu.sample_product(dtype=inexact_dtypes, side=['left', 'right'], method=['sort', 'scan', 'compare_all'])\ndef testSearchsortedNans(self, dtype, side, method):\n    if np.issubdtype(dtype, np.complexfloating):\n        raise SkipTest('Known failure for complex inputs; see #9107')\n    x = np.array([-np.inf, -1.0, 0.0, -0.0, 1.0, np.inf, np.nan, -np.nan], dtype=dtype)\n    x_equiv = np.array([0, 1, 2, 2, 3, 4, 5, 5])\n    if jnp.issubdtype(dtype, jnp.complexfloating):\n        x = np.array([complex(r, c) for r, c in itertools.product(x, repeat=2)])\n        x_equiv = np.array([complex(r, c) for r, c in itertools.product(x_equiv, repeat=2)])\n    fun = partial(jnp.searchsorted, side=side, method=method)\n    self.assertArraysEqual(fun(x, x), fun(x_equiv, x_equiv))\n    self.assertArraysEqual(jax.jit(fun)(x, x), fun(x_equiv, x_equiv))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def fun(x, t):\n    return jnp.sum(jnp.power(jnp.maximum(x, 0.0), 2)) + t"
  },
  {
    "test_code": "@jtu.sample_product([dict(func=func, args=args) for func, args in [('full_like', (-100,)), ('ones_like', ()), ('zeros_like', ())]], shape=array_shapes, in_dtype=[np.int32, np.float32, np.complex64], weak_type=[True, False], out_shape=[None, (), (10,)], out_dtype=[None, float])\ndef testZerosOnesFullLikeWeakType(self, func, args, shape, in_dtype, weak_type, out_shape, out_dtype):\n    rng = jtu.rand_default(self.rng())\n    x = lax_internal._convert_element_type(rng(shape, in_dtype), weak_type=weak_type)\n    fun = lambda x: getattr(jnp, func)(x, *args, dtype=out_dtype, shape=out_shape)\n    expected_weak_type = weak_type and out_dtype is None\n    self.assertEqual(dtypes.is_weakly_typed(fun(x)), expected_weak_type)\n    self.assertEqual(dtypes.is_weakly_typed(jax.jit(fun)(x)), expected_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def fun(x, t):\n    return jnp.sum(jnp.power(jnp.maximum(x, 0.0), 2)) + t"
  },
  {
    "test_code": "def testZeroStridesConstantHandler(self):\n    raw_const = self.rng().randn(1, 2, 1, 1, 5, 1)\n    const = np.broadcast_to(raw_const, (3, 2, 3, 4, 5, 6))\n\n    def fun(x):\n        return x * const\n    fun = jax.jit(fun)\n    out_val = fun(3.0)\n    self.assertAllClose(out_val, 3.0 * const, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def fun(x, t):\n    return jnp.sum(jnp.power(jnp.maximum(x, 0.0), 2)) + t"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "@jtu.ignore_warning(category=UserWarning, message='Explicitly requested dtype.*')\ndef testArrayDtypeInference(self):\n\n    def _check(obj, out_dtype, weak_type):\n        dtype_reference = np.array(obj, dtype=out_dtype)\n        out = jnp.array(obj)\n        self.assertDtypesMatch(out, dtype_reference)\n        self.assertEqual(dtypes.is_weakly_typed(out), weak_type)\n        out_jit = jax.jit(jnp.array)(obj)\n        self.assertDtypesMatch(out_jit, dtype_reference)\n        self.assertEqual(dtypes.is_weakly_typed(out_jit), weak_type)\n    _check(1, np.int64, True)\n    _check(1.0, np.float64, True)\n    _check(1j, np.complex128, True)\n    _check([1], jnp.int64, False)\n    _check([1.0], jnp.float64, False)\n    _check([1j], jnp.complex128, False)\n    _check([jnp.array(1)], jnp.int64, False)\n    _check([jnp.array(1.0)], jnp.float64, False)\n    _check([jnp.array(1j)], jnp.complex128, False)\n    _check([jnp.int64(1)], np.int64, False)\n    _check([jnp.float64(1)], np.float64, False)\n    _check([jnp.complex128(1)], np.complex128, False)\n    _check([0, np.int16(1)], np.int16, False)\n    _check([0.0, np.float16(1)], np.float16, False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _check(self, s, *ops):\n    a = np.einsum(s, *ops)\n    b = jnp.einsum(s, *ops, precision=lax.Precision.HIGHEST)\n    self.assertAllClose(a, b, atol=0.0001, rtol=0.0001)"
  },
  {
    "test_code": "@jtu.sample_product(dtype=[dt for dt in float_dtypes if dt not in [jnp.float16, jnp.bfloat16]], shape=[shape for shape in one_dim_array_shapes if shape != (1,)], deg=[1, 2, 3], rcond=[None, -1, 0.01, 0.0001, 1e-09], full=[False, True], w=[False, True], cov=[False, True, 'unscaled'])\n@jax.default_matmul_precision('float32')\ndef testPolyfit(self, shape, dtype, deg, rcond, full, w, cov):\n    rng = jtu.rand_default(self.rng())\n    tol_spec = {np.float32: 0.001, np.float64: 1e-13, np.complex64: 1e-05}\n    tol = jtu.tolerance(dtype, tol_spec)\n    _w = lambda a: abs(a) if w else None\n    args_maker = lambda: [rng(shape, dtype), rng(shape, dtype), rng(shape, dtype)]\n    jnp_fun = lambda x, y, a: jnp.polyfit(x, y, deg=deg, rcond=rcond, full=full, w=_w(a), cov=cov)\n    np_fun = jtu.ignore_warning(message='Polyfit may be poorly conditioned*')(lambda x, y, a: np.polyfit(x, y, deg=deg, rcond=rcond, full=full, w=_w(a), cov=cov))\n    self._CompileAndCheck(jnp_fun, args_maker, check_dtypes=False, atol=tol, rtol=tol)\n    args = args_maker()\n    if not full:\n        args = args_maker()\n        try:\n            np_out = np_fun(*args)\n        except ValueError:\n            return\n        jnp_out = jnp_fun(*args)\n        self.assertAllClose(np_out, jnp_out, atol=tol, rtol=tol, check_dtypes=False)\n    else:\n        np_p, _, nrank, nsingular_values, nrcond = np_fun(*args)\n        jp_p, _, jrank, jsingular_values, jrcond = jnp_fun(*args)\n        self.assertAllClose((np_p, nrank, nsingular_values, nrcond), (jp_p, jrank, jsingular_values, jrcond), atol=tol, rtol=tol, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def jnp_fun(*args, signature=signature, optimize=optimize):\n    path, _ = jnp.einsum_path(signature, *args, optimize=optimize)\n    return jnp.einsum(signature, *args, optimize=path)"
  },
  {
    "test_code": "@jtu.sample_product(period=[None, 0.59], left=[None, 0], right=[None, 1], dtype=jtu.dtypes.floating)\ndef testInterpGradNan(self, dtype, period, left, right):\n    kwds = dict(period=period, left=left, right=right)\n    jnp_fun = partial(jnp.interp, **kwds)\n    x = dtype(np.exp(np.linspace(-90, -20, 1000)))\n    g = jax.grad(lambda z: jnp.sum(jnp_fun(z, z, jnp.ones_like(z))))(x)\n    np.testing.assert_equal(np.all(np.isfinite(g)), True)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def jnp_fun(*args, signature=signature, optimize=optimize):\n    path, _ = jnp.einsum_path(signature, *args, optimize=optimize)\n    return jnp.einsum(signature, *args, optimize=path)"
  },
  {
    "test_code": "@jtu.sample_product(dtype=inexact_dtypes, side=['left', 'right'], method=['sort', 'scan', 'compare_all'])\ndef testSearchsortedNans(self, dtype, side, method):\n    if np.issubdtype(dtype, np.complexfloating):\n        raise SkipTest('Known failure for complex inputs; see #9107')\n    x = np.array([-np.inf, -1.0, 0.0, -0.0, 1.0, np.inf, np.nan, -np.nan], dtype=dtype)\n    x_equiv = np.array([0, 1, 2, 2, 3, 4, 5, 5])\n    if jnp.issubdtype(dtype, jnp.complexfloating):\n        x = np.array([complex(r, c) for r, c in itertools.product(x, repeat=2)])\n        x_equiv = np.array([complex(r, c) for r, c in itertools.product(x_equiv, repeat=2)])\n    fun = partial(jnp.searchsorted, side=side, method=method)\n    self.assertArraysEqual(fun(x, x), fun(x_equiv, x_equiv))\n    self.assertArraysEqual(jax.jit(fun)(x, x), fun(x_equiv, x_equiv))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, backend=backend)\ndef fun(x, y):\n    return jnp.matmul(x, y)"
  },
  {
    "test_code": "@jtu.sample_product([dict(func=func, args=args) for func, args in [('full_like', (-100,)), ('ones_like', ()), ('zeros_like', ())]], shape=array_shapes, in_dtype=[np.int32, np.float32, np.complex64], weak_type=[True, False], out_shape=[None, (), (10,)], out_dtype=[None, float])\ndef testZerosOnesFullLikeWeakType(self, func, args, shape, in_dtype, weak_type, out_shape, out_dtype):\n    rng = jtu.rand_default(self.rng())\n    x = lax_internal._convert_element_type(rng(shape, in_dtype), weak_type=weak_type)\n    fun = lambda x: getattr(jnp, func)(x, *args, dtype=out_dtype, shape=out_shape)\n    expected_weak_type = weak_type and out_dtype is None\n    self.assertEqual(dtypes.is_weakly_typed(fun(x)), expected_weak_type)\n    self.assertEqual(dtypes.is_weakly_typed(jax.jit(fun)(x)), expected_weak_type)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, backend=backend)\ndef fun(x, y):\n    return jnp.matmul(x, y)"
  },
  {
    "test_code": "def testZeroStridesConstantHandler(self):\n    raw_const = self.rng().randn(1, 2, 1, 1, 5, 1)\n    const = np.broadcast_to(raw_const, (3, 2, 3, 4, 5, 6))\n\n    def fun(x):\n        return x * const\n    fun = jax.jit(fun)\n    out_val = fun(3.0)\n    self.assertAllClose(out_val, 3.0 * const, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jax.jit, backend=backend)\ndef fun(x, y):\n    return jnp.matmul(x, y)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def testStackArrayArgument(self):\n\n    @jax.jit\n    def foo(x):\n        return jnp.stack(x)\n    foo(np.zeros(2))\n\n    @jax.jit\n    def foo(x):\n        return jnp.concatenate(x)\n    foo(np.zeros((2, 2)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.custom_vjp\ndef foo(x):\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef g():\n    _, _, attr_tangents = attrs.jvp(f, (), (), [(thing, 'x', 1.0)])\n    (thing_, attr_, tangent_), = attr_tangents\n    self.assertIs(thing, thing_)\n    self.assertEqual(attr_, 'x')\n    return (jax_getattr(thing, 'x'), tangent_)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef g():\n    _, _, attr_tangents = attrs.jvp(f, (), (), [(thing, 'x', 1.0)])\n    (thing_, attr_, tangent_), = attr_tangents\n    self.assertIs(thing, thing_)\n    self.assertEqual(attr_, 'x')\n    return (jax_getattr(thing, 'x'), tangent_)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis, num_sections=num_sections) for shape, axis, num_sections in [((3,), 0, 3), ((12,), 0, 3), ((12, 4), 0, 4), ((12, 4), 1, 2), ((2, 3, 4), -1, 2), ((2, 3, 4), -2, 3)]], dtype=default_dtypes)\ndef testSplitStaticInt(self, shape, num_sections, axis, dtype):\n    rng = jtu.rand_default(self.rng())\n    np_fun = lambda x: np.split(x, num_sections, axis=axis)\n    jnp_fun = lambda x: jnp.split(x, num_sections, axis=axis)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "def testSplitTypeError(self):\n    self.assertEqual(3, len(jnp.split(jnp.zeros(3), jnp.array([1, 2]))))\n    CONCRETIZATION_MSG = 'Abstract tracer value encountered where concrete value is expected.'\n    with self.assertRaisesRegex(TypeError, CONCRETIZATION_MSG):\n        jax.jit(lambda idx: jnp.split(jnp.zeros((12, 2)), idx))(2.0)\n    with self.assertRaisesRegex(TypeError, CONCRETIZATION_MSG):\n        jax.jit(lambda idx: jnp.split(jnp.zeros((12, 2)), [2, idx]))(2.0)\n    jax.jvp(lambda idx: jnp.split(jnp.zeros((12, 2)), idx), (2.0,), (1.0,))\n    jax.jvp(lambda idx: jnp.split(jnp.zeros((12, 2)), (1, idx.astype(np.int32))), (2.0,), (1.0,))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@pjit\ndef g(y):\n    return jnp.sin(y)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@pjit\ndef g(y):\n    return jnp.sin(y)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis) for shape in [(3,), (2, 3)] for axis in list(range(-len(shape), len(shape))) + [None] + [tuple(range(len(shape)))]], dtype=default_dtypes)\ndef testFlip(self, shape, dtype, axis):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    jnp_op = lambda x: jnp.flip(x, axis)\n    np_op = lambda x: np.flip(x, axis)\n    self._CheckAgainstNumpy(np_op, jnp_op, args_maker)\n    self._CompileAndCheck(jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(shape=[(3,), (2, 3), (3, 2, 4)], dtype=default_dtypes)\ndef testFlipud(self, shape, dtype):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    jnp_op = lambda x: jnp.flipud(x)\n    np_op = lambda x: np.flipud(x)\n    self._CheckAgainstNumpy(np_op, jnp_op, args_maker)\n    self._CompileAndCheck(jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(shape=[(3, 2), (2, 3), (3, 2, 4)], dtype=default_dtypes)\ndef testFliplr(self, shape, dtype):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    jnp_op = lambda x: jnp.fliplr(x)\n    np_op = lambda x: np.fliplr(x)\n    self._CheckAgainstNumpy(np_op, jnp_op, args_maker)\n    self._CompileAndCheck(jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axes=axes) for shape, axes in [[(2, 3), (0, 1)], [(2, 3), (1, 0)], [(4, 3, 2), (0, 2)], [(4, 3, 2), (2, 1)]]], k=range(-3, 4), dtype=default_dtypes)\ndef testRot90(self, shape, dtype, k, axes):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    jnp_op = lambda x: jnp.rot90(x, k, axes)\n    np_op = lambda x: np.rot90(x, k, axes)\n    self._CheckAgainstNumpy(np_op, jnp_op, args_maker)\n    self._CompileAndCheck(jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(shapes=filter(_shapes_are_broadcast_compatible, itertools.combinations_with_replacement(all_shapes, 3)), dtypes=itertools.combinations_with_replacement(all_dtypes, 3))\ndef testWhereThreeArgument(self, shapes, dtypes):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, shapes, dtypes)\n\n    def np_fun(cond, x, y):\n        return jtu.promote_like_jnp(partial(np.where, cond))(x, y)\n    with jtu.strict_promotion_if_dtypes_match(dtypes):\n        self._CheckAgainstNumpy(np_fun, jnp.where, args_maker)\n        self._CompileAndCheck(jnp.where, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(shapes=[(), (5,), (5, 3)], dtype=number_dtypes, indexing=['xy', 'ij'], sparse=[True, False])\ndef testMeshGrid(self, shapes, dtype, indexing, sparse):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [(x,) for x in shapes], [dtype] * len(shapes))\n    np_fun = partial(np.meshgrid, indexing=indexing, sparse=sparse)\n    jnp_fun = partial(jnp.meshgrid, indexing=indexing, sparse=sparse)\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(start_shape=[(), (2,), (2, 2)], stop_shape=[(), (2,), (2, 2)], num=[0, 1, 2, 5, 20], endpoint=[True, False], retstep=[True, False], dtype=inexact_dtypes + [None])\n@jax.numpy_rank_promotion('allow')\ndef testLinspace(self, start_shape, stop_shape, num, endpoint, retstep, dtype):\n    rng = jtu.rand_default(self.rng())\n    tol = jtu.tolerance(dtype if dtype else np.float32) * 10\n    args_maker = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])\n    start, stop = args_maker()\n    ndim = len(np.shape(start + stop))\n    for axis in range(-ndim, ndim):\n        jnp_op = lambda start, stop: jnp.linspace(start, stop, num, endpoint=endpoint, retstep=retstep, dtype=dtype, axis=axis)\n        np_op = lambda start, stop: np.linspace(start, stop, num, endpoint=endpoint, retstep=retstep, dtype=dtype, axis=axis)\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker, check_dtypes=False, tol=tol)\n        self._CompileAndCheck(jnp_op, args_maker, check_dtypes=False, atol=tol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(start_shape=[(), (2,), (2, 2)], stop_shape=[(), (2,), (2, 2)], num=[0, 1, 2, 5, 20], endpoint=[True, False], base=[10.0, 2, np.e], dtype=jtu.dtypes.inexact + [None])\n@jax.numpy_rank_promotion('allow')\ndef testLogspace(self, start_shape, stop_shape, num, endpoint, base, dtype):\n    if dtype in int_dtypes and jtu.test_device_matches(['gpu', 'tpu']) and (not config.enable_x64.value):\n        raise unittest.SkipTest(\"GPUx32 truncated exponentiation doesn't exactly match other platforms.\")\n    rng = jtu.rand_default(self.rng())\n    tol = {np.float32: 0.01, np.float64: 1e-06, np.complex64: 0.001, np.complex128: 1e-06}\n    args_maker = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])\n    start, stop = args_maker()\n    ndim = len(np.shape(start + stop))\n    for axis in range(-ndim, ndim):\n        jnp_op = lambda start, stop: jnp.logspace(start, stop, num, endpoint=endpoint, base=base, dtype=dtype, axis=axis)\n\n        @jtu.ignore_warning(category=RuntimeWarning, message='overflow encountered in power')\n        def np_op(start, stop):\n            return np.logspace(start, stop, num, endpoint=endpoint, base=base, dtype=dtype, axis=axis)\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker, check_dtypes=False, tol=tol)\n        if dtype in inexact_dtypes + [None]:\n            atol = {np.float16: 0.01}\n            self._CompileAndCheck(jnp_op, args_maker, check_dtypes=False, atol=atol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product([dict(start_shape=start_shape, stop_shape=stop_shape, axis=axis) for start_shape in [(), (2,), (2, 2)] for stop_shape in [(), (2,), (2, 2)] for axis in range(-max(len(start_shape), len(stop_shape)), max(len(start_shape), len(stop_shape)))], num=[0, 1, 2, 5, 20], endpoint=[True, False], dtype=inexact_dtypes + [None])\n@jax.numpy_rank_promotion('allow')\ndef testGeomspace(self, start_shape, stop_shape, num, endpoint, dtype, axis):\n    rng = jtu.rand_default(self.rng())\n    tol = {dtypes.bfloat16: 0.02, np.float16: 0.004, np.float32: 0.002, np.float64: 1e-14, np.complex64: 0.002, np.complex128: 1e-14}\n\n    def args_maker():\n        \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n        start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n        start, stop = jnp.broadcast_arrays(start, stop)\n        if dtype in complex_dtypes:\n            return (start, stop)\n        start = start * jnp.sign(start) * jnp.sign(stop)\n        return (start, stop)\n    start, stop = args_maker()\n\n    def jnp_op(start, stop):\n        return jnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype, axis=axis)\n\n    def np_op(start, stop):\n        start = start.astype(np.float32) if dtype == jnp.bfloat16 else start\n        stop = stop.astype(np.float32) if dtype == jnp.bfloat16 else stop\n        return np.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype if dtype != jnp.bfloat16 else np.float32, axis=axis).astype(dtype)\n    if not (jtu.numpy_version() < (2, 0, 0) and dtypes.issubdtype(dtype, jnp.complexfloating)):\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker, check_dtypes=False, tol=tol)\n    if dtype in inexact_dtypes + [None]:\n        self._CompileAndCheck(jnp_op, args_maker, check_dtypes=False, atol=tol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product([dict(from_shape=from_shape, to_shape=to_shape) for from_shape, to_shape in [[(1, 3), (4, 3)], [(3,), (2, 1, 3)], [(3,), (3, 3)], [(1,), (3,)], [(1,), 3]]])\ndef testBroadcastTo(self, from_shape, to_shape):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [from_shape], [np.float32])\n    np_op = lambda x: np.broadcast_to(x, to_shape)\n    jnp_op = lambda x: jnp.broadcast_to(x, to_shape)\n    self._CheckAgainstNumpy(np_op, jnp_op, args_maker)\n    self._CompileAndCheck(jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, varargs=varargs, axis=axis) for shape in [(10,), (10, 15), (10, 15, 20)] for _num_axes in range(len(shape)) for varargs in itertools.combinations(range(1, len(shape) + 1), _num_axes) for axis in itertools.combinations(range(len(shape)), _num_axes)], dtype=inexact_dtypes)\ndef testGradient(self, shape, varargs, axis, dtype):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    jnp_fun = lambda y: jnp.gradient(y, *varargs, axis=axis)\n    np_fun = lambda y: np.gradient(y, *varargs, axis=axis)\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, check_dtypes=False)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(shape=[(5,), (5, 7), (5, 10, 3)], dtype=inexact_dtypes)\ndef testGradientNonConstant(self, shape, dtype):\n    rng = jtu.rand_default(self.rng())\n    varargs = [(s,) for s in shape]\n    args = [shape] + varargs\n    args_maker = self._GetArgsMaker(rng, args, [dtype] * len(args))\n    atol = jtu.tolerance(dtype, {np.float16: 0.04, jax.dtypes.bfloat16: 0.4, np.float32: 2e-05})\n    rtol = jtu.tolerance(dtype, {jax.dtypes.bfloat16: 0.5})\n    self._CheckAgainstNumpy(np.gradient, jnp.gradient, args_maker, check_dtypes=False, atol=atol, rtol=rtol)\n    self._CompileAndCheck(jnp.gradient, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.remat\ndef g(x):\n    jax.jit(lambda: 0 if jnp.add(1, 1) else 0)()\n    return lax.sin(x)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.remat\ndef g(x):\n    jax.jit(lambda: 0 if jnp.add(1, 1) else 0)()\n    return lax.sin(x)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis, num_sections=num_sections) for shape, axis, num_sections in [((12, 4), 0, 4), ((12,), 1, 2), ((2, 3, 4), 2, 2), ((4, 3, 4), 0, 2)]], dtype=default_dtypes)\ndef testHVDSplit(self, shape, num_sections, axis, dtype):\n    rng = jtu.rand_default(self.rng())\n\n    def fn(module, axis):\n        if axis == 0:\n            return module.vsplit\n        elif axis == 1:\n            return module.hsplit\n        else:\n            assert axis == 2\n            return module.dsplit\n    np_fun = lambda x: fn(np, axis)(x, num_sections)\n    jnp_fun = lambda x: fn(jnp, axis)(x, num_sections)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [
      "assert axis == 2"
    ],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@custom_transpose_with_example_out(jnp.ones(2))\ndef fn(r, x):\n    tracer_spy.append(r)\n    tracer_spy.append(x['c'])\n    return dict(b=x['c'] / r)"
  },
  {
    "test_code": "@parameterized.named_parameters(('ones', jnp.ones), ('zeros', jnp.zeros), ('empty', jnp.empty))\ndef test_error_hint(self, fn):\n    with self.assertRaisesRegex(TypeError, 'Did you accidentally write `jax\\\\.numpy\\\\..*?\\\\(2, 3\\\\)` when you meant `jax\\\\.numpy\\\\..*?\\\\(\\\\(2, 3\\\\)\\\\)`'):\n        fn(2, 3)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@custom_transpose_with_example_out(jnp.ones(2))\ndef fn(r, x):\n    tracer_spy.append(r)\n    tracer_spy.append(x['c'])\n    return dict(b=x['c'] / r)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis) for shape in [(3,), (2, 3)] for axis in list(range(-len(shape), len(shape))) + [None] + [tuple(range(len(shape)))]], dtype=default_dtypes)\ndef testFlip(self, shape, dtype, axis):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    jnp_op = lambda x: jnp.flip(x, axis)\n    np_op = lambda x: np.flip(x, axis)\n    self._CheckAgainstNumpy(np_op, jnp_op, args_maker)\n    self._CompileAndCheck(jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(shape=[(3,), (2, 3), (3, 2, 4)], dtype=default_dtypes)\ndef testFlipud(self, shape, dtype):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    jnp_op = lambda x: jnp.flipud(x)\n    np_op = lambda x: np.flipud(x)\n    self._CheckAgainstNumpy(np_op, jnp_op, args_maker)\n    self._CompileAndCheck(jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(shape=[(3, 2), (2, 3), (3, 2, 4)], dtype=default_dtypes)\ndef testFliplr(self, shape, dtype):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    jnp_op = lambda x: jnp.fliplr(x)\n    np_op = lambda x: np.fliplr(x)\n    self._CheckAgainstNumpy(np_op, jnp_op, args_maker)\n    self._CompileAndCheck(jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axes=axes) for shape, axes in [[(2, 3), (0, 1)], [(2, 3), (1, 0)], [(4, 3, 2), (0, 2)], [(4, 3, 2), (2, 1)]]], k=range(-3, 4), dtype=default_dtypes)\ndef testRot90(self, shape, dtype, k, axes):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    jnp_op = lambda x: jnp.rot90(x, k, axes)\n    np_op = lambda x: np.rot90(x, k, axes)\n    self._CheckAgainstNumpy(np_op, jnp_op, args_maker)\n    self._CompileAndCheck(jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(shapes=filter(_shapes_are_broadcast_compatible, itertools.combinations_with_replacement(all_shapes, 3)), dtypes=itertools.combinations_with_replacement(all_dtypes, 3))\ndef testWhereThreeArgument(self, shapes, dtypes):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, shapes, dtypes)\n\n    def np_fun(cond, x, y):\n        return jtu.promote_like_jnp(partial(np.where, cond))(x, y)\n    with jtu.strict_promotion_if_dtypes_match(dtypes):\n        self._CheckAgainstNumpy(np_fun, jnp.where, args_maker)\n        self._CompileAndCheck(jnp.where, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(shapes=[(), (5,), (5, 3)], dtype=number_dtypes, indexing=['xy', 'ij'], sparse=[True, False])\ndef testMeshGrid(self, shapes, dtype, indexing, sparse):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [(x,) for x in shapes], [dtype] * len(shapes))\n    np_fun = partial(np.meshgrid, indexing=indexing, sparse=sparse)\n    jnp_fun = partial(jnp.meshgrid, indexing=indexing, sparse=sparse)\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(start_shape=[(), (2,), (2, 2)], stop_shape=[(), (2,), (2, 2)], num=[0, 1, 2, 5, 20], endpoint=[True, False], retstep=[True, False], dtype=inexact_dtypes + [None])\n@jax.numpy_rank_promotion('allow')\ndef testLinspace(self, start_shape, stop_shape, num, endpoint, retstep, dtype):\n    rng = jtu.rand_default(self.rng())\n    tol = jtu.tolerance(dtype if dtype else np.float32) * 10\n    args_maker = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])\n    start, stop = args_maker()\n    ndim = len(np.shape(start + stop))\n    for axis in range(-ndim, ndim):\n        jnp_op = lambda start, stop: jnp.linspace(start, stop, num, endpoint=endpoint, retstep=retstep, dtype=dtype, axis=axis)\n        np_op = lambda start, stop: np.linspace(start, stop, num, endpoint=endpoint, retstep=retstep, dtype=dtype, axis=axis)\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker, check_dtypes=False, tol=tol)\n        self._CompileAndCheck(jnp_op, args_maker, check_dtypes=False, atol=tol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(start_shape=[(), (2,), (2, 2)], stop_shape=[(), (2,), (2, 2)], num=[0, 1, 2, 5, 20], endpoint=[True, False], base=[10.0, 2, np.e], dtype=jtu.dtypes.inexact + [None])\n@jax.numpy_rank_promotion('allow')\ndef testLogspace(self, start_shape, stop_shape, num, endpoint, base, dtype):\n    if dtype in int_dtypes and jtu.test_device_matches(['gpu', 'tpu']) and (not config.enable_x64.value):\n        raise unittest.SkipTest(\"GPUx32 truncated exponentiation doesn't exactly match other platforms.\")\n    rng = jtu.rand_default(self.rng())\n    tol = {np.float32: 0.01, np.float64: 1e-06, np.complex64: 0.001, np.complex128: 1e-06}\n    args_maker = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])\n    start, stop = args_maker()\n    ndim = len(np.shape(start + stop))\n    for axis in range(-ndim, ndim):\n        jnp_op = lambda start, stop: jnp.logspace(start, stop, num, endpoint=endpoint, base=base, dtype=dtype, axis=axis)\n\n        @jtu.ignore_warning(category=RuntimeWarning, message='overflow encountered in power')\n        def np_op(start, stop):\n            return np.logspace(start, stop, num, endpoint=endpoint, base=base, dtype=dtype, axis=axis)\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker, check_dtypes=False, tol=tol)\n        if dtype in inexact_dtypes + [None]:\n            atol = {np.float16: 0.01}\n            self._CompileAndCheck(jnp_op, args_maker, check_dtypes=False, atol=atol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product([dict(start_shape=start_shape, stop_shape=stop_shape, axis=axis) for start_shape in [(), (2,), (2, 2)] for stop_shape in [(), (2,), (2, 2)] for axis in range(-max(len(start_shape), len(stop_shape)), max(len(start_shape), len(stop_shape)))], num=[0, 1, 2, 5, 20], endpoint=[True, False], dtype=inexact_dtypes + [None])\n@jax.numpy_rank_promotion('allow')\ndef testGeomspace(self, start_shape, stop_shape, num, endpoint, dtype, axis):\n    rng = jtu.rand_default(self.rng())\n    tol = {dtypes.bfloat16: 0.02, np.float16: 0.004, np.float32: 0.002, np.float64: 1e-14, np.complex64: 0.002, np.complex128: 1e-14}\n\n    def args_maker():\n        \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n        start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n        start, stop = jnp.broadcast_arrays(start, stop)\n        if dtype in complex_dtypes:\n            return (start, stop)\n        start = start * jnp.sign(start) * jnp.sign(stop)\n        return (start, stop)\n    start, stop = args_maker()\n\n    def jnp_op(start, stop):\n        return jnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype, axis=axis)\n\n    def np_op(start, stop):\n        start = start.astype(np.float32) if dtype == jnp.bfloat16 else start\n        stop = stop.astype(np.float32) if dtype == jnp.bfloat16 else stop\n        return np.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype if dtype != jnp.bfloat16 else np.float32, axis=axis).astype(dtype)\n    if not (jtu.numpy_version() < (2, 0, 0) and dtypes.issubdtype(dtype, jnp.complexfloating)):\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker, check_dtypes=False, tol=tol)\n    if dtype in inexact_dtypes + [None]:\n        self._CompileAndCheck(jnp_op, args_maker, check_dtypes=False, atol=tol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product([dict(from_shape=from_shape, to_shape=to_shape) for from_shape, to_shape in [[(1, 3), (4, 3)], [(3,), (2, 1, 3)], [(3,), (3, 3)], [(1,), (3,)], [(1,), 3]]])\ndef testBroadcastTo(self, from_shape, to_shape):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [from_shape], [np.float32])\n    np_op = lambda x: np.broadcast_to(x, to_shape)\n    jnp_op = lambda x: jnp.broadcast_to(x, to_shape)\n    self._CheckAgainstNumpy(np_op, jnp_op, args_maker)\n    self._CompileAndCheck(jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, varargs=varargs, axis=axis) for shape in [(10,), (10, 15), (10, 15, 20)] for _num_axes in range(len(shape)) for varargs in itertools.combinations(range(1, len(shape) + 1), _num_axes) for axis in itertools.combinations(range(len(shape)), _num_axes)], dtype=inexact_dtypes)\ndef testGradient(self, shape, varargs, axis, dtype):\n    rng = jtu.rand_default(self.rng())\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    jnp_fun = lambda y: jnp.gradient(y, *varargs, axis=axis)\n    np_fun = lambda y: np.gradient(y, *varargs, axis=axis)\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, check_dtypes=False)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(shape=[(5,), (5, 7), (5, 10, 3)], dtype=inexact_dtypes)\ndef testGradientNonConstant(self, shape, dtype):\n    rng = jtu.rand_default(self.rng())\n    varargs = [(s,) for s in shape]\n    args = [shape] + varargs\n    args_maker = self._GetArgsMaker(rng, args, [dtype] * len(args))\n    atol = jtu.tolerance(dtype, {np.float16: 0.04, jax.dtypes.bfloat16: 0.4, np.float32: 2e-05})\n    rtol = jtu.tolerance(dtype, {jax.dtypes.bfloat16: 0.5})\n    self._CheckAgainstNumpy(np.gradient, jnp.gradient, args_maker, check_dtypes=False, atol=atol, rtol=rtol)\n    self._CompileAndCheck(jnp.gradient, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _GetArgsMaker(self, rng, shapes, dtypes, np_arrays=True):\n\n    def f():\n        out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n        if np_arrays:\n            return out\n        return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]\n    return f"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(dtype=[dt for dt in float_dtypes if dt not in [jnp.float16, jnp.bfloat16]], shape=[shape for shape in one_dim_array_shapes if shape != (1,)], deg=[1, 2, 3], rcond=[None, -1, 0.01, 0.0001, 1e-09], full=[False, True], w=[False, True], cov=[False, True, 'unscaled'])\n@jax.default_matmul_precision('float32')\ndef testPolyfit(self, shape, dtype, deg, rcond, full, w, cov):\n    rng = jtu.rand_default(self.rng())\n    tol_spec = {np.float32: 0.001, np.float64: 1e-13, np.complex64: 1e-05}\n    tol = jtu.tolerance(dtype, tol_spec)\n    _w = lambda a: abs(a) if w else None\n    args_maker = lambda: [rng(shape, dtype), rng(shape, dtype), rng(shape, dtype)]\n    jnp_fun = lambda x, y, a: jnp.polyfit(x, y, deg=deg, rcond=rcond, full=full, w=_w(a), cov=cov)\n    np_fun = jtu.ignore_warning(message='Polyfit may be poorly conditioned*')(lambda x, y, a: np.polyfit(x, y, deg=deg, rcond=rcond, full=full, w=_w(a), cov=cov))\n    self._CompileAndCheck(jnp_fun, args_maker, check_dtypes=False, atol=tol, rtol=tol)\n    args = args_maker()\n    if not full:\n        args = args_maker()\n        try:\n            np_out = np_fun(*args)\n        except ValueError:\n            return\n        jnp_out = jnp_fun(*args)\n        self.assertAllClose(np_out, jnp_out, atol=tol, rtol=tol, check_dtypes=False)\n    else:\n        np_p, _, nrank, nsingular_values, nrcond = np_fun(*args)\n        jp_p, _, jrank, jsingular_values, jrcond = jnp_fun(*args)\n        self.assertAllClose((np_p, nrank, nsingular_values, nrcond), (jp_p, jrank, jsingular_values, jrcond), atol=tol, rtol=tol, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.numpy_dtype_promotion('standard')\ndef np_fun(condlist, choicelist, default):\n    choicelist = [x if jnp.result_type(x) != jnp.bfloat16 else x.astype(np.float32) for x in choicelist]\n    dtype = jnp.result_type(default, *choicelist)\n    return np.select(condlist, [np.asarray(x, dtype=dtype) for x in choicelist], np.asarray(default, dtype=dtype))"
  },
  {
    "test_code": "@jtu.sample_product(dtype=[dt for dt in float_dtypes if dt not in [jnp.float16, jnp.bfloat16]], shape=[shape for shape in one_dim_array_shapes if shape != (1,)], deg=[1, 2, 3], rcond=[None, -1, 0.01, 0.0001, 1e-09], full=[False, True], w=[False, True], cov=[False, True, 'unscaled'])\n@jax.default_matmul_precision('float32')\ndef testPolyfit(self, shape, dtype, deg, rcond, full, w, cov):\n    rng = jtu.rand_default(self.rng())\n    tol_spec = {np.float32: 0.001, np.float64: 1e-13, np.complex64: 1e-05}\n    tol = jtu.tolerance(dtype, tol_spec)\n    _w = lambda a: abs(a) if w else None\n    args_maker = lambda: [rng(shape, dtype), rng(shape, dtype), rng(shape, dtype)]\n    jnp_fun = lambda x, y, a: jnp.polyfit(x, y, deg=deg, rcond=rcond, full=full, w=_w(a), cov=cov)\n    np_fun = jtu.ignore_warning(message='Polyfit may be poorly conditioned*')(lambda x, y, a: np.polyfit(x, y, deg=deg, rcond=rcond, full=full, w=_w(a), cov=cov))\n    self._CompileAndCheck(jnp_fun, args_maker, check_dtypes=False, atol=tol, rtol=tol)\n    args = args_maker()\n    if not full:\n        args = args_maker()\n        try:\n            np_out = np_fun(*args)\n        except ValueError:\n            return\n        jnp_out = jnp_fun(*args)\n        self.assertAllClose(np_out, jnp_out, atol=tol, rtol=tol, check_dtypes=False)\n    else:\n        np_p, _, nrank, nsingular_values, nrcond = np_fun(*args)\n        jp_p, _, jrank, jsingular_values, jrcond = jnp_fun(*args)\n        self.assertAllClose((np_p, nrank, nsingular_values, nrcond), (jp_p, jrank, jsingular_values, jrcond), atol=tol, rtol=tol, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def jnp_fun(a, c):\n    try:\n        return jnp.choose(a, c, mode=mode)\n    except ValueError as err:\n        if mode == 'raise' and str(err).startswith('invalid entry'):\n            return -999\n        else:\n            raise"
  },
  {
    "test_code": "@jtu.sample_product(period=[None, 0.59], left=[None, 0], right=[None, 1], dtype=jtu.dtypes.floating)\ndef testInterpGradNan(self, dtype, period, left, right):\n    kwds = dict(period=period, left=left, right=right)\n    jnp_fun = partial(jnp.interp, **kwds)\n    x = dtype(np.exp(np.linspace(-90, -20, 1000)))\n    g = jax.grad(lambda z: jnp.sum(jnp_fun(z, z, jnp.ones_like(z))))(x)\n    np.testing.assert_equal(np.all(np.isfinite(g)), True)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def jnp_fun(a, c):\n    try:\n        return jnp.choose(a, c, mode=mode)\n    except ValueError as err:\n        if mode == 'raise' and str(err).startswith('invalid entry'):\n            return -999\n        else:\n            raise"
  },
  {
    "test_code": "@jtu.sample_product(fixed_size=[False, True])\ndef testNonScalarRepeats(self, fixed_size):\n    \"\"\"\n    Following numpy test suite from `test_repeat` at\n    https://github.com/numpy/numpy/blob/main/numpy/core/tests/test_multiarray.py\n    \"\"\"\n    tol = 1e-05\n\n    def test_single(m, args_maker, repeats, axis):\n        lax_ans = jnp.repeat(m, repeats, axis)\n        numpy_ans = np.repeat(m, repeats, axis)\n        self.assertAllClose(lax_ans, numpy_ans, rtol=tol, atol=tol)\n        if fixed_size:\n            rep_length = np.repeat(np.zeros_like(m), repeats, axis).shape[axis or 0]\n            jnp_fun = lambda arg, rep: jnp.repeat(arg, repeats=rep, axis=axis, total_repeat_length=rep_length)\n        else:\n            jnp_fun = lambda arg: jnp.repeat(arg, repeats=repeats, axis=axis)\n        self._CompileAndCheck(jnp_fun, args_maker)\n    m = jnp.array([1, 2, 3, 4, 5, 6])\n    if fixed_size:\n        args_maker = lambda: [m, repeats]\n    else:\n        args_maker = lambda: [m]\n    for repeats in [2, jnp.array([1, 3, 0, 1, 1, 2]), jnp.array([1, 3, 2, 1, 1, 2]), jnp.array([2])]:\n        test_single(m, args_maker, repeats, axis=None)\n        test_single(m, args_maker, repeats, axis=0)\n    m_rect = m.reshape((2, 3))\n    if fixed_size:\n        args_maker = lambda: [m_rect, repeats]\n    else:\n        args_maker = lambda: [m_rect]\n    for repeats in [2, jnp.array([2, 1]), jnp.array([2])]:\n        test_single(m_rect, args_maker, repeats, axis=0)\n    for repeats in [2, jnp.array([1, 3, 2]), jnp.array([2])]:\n        test_single(m_rect, args_maker, repeats, axis=1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def test_single(m, args_maker, repeats, axis):\n    lax_ans = jnp.repeat(m, repeats, axis)\n    numpy_ans = np.repeat(m, repeats, axis)\n    self.assertAllClose(lax_ans, numpy_ans, rtol=tol, atol=tol)\n    if fixed_size:\n        rep_length = np.repeat(np.zeros_like(m), repeats, axis).shape[axis or 0]\n        jnp_fun = lambda arg, rep: jnp.repeat(arg, repeats=rep, axis=axis, total_repeat_length=rep_length)\n    else:\n        jnp_fun = lambda arg: jnp.repeat(arg, repeats=repeats, axis=axis)\n    self._CompileAndCheck(jnp_fun, args_maker)"
  },
  {
    "test_code": "def testIssue2330(self):\n    \"\"\"\n    Make sure return value of jnp.concatenate is a jax.ndarray and is side-effect save\n    \"\"\"\n\n    def attempt_sideeffect(x):\n        x = [x]\n        x = jnp.concatenate(x)\n        x -= 1.0\n        return x\n    np_input = np.ones(1)\n    jnp_input = jnp.ones(1)\n    expected_np_input_after_call = np.ones(1)\n    expected_jnp_input_after_call = jnp.ones(1)\n    out = jnp.concatenate([np_input])\n    self.assertIs(type(out), array.ArrayImpl)\n    attempt_sideeffect(np_input)\n    attempt_sideeffect(jnp_input)\n    self.assertAllClose(np_input, expected_np_input_after_call)\n    self.assertAllClose(jnp_input, expected_jnp_input_after_call)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def attempt_sideeffect(x):\n    x = [x]\n    x = jnp.concatenate(x)\n    x -= 1.0\n    return x"
  },
  {
    "test_code": "@jtu.ignore_warning(category=UserWarning, message='Explicitly requested dtype.*')\ndef testArrayDtypeInference(self):\n\n    def _check(obj, out_dtype, weak_type):\n        dtype_reference = np.array(obj, dtype=out_dtype)\n        out = jnp.array(obj)\n        self.assertDtypesMatch(out, dtype_reference)\n        self.assertEqual(dtypes.is_weakly_typed(out), weak_type)\n        out_jit = jax.jit(jnp.array)(obj)\n        self.assertDtypesMatch(out_jit, dtype_reference)\n        self.assertEqual(dtypes.is_weakly_typed(out_jit), weak_type)\n    _check(1, np.int64, True)\n    _check(1.0, np.float64, True)\n    _check(1j, np.complex128, True)\n    _check([1], jnp.int64, False)\n    _check([1.0], jnp.float64, False)\n    _check([1j], jnp.complex128, False)\n    _check([jnp.array(1)], jnp.int64, False)\n    _check([jnp.array(1.0)], jnp.float64, False)\n    _check([jnp.array(1j)], jnp.complex128, False)\n    _check([jnp.int64(1)], np.int64, False)\n    _check([jnp.float64(1)], np.float64, False)\n    _check([jnp.complex128(1)], np.complex128, False)\n    _check([0, np.int16(1)], np.int16, False)\n    _check([0.0, np.float16(1)], np.float16, False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def _check(obj, out_dtype, weak_type):\n    dtype_reference = np.array(obj, dtype=out_dtype)\n    out = jnp.array(obj)\n    self.assertDtypesMatch(out, dtype_reference)\n    self.assertEqual(dtypes.is_weakly_typed(out), weak_type)\n    out_jit = jax.jit(jnp.array)(obj)\n    self.assertDtypesMatch(out_jit, dtype_reference)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), weak_type)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef g(x):\n    if x > 0.0:\n        return x * 2\n    else:\n        return x + 2"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef g(x):\n    if x > 0.0:\n        return x * 2\n    else:\n        return x + 2"
  },
  {
    "test_code": "@jtu.sample_product(dtype=[dt for dt in float_dtypes if dt not in [jnp.float16, jnp.bfloat16]], shape=[shape for shape in one_dim_array_shapes if shape != (1,)], deg=[1, 2, 3], rcond=[None, -1, 0.01, 0.0001, 1e-09], full=[False, True], w=[False, True], cov=[False, True, 'unscaled'])\n@jax.default_matmul_precision('float32')\ndef testPolyfit(self, shape, dtype, deg, rcond, full, w, cov):\n    rng = jtu.rand_default(self.rng())\n    tol_spec = {np.float32: 0.001, np.float64: 1e-13, np.complex64: 1e-05}\n    tol = jtu.tolerance(dtype, tol_spec)\n    _w = lambda a: abs(a) if w else None\n    args_maker = lambda: [rng(shape, dtype), rng(shape, dtype), rng(shape, dtype)]\n    jnp_fun = lambda x, y, a: jnp.polyfit(x, y, deg=deg, rcond=rcond, full=full, w=_w(a), cov=cov)\n    np_fun = jtu.ignore_warning(message='Polyfit may be poorly conditioned*')(lambda x, y, a: np.polyfit(x, y, deg=deg, rcond=rcond, full=full, w=_w(a), cov=cov))\n    self._CompileAndCheck(jnp_fun, args_maker, check_dtypes=False, atol=tol, rtol=tol)\n    args = args_maker()\n    if not full:\n        args = args_maker()\n        try:\n            np_out = np_fun(*args)\n        except ValueError:\n            return\n        jnp_out = jnp_fun(*args)\n        self.assertAllClose(np_out, jnp_out, atol=tol, rtol=tol, check_dtypes=False)\n    else:\n        np_p, _, nrank, nsingular_values, nrcond = np_fun(*args)\n        jp_p, _, jrank, jsingular_values, jrcond = jnp_fun(*args)\n        self.assertAllClose((np_p, nrank, nsingular_values, nrcond), (jp_p, jrank, jsingular_values, jrcond), atol=tol, rtol=tol, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "def testArrayFromMasked(self):\n    args_maker = lambda: [np.ma.array([1, 2], mask=[True, False])]\n    self._CheckAgainstNumpy(np.array, jnp.array, args_maker)\n    with self.assertRaisesRegex(ValueError, 'numpy masked arrays are not supported'):\n        jax.jit(jnp.asarray)(*args_maker())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product(shape=nonempty_nonscalar_array_shapes, order=['C', 'F'], mode=['wrap', 'clip', 'raise'])\n@jax.numpy_rank_promotion('allow')\ndef testRavelMultiIndex(self, shape, order, mode):\n    rngs = [jtu.rand_int(self.rng(), low=-1, high=dim + 1) for dim in shape]\n    args_maker = lambda: [tuple((rng(ndim * (3,), jnp.int_) for ndim, rng in enumerate(rngs)))]\n\n    def np_fun(x):\n        try:\n            return np.ravel_multi_index(x, shape, order=order, mode=mode)\n        except ValueError as err:\n            if str(err).startswith('invalid entry'):\n                return -999\n            else:\n                raise\n\n    def jnp_fun(x):\n        try:\n            return jnp.ravel_multi_index(x, shape, order=order, mode=mode)\n        except ValueError as err:\n            if str(err).startswith('invalid entry'):\n                return -999\n            else:\n                raise\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, check_dtypes=False)\n    if mode == 'raise':\n        msg = \"The error occurred because ravel_multi_index was jit-compiled with mode='raise'. Use mode='wrap' or mode='clip' instead.\"\n        with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n            jax.jit(jnp_fun)(*args_maker())\n    else:\n        self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product(ashape=((), (4,), (3, 4)), cshapes=[[(), (4,)], [(3, 4), (4,), (3, 1)]], adtype=int_dtypes, cdtype=default_dtypes, mode=['wrap', 'clip', 'raise'])\ndef testChoose(self, ashape, adtype, cshapes, cdtype, mode):\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(ashape, adtype), [rng(s, cdtype) for s in cshapes]]\n\n    def np_fun(a, c):\n        try:\n            return np.choose(a, c, mode=mode)\n        except ValueError as err:\n            if mode == 'raise' and str(err).startswith('invalid entry'):\n                return -999\n            else:\n                raise\n\n    def jnp_fun(a, c):\n        try:\n            return jnp.choose(a, c, mode=mode)\n        except ValueError as err:\n            if mode == 'raise' and str(err).startswith('invalid entry'):\n                return -999\n            else:\n                raise\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, check_dtypes=False)\n    if mode == 'raise':\n        msg = \"The error occurred because jnp.choose was jit-compiled with mode='raise'. Use mode='wrap' or mode='clip' instead.\"\n        with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n            jax.jit(jnp_fun)(*args_maker())\n    else:\n        self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product(shape=nonempty_array_shapes, dtype=all_dtypes, num_args=[0, 1, 'all'], use_tuple=[True, False])\ndef testItem(self, shape, dtype, num_args, use_tuple):\n    rng = jtu.rand_default(self.rng())\n    size = math.prod(shape)\n    if num_args == 0:\n        args = ()\n    elif num_args == 1:\n        args = (self.rng().randint(0, size),)\n    else:\n        args = tuple((self.rng().randint(0, s) for s in shape))\n    args = (args,) if use_tuple else args\n    np_op = lambda x: np.asarray(x).item(*args)\n    jnp_op = lambda x: jnp.asarray(x).item(*args)\n    args_maker = lambda: [rng(shape, dtype)]\n    if size != 1 and num_args == 0:\n        with self.assertRaises(ValueError):\n            jnp_op(*args_maker())\n    else:\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product(start_shape=[(), (2,), (2, 2)], stop_shape=[(), (2,), (2, 2)], num=[0, 1, 2, 5, 20], endpoint=[True, False], retstep=[True, False], dtype=inexact_dtypes + [None])\n@jax.numpy_rank_promotion('allow')\ndef testLinspace(self, start_shape, stop_shape, num, endpoint, retstep, dtype):\n    rng = jtu.rand_default(self.rng())\n    tol = jtu.tolerance(dtype if dtype else np.float32) * 10\n    args_maker = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])\n    start, stop = args_maker()\n    ndim = len(np.shape(start + stop))\n    for axis in range(-ndim, ndim):\n        jnp_op = lambda start, stop: jnp.linspace(start, stop, num, endpoint=endpoint, retstep=retstep, dtype=dtype, axis=axis)\n        np_op = lambda start, stop: np.linspace(start, stop, num, endpoint=endpoint, retstep=retstep, dtype=dtype, axis=axis)\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker, check_dtypes=False, tol=tol)\n        self._CompileAndCheck(jnp_op, args_maker, check_dtypes=False, atol=tol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product(start_shape=[(), (2,), (2, 2)], stop_shape=[(), (2,), (2, 2)], num=[0, 1, 2, 5, 20], endpoint=[True, False], base=[10.0, 2, np.e], dtype=jtu.dtypes.inexact + [None])\n@jax.numpy_rank_promotion('allow')\ndef testLogspace(self, start_shape, stop_shape, num, endpoint, base, dtype):\n    if dtype in int_dtypes and jtu.test_device_matches(['gpu', 'tpu']) and (not config.enable_x64.value):\n        raise unittest.SkipTest(\"GPUx32 truncated exponentiation doesn't exactly match other platforms.\")\n    rng = jtu.rand_default(self.rng())\n    tol = {np.float32: 0.01, np.float64: 1e-06, np.complex64: 0.001, np.complex128: 1e-06}\n    args_maker = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])\n    start, stop = args_maker()\n    ndim = len(np.shape(start + stop))\n    for axis in range(-ndim, ndim):\n        jnp_op = lambda start, stop: jnp.logspace(start, stop, num, endpoint=endpoint, base=base, dtype=dtype, axis=axis)\n\n        @jtu.ignore_warning(category=RuntimeWarning, message='overflow encountered in power')\n        def np_op(start, stop):\n            return np.logspace(start, stop, num, endpoint=endpoint, base=base, dtype=dtype, axis=axis)\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker, check_dtypes=False, tol=tol)\n        if dtype in inexact_dtypes + [None]:\n            atol = {np.float16: 0.01}\n            self._CompileAndCheck(jnp_op, args_maker, check_dtypes=False, atol=atol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product([dict(start_shape=start_shape, stop_shape=stop_shape, axis=axis) for start_shape in [(), (2,), (2, 2)] for stop_shape in [(), (2,), (2, 2)] for axis in range(-max(len(start_shape), len(stop_shape)), max(len(start_shape), len(stop_shape)))], num=[0, 1, 2, 5, 20], endpoint=[True, False], dtype=inexact_dtypes + [None])\n@jax.numpy_rank_promotion('allow')\ndef testGeomspace(self, start_shape, stop_shape, num, endpoint, dtype, axis):\n    rng = jtu.rand_default(self.rng())\n    tol = {dtypes.bfloat16: 0.02, np.float16: 0.004, np.float32: 0.002, np.float64: 1e-14, np.complex64: 0.002, np.complex128: 1e-14}\n\n    def args_maker():\n        \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n        start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n        start, stop = jnp.broadcast_arrays(start, stop)\n        if dtype in complex_dtypes:\n            return (start, stop)\n        start = start * jnp.sign(start) * jnp.sign(stop)\n        return (start, stop)\n    start, stop = args_maker()\n\n    def jnp_op(start, stop):\n        return jnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype, axis=axis)\n\n    def np_op(start, stop):\n        start = start.astype(np.float32) if dtype == jnp.bfloat16 else start\n        stop = stop.astype(np.float32) if dtype == jnp.bfloat16 else stop\n        return np.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype if dtype != jnp.bfloat16 else np.float32, axis=axis).astype(dtype)\n    if not (jtu.numpy_version() < (2, 0, 0) and dtypes.issubdtype(dtype, jnp.complexfloating)):\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker, check_dtypes=False, tol=tol)\n    if dtype in inexact_dtypes + [None]:\n        self._CompileAndCheck(jnp_op, args_maker, check_dtypes=False, atol=tol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def args_maker():\n    \"\"\"Test the set of inputs np.geomspace is well-defined on.\"\"\"\n    start, stop = self._GetArgsMaker(rng, [start_shape, stop_shape], [dtype, dtype])()\n    start, stop = jnp.broadcast_arrays(start, stop)\n    if dtype in complex_dtypes:\n        return (start, stop)\n    start = start * jnp.sign(start) * jnp.sign(stop)\n    return (start, stop)"
  },
  {
    "test_code": "@jtu.sample_product([dict(name=rec.name, np_op=getattr(np, rec.name), jnp_op=getattr(jnp, rec.name)) for rec in JAX_ARGMINMAX_RECORDS])\ndef testArgMinMaxEmpty(self, name, np_op, jnp_op):\n    name = name[3:] if name.startswith('nan') else name\n    msg = f'attempt to get {name} of an empty sequence'\n    with self.assertRaisesRegex(ValueError, msg):\n        jnp_op(np.array([]))\n    with self.assertRaisesRegex(ValueError, msg):\n        jnp_op(np.zeros((2, 0)), axis=1)\n    np_fun = jtu.with_jax_dtype_defaults(partial(np_op, axis=0))\n    jnp_fun = partial(jnp_op, axis=0)\n    args_maker = lambda: [np.zeros((2, 0))]\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def jnp_op(start, stop):\n    return jnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype, axis=axis)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis) for shape in all_shapes for axis in [None] + list(range(-len(shape), len(shape)))], op=['cumsum', 'cumprod'], dtype=all_dtypes, out_dtype=[dtype for dtype in default_dtypes if dtype != np.float16])\ndef testCumSumProd(self, axis, shape, dtype, out_dtype, op):\n    jnp_op = getattr(jnp, op)\n    np_op = getattr(np, op)\n    rng = jtu.rand_default(self.rng())\n    np_fun = lambda arg: np_op(arg, axis=axis, dtype=out_dtype)\n    np_fun = jtu.ignore_warning(category=NumpyComplexWarning)(np_fun)\n    np_fun = jtu.ignore_warning(category=RuntimeWarning, message='overflow encountered.*')(np_fun)\n    jnp_fun = lambda arg: jnp_op(arg, axis=axis, dtype=out_dtype)\n    jnp_fun = jtu.ignore_warning(category=jnp.ComplexWarning)(jnp_fun)\n    args_maker = lambda: [rng(shape, dtype)]\n    tol_thresholds = {dtypes.bfloat16: 0.04}\n    tol = max(jtu.tolerance(dtype, tol_thresholds), jtu.tolerance(out_dtype, tol_thresholds))\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def jnp_op(start, stop):\n    return jnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype, axis=axis)"
  },
  {
    "test_code": "@jtu.sample_product(shape=nonempty_array_shapes, dtype=all_dtypes, num_args=[0, 1, 'all'], use_tuple=[True, False])\ndef testItem(self, shape, dtype, num_args, use_tuple):\n    rng = jtu.rand_default(self.rng())\n    size = math.prod(shape)\n    if num_args == 0:\n        args = ()\n    elif num_args == 1:\n        args = (self.rng().randint(0, size),)\n    else:\n        args = tuple((self.rng().randint(0, s) for s in shape))\n    args = (args,) if use_tuple else args\n    np_op = lambda x: np.asarray(x).item(*args)\n    jnp_op = lambda x: jnp.asarray(x).item(*args)\n    args_maker = lambda: [rng(shape, dtype)]\n    if size != 1 and num_args == 0:\n        with self.assertRaises(ValueError):\n            jnp_op(*args_maker())\n    else:\n        self._CheckAgainstNumpy(np_op, jnp_op, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def jnp_op(start, stop):\n    return jnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype, axis=axis)"
  },
  {
    "test_code": "@jtu.sample_product(dtype=float_dtypes, op=('sqrt', 'arccos', 'arcsin', 'arctan', 'sin', 'cos', 'tan', 'sinh', 'cosh', 'tanh', 'arccosh', 'arcsinh', 'arctanh', 'exp', 'log', 'expm1', 'log1p'))\ndef testMathSpecialFloatValues(self, op, dtype):\n    np_op = getattr(np, op)\n    np_op = jtu.ignore_warning(category=RuntimeWarning, message='invalid value.*')(np_op)\n    np_op = jtu.ignore_warning(category=RuntimeWarning, message='divide by zero.*')(np_op)\n    np_op = jtu.ignore_warning(category=RuntimeWarning, message='overflow.*')(np_op)\n    jnp_op = getattr(jnp, op)\n    dtype = np.dtype(dtypes.canonicalize_dtype(dtype)).type\n    for x in (np.nan, -np.inf, -100.0, -2.0, -1.0, 0.0, 1.0, 2.0, 100.0, np.inf, jnp.finfo(dtype).max, np.sqrt(jnp.finfo(dtype).max), np.sqrt(jnp.finfo(dtype).max) * 2.0):\n        x = dtype(x)\n        expected = np_op(x)\n        actual = jnp_op(x)\n        tol = jtu.tolerance(dtype, {np.float32: 0.001, np.float64: 1e-07})\n        self.assertAllClose(expected, actual, atol=tol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def jnp_op(start, stop):\n    return jnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype, axis=axis)"
  },
  {
    "test_code": "@jtu.sample_product(shape=all_shapes, dtype=default_dtypes, op=['ndim', 'shape', 'size'])\ndef testNdimShapeSize(self, shape, dtype, op):\n    rng = jtu.rand_default(self.rng())\n    jnp_op = getattr(jnp, op)\n    np_op = getattr(np, op)\n    x = rng(shape, dtype)\n    expected = np_op(x)\n    self.assertEqual(expected, jnp_op(x))\n    self.assertEqual(expected, jnp_op(jnp.asarray(x)))\n    self.assertEqual(expected, jax.jit(jnp_op)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def jnp_op(start, stop):\n    return jnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype, axis=axis)"
  },
  {
    "test_code": "@jtu.sample_product(mode=['full', 'same', 'valid'], op=['convolve', 'correlate'], dtype=number_dtypes, xshape=one_dim_array_shapes, yshape=one_dim_array_shapes)\ndef testConvolutions(self, xshape, yshape, dtype, mode, op):\n    jnp_op = getattr(jnp, op)\n    np_op = getattr(np, op)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(xshape, dtype), rng(yshape, dtype)]\n    precision = lax.Precision.HIGHEST if jtu.test_device_matches(['tpu']) else None\n    jnp_fun = partial(jnp_op, mode=mode, precision=precision)\n\n    def np_fun(x, y):\n        return np_op(x, y, mode=mode).astype(dtypes.to_inexact_dtype(dtype))\n    tol = {np.float16: 0.2, np.float32: 0.01, np.float64: 1e-14, np.complex128: 1e-14}\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, check_dtypes=True, tol=tol)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def np_op(start, stop):\n    start = start.astype(np.float32) if dtype == jnp.bfloat16 else start\n    stop = stop.astype(np.float32) if dtype == jnp.bfloat16 else stop\n    return np.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype if dtype != jnp.bfloat16 else np.float32, axis=axis).astype(dtype)"
  },
  {
    "test_code": "@jtu.sample_product(mode=['full', 'same', 'valid'], op=['convolve', 'correlate'], dtype=number_dtypes, xshape=one_dim_array_shapes, yshape=one_dim_array_shapes)\n@jtu.skip_on_devices('cuda', 'rocm')\ndef testConvolutionsPreferredElementType(self, xshape, yshape, dtype, mode, op):\n    jnp_op = getattr(jnp, op)\n    np_op = getattr(np, op)\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(xshape, dtype), rng(yshape, dtype)]\n    precision = lax.Precision.HIGHEST if jtu.test_device_matches(['tpu']) else None\n    jnp_fun = partial(jnp_op, mode=mode, precision=precision, preferred_element_type=dtype)\n\n    def np_fun(x, y):\n        return np_op(x, y, mode=mode).astype(dtype)\n    tol = {np.float16: 0.2, np.float32: 0.01, np.float64: 1e-14, np.complex128: 1e-14}\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, check_dtypes=True, tol=tol)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def np_op(start, stop):\n    start = start.astype(np.float32) if dtype == jnp.bfloat16 else start\n    stop = stop.astype(np.float32) if dtype == jnp.bfloat16 else stop\n    return np.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype if dtype != jnp.bfloat16 else np.float32, axis=axis).astype(dtype)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, axis=axis) for shape in all_shapes for axis in [None] + list(range(-len(shape), len(shape)))], op=['cumsum', 'cumprod'], dtype=all_dtypes, out_dtype=[dtype for dtype in default_dtypes if dtype != np.float16])\ndef testCumSumProd(self, axis, shape, dtype, out_dtype, op):\n    jnp_op = getattr(jnp, op)\n    np_op = getattr(np, op)\n    rng = jtu.rand_default(self.rng())\n    np_fun = lambda arg: np_op(arg, axis=axis, dtype=out_dtype)\n    np_fun = jtu.ignore_warning(category=NumpyComplexWarning)(np_fun)\n    np_fun = jtu.ignore_warning(category=RuntimeWarning, message='overflow encountered.*')(np_fun)\n    jnp_fun = lambda arg: jnp_op(arg, axis=axis, dtype=out_dtype)\n    jnp_fun = jtu.ignore_warning(category=jnp.ComplexWarning)(jnp_fun)\n    args_maker = lambda: [rng(shape, dtype)]\n    tol_thresholds = {dtypes.bfloat16: 0.04}\n    tol = max(jtu.tolerance(dtype, tol_thresholds), jtu.tolerance(out_dtype, tol_thresholds))\n    self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fun, args_maker)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def np_op(start, stop):\n    start = start.astype(np.float32) if dtype == jnp.bfloat16 else start\n    stop = stop.astype(np.float32) if dtype == jnp.bfloat16 else stop\n    return np.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype if dtype != jnp.bfloat16 else np.float32, axis=axis).astype(dtype)"
  },
  {
    "test_code": "@jtu.sample_product(dtype=float_dtypes, op=('sqrt', 'arccos', 'arcsin', 'arctan', 'sin', 'cos', 'tan', 'sinh', 'cosh', 'tanh', 'arccosh', 'arcsinh', 'arctanh', 'exp', 'log', 'expm1', 'log1p'))\ndef testMathSpecialFloatValues(self, op, dtype):\n    np_op = getattr(np, op)\n    np_op = jtu.ignore_warning(category=RuntimeWarning, message='invalid value.*')(np_op)\n    np_op = jtu.ignore_warning(category=RuntimeWarning, message='divide by zero.*')(np_op)\n    np_op = jtu.ignore_warning(category=RuntimeWarning, message='overflow.*')(np_op)\n    jnp_op = getattr(jnp, op)\n    dtype = np.dtype(dtypes.canonicalize_dtype(dtype)).type\n    for x in (np.nan, -np.inf, -100.0, -2.0, -1.0, 0.0, 1.0, 2.0, 100.0, np.inf, jnp.finfo(dtype).max, np.sqrt(jnp.finfo(dtype).max), np.sqrt(jnp.finfo(dtype).max) * 2.0):\n        x = dtype(x)\n        expected = np_op(x)\n        actual = jnp_op(x)\n        tol = jtu.tolerance(dtype, {np.float32: 0.001, np.float64: 1e-07})\n        self.assertAllClose(expected, actual, atol=tol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def np_op(start, stop):\n    start = start.astype(np.float32) if dtype == jnp.bfloat16 else start\n    stop = stop.astype(np.float32) if dtype == jnp.bfloat16 else stop\n    return np.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype if dtype != jnp.bfloat16 else np.float32, axis=axis).astype(dtype)"
  },
  {
    "test_code": "@jtu.sample_product(shape=all_shapes, dtype=default_dtypes, op=['ndim', 'shape', 'size'])\ndef testNdimShapeSize(self, shape, dtype, op):\n    rng = jtu.rand_default(self.rng())\n    jnp_op = getattr(jnp, op)\n    np_op = getattr(np, op)\n    x = rng(shape, dtype)\n    expected = np_op(x)\n    self.assertEqual(expected, jnp_op(x))\n    self.assertEqual(expected, jnp_op(jnp.asarray(x)))\n    self.assertEqual(expected, jax.jit(jnp_op)(x))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def np_op(start, stop):\n    start = start.astype(np.float32) if dtype == jnp.bfloat16 else start\n    stop = stop.astype(np.float32) if dtype == jnp.bfloat16 else stop\n    return np.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype if dtype != jnp.bfloat16 else np.float32, axis=axis).astype(dtype)"
  },
  {
    "test_code": "def testStackArrayArgument(self):\n\n    @jax.jit\n    def foo(x):\n        return jnp.stack(x)\n    foo(np.zeros(2))\n\n    @jax.jit\n    def foo(x):\n        return jnp.concatenate(x)\n    foo(np.zeros((2, 2)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef foo(x):\n    return jnp.concatenate(x)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef g(z):\n    return f(z, z + 77)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.pmap\ndef g(z):\n    return f(z, z + 77)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef g(x):\n    z = x * 2\n    return shard_alike(x, z)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.jit\ndef g(x):\n    z = x * 2\n    return shard_alike(x, z)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.custom_jvp\ndef g(x):\n    return x"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.custom_jvp\ndef g(x):\n    return x"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, axis_size=[2, 4], axis=range(-2, 2), dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecdot(self, lhs_batch, rhs_batch, axis_size, axis, dtype):\n    size = min(len(lhs_batch), len(rhs_batch))\n    axis = int(np.clip(axis, -size - 1, size))\n    if axis >= 0:\n        lhs_shape = (*lhs_batch[:axis], axis_size, *lhs_batch[axis:])\n        rhs_shape = (*rhs_batch[:axis], axis_size, *rhs_batch[axis:])\n    else:\n        laxis = axis + len(lhs_batch) + 1\n        lhs_shape = (*lhs_batch[:laxis], axis_size, *lhs_batch[laxis:])\n        raxis = axis + len(rhs_batch) + 1\n        rhs_shape = (*rhs_batch[:raxis], axis_size, *rhs_batch[raxis:])\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y, axis=axis):\n        f = jtu.numpy_vecdot if jtu.numpy_version() < (2, 0, 0) else np.vecdot\n        return f(x, y, axis=axis).astype(x.dtype)\n    jnp_fn = partial(jnp.vecdot, axis=axis)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testMatvec(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, mat_size, vec_size)\n    rhs_shape = (*rhs_batch, vec_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.matvec\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(np.matmul, signature='(m,n),(n)->(m)') if jtu.numpy_version() < (2, 2, 0) else np.matvec\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "@jtu.sample_product(lhs_batch=broadcast_compatible_shapes, rhs_batch=broadcast_compatible_shapes, mat_size=[1, 2, 3], vec_size=[2, 3, 4], dtype=number_dtypes)\n@jax.default_matmul_precision('float32')\n@jax.numpy_rank_promotion('allow')\ndef testVecmat(self, lhs_batch, rhs_batch, mat_size, vec_size, dtype):\n    rng = jtu.rand_default(self.rng())\n    lhs_shape = (*lhs_batch, vec_size)\n    rhs_shape = (*rhs_batch, vec_size, mat_size)\n    args_maker = lambda: [rng(lhs_shape, dtype), rng(rhs_shape, dtype)]\n    jnp_fn = jnp.vecmat\n\n    @jtu.promote_like_jnp\n    def np_fn(x, y):\n        f = np.vectorize(lambda x, y: np.matmul(np.conj(x), y), signature='(m),(m,n)->(n)') if jtu.numpy_version() < (2, 2, 0) else np.vecmat\n        return f(x, y).astype(x.dtype)\n    tol = {np.float16: 0.01, np.float32: 0.001, np.float64: 1e-12, np.complex64: 0.001, np.complex128: 1e-12, jnp.bfloat16: 0.1}\n    self._CheckAgainstNumpy(np_fn, jnp_fn, args_maker, tol=tol)\n    self._CompileAndCheck(jnp_fn, args_maker, tol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def testPadWithNumpyPadWidth(self):\n    a = jnp.array([1, 2, 3, 4, 5])\n    f = jax.jit(partial(jnp.pad, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))\n    np.testing.assert_array_equal(f(a), np.pad(a, pad_width=np.asarray((2, 3)), mode='constant', constant_values=(4, 6)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def testIsInstanceNdarrayDuringTracing(self):\n    arr = np.ones(3)\n\n    @jax.jit\n    def f(x):\n        self.assertIsInstance(x, jax.Array)\n        return jnp.sum(x)\n    f(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def testAbstractionErrorMessage(self):\n\n    @jax.jit\n    def f(x, n):\n        for _ in range(n):\n            x = x * x\n        return x\n    self.assertRaises(jax.errors.TracerIntegerConversionError, lambda: f(3.0, 3))\n\n    @jax.jit\n    def g(x):\n        if x > 0.0:\n            return x * 2\n        else:\n            return x + 2\n    self.assertRaises(jax.errors.ConcretizationTypeError, lambda: g(3.0))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def testIssue764(self):\n    x = jnp.linspace(190, 200, 4)\n    f = jax.grad(lambda x: jnp.sum(jnp.tanh(x)))\n    expected = np.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171, 7.66067839e-174], np.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def testToBytesJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tobytes())\n    msg = '.*The tobytes\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def testToListJitError(self):\n    v = np.arange(12, dtype=np.int32).reshape(3, 4)\n    f = jax.jit(lambda x: x.tolist())\n    msg = '.*The tolist\\\\(\\\\) method was called on traced array'\n    with self.assertRaisesRegex(core.ConcretizationTypeError, msg):\n        f(v)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def testSincAtZero(self):\n\n    def deriv(f):\n        return lambda x: jax.jvp(f, (x,), (1.0,))[1]\n\n    def apply_all(fns, x):\n        for f in fns:\n            x = f(x)\n        return x\n    d1 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 1):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d1)\n    d2 = -np.pi ** 2 / 3\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 2):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d2)\n    d3 = 0.0\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 3):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d3)\n    d4 = np.pi ** 4 / 5\n    for ops in itertools.combinations_with_replacement([deriv, jax.grad], 4):\n        self.assertAllClose(apply_all(ops, jnp.sinc)(0.0), d4)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "@jtu.sample_product([dict(lhs_shape=lhs_shape, lhs_dtype=lhs_dtype, rhs_shape=rhs_shape, rhs_dtype=rhs_dtype) for lhs_shape, lhs_dtype in _shape_and_dtypes(all_shapes, inexact_dtypes) for rhs_shape, rhs_dtype in _shape_and_dtypes(all_shapes, inexact_dtypes) if len(jtu._dims_of_shape(lhs_shape)) == 0 or len(jtu._dims_of_shape(rhs_shape)) == 0 or lhs_shape[-1] == rhs_shape[-1]])\n@jax.default_matmul_precision('float32')\ndef testInner(self, lhs_shape, lhs_dtype, rhs_shape, rhs_dtype):\n    rng = jtu.rand_default(self.rng())\n    args_maker = lambda: [rng(lhs_shape, lhs_dtype), rng(rhs_shape, rhs_dtype)]\n\n    def np_fun(lhs, rhs):\n        lhs = lhs if lhs_dtype != jnp.bfloat16 else lhs.astype(np.float32)\n        rhs = rhs if rhs_dtype != jnp.bfloat16 else rhs.astype(np.float32)\n        dtype = jnp.promote_types(lhs_dtype, rhs_dtype)\n        return np.inner(lhs, rhs).astype(dtype)\n    jnp_fun = lambda lhs, rhs: jnp.inner(lhs, rhs)\n    tol_spec = {np.float16: 0.01, np.float32: 1e-05, np.float64: 1e-13, np.complex64: 1e-05}\n    tol = max(jtu.tolerance(lhs_dtype, tol_spec), jtu.tolerance(rhs_dtype, tol_spec))\n    with jtu.strict_promotion_if_dtypes_match([lhs_dtype, rhs_dtype]):\n        self._CheckAgainstNumpy(np_fun, jnp_fun, args_maker, check_dtypes=False, tol=tol)\n        self._CompileAndCheck(jnp_fun, args_maker, check_dtypes=False, atol=tol, rtol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@jax.custom_vjp\ndef inner(carry, scale):\n    del scale\n    return carry"
  },
  {
    "test_code": "def testNonArrayErrorMessage(self):\n    x = [1.0, 2.0]\n    y = np.array([3.0, 4.0])\n\n    def g(x, y):\n        return jnp.add(x, y)\n\n    def f(x, y):\n        return jnp.dot(x, y)\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: jax.jit(f)(x, y))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_numpy_test.py",
    "function": "@staticmethod\ndef add(dt, x, y):\n    fromscale = partial(jax.lax.convert_element_type, new_dtype=dt.float_dtype)\n    toscale = partial(jax.lax.convert_element_type, new_dtype=dt)\n    return toscale(jax.lax.max(fromscale(x), fromscale(y)))"
  }
]