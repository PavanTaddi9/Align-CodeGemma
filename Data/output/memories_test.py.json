[
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_deepcopy(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'x')\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n    t = jax.device_put(jnp.zeros((8, 2)), s_host)\n    t_copy = copy.deepcopy(t)\n    self.assertArraysEqual(t, t_copy)\n    self.assertEqual(t.shape, t_copy.shape)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.run_on_devices('tpu')\ndef test_ragged_copy_on_host(self):\n    mesh = jtu.create_mesh((2,), 'x')\n    sharding = jax.sharding.NamedSharding(mesh, P('x'))\n    cpu_sharding = sharding.with_memory_kind('pinned_host')\n    num_pages = 512 * 1024\n    page_size = 1024\n    x = jnp.full((num_pages, page_size), 1, dtype=jnp.bfloat16, device=sharding)\n\n    def write(x):\n        return x.at[16 * 1024:].set(0)\n    x = shard_map(write, mesh, P('x'), P('x'))(x)\n    chunk_size = 8\n\n    def inner(state):\n        idx, x, output = state\n        chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n        chunk_host = jax.device_put(chunk, TransferToMemoryKind('pinned_host'))\n        output = jax.lax.dynamic_update_slice_in_dim(output, chunk_host, idx * chunk_size, axis=0)\n        return (idx + 1, x, output)\n\n    def cond(state):\n        idx, x, _ = state\n        chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n        return (idx * chunk_size < x.shape[0]) & jnp.any(chunk > 0)\n\n    def foo(x):\n        output = jnp.zeros_like(x, device=cpu_sharding)\n        _, _, cpu_x = jax.lax.while_loop(cond, inner, (0, x, output))\n        return cpu_x\n    fn = jax.jit(shard_map(foo, mesh, P('x'), P('x'), check_rep=False), out_shardings=cpu_sharding)\n    y = fn(x)\n    jax.block_until_ready(y)\n    compiled_text = fn.lower(x).compile().as_text()\n    if compiled_text is not None:\n        self.assertIn('custom_call_target=\"AllocateBuffer\"', compiled_text)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef fn(n, x):\n    return lax.broadcast_in_dim(x, (n,), ())"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g():\n    return jnp.zeros(n) + x"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g():\n    return jnp.zeros(n) + x"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def g():\n    return jax.lax.cond(True, lambda: data[0], lambda: data[1])"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def g():\n    return jax.lax.cond(True, lambda: data[0], lambda: data[1])"
  },
  {
    "test_code": "@jtu.run_on_devices('tpu')\ndef test_ragged_copy_on_host(self):\n    mesh = jtu.create_mesh((2,), 'x')\n    sharding = jax.sharding.NamedSharding(mesh, P('x'))\n    cpu_sharding = sharding.with_memory_kind('pinned_host')\n    num_pages = 512 * 1024\n    page_size = 1024\n    x = jnp.full((num_pages, page_size), 1, dtype=jnp.bfloat16, device=sharding)\n\n    def write(x):\n        return x.at[16 * 1024:].set(0)\n    x = shard_map(write, mesh, P('x'), P('x'))(x)\n    chunk_size = 8\n\n    def inner(state):\n        idx, x, output = state\n        chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n        chunk_host = jax.device_put(chunk, TransferToMemoryKind('pinned_host'))\n        output = jax.lax.dynamic_update_slice_in_dim(output, chunk_host, idx * chunk_size, axis=0)\n        return (idx + 1, x, output)\n\n    def cond(state):\n        idx, x, _ = state\n        chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n        return (idx * chunk_size < x.shape[0]) & jnp.any(chunk > 0)\n\n    def foo(x):\n        output = jnp.zeros_like(x, device=cpu_sharding)\n        _, _, cpu_x = jax.lax.while_loop(cond, inner, (0, x, output))\n        return cpu_x\n    fn = jax.jit(shard_map(foo, mesh, P('x'), P('x'), check_rep=False), out_shardings=cpu_sharding)\n    y = fn(x)\n    jax.block_until_ready(y)\n    compiled_text = fn.lower(x).compile().as_text()\n    if compiled_text is not None:\n        self.assertIn('custom_call_target=\"AllocateBuffer\"', compiled_text)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\ndef fn(a, b):\n    m1, v1 = a\n    m2, v2 = b\n    return (m1 + m2, jsp.linalg.solve(m1, v2) + jsp.linalg.solve(m2, v1))"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def scan(y):\n\n    def body(carry, x):\n        return (carry, jnp.dot(x, x))\n    return jax.lax.scan(body, 1.0, y, unroll=False)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def scan(y):\n\n    def body(carry, x):\n        return (carry, jnp.dot(x, x))\n    return jax.lax.scan(body, 1.0, y, unroll=False)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def scan(y):\n\n    def body(carry, x):\n        return (carry, jnp.dot(x, x))\n    return jax.lax.scan(body, 1.0, y, unroll=False)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def scan(y):\n\n    def body(carry, x):\n        return (carry, jnp.dot(x, x))\n    return jax.lax.scan(body, 1.0, y, unroll=False)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g():\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g():\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def g(a, b):\n    c = jnp.zeros_like(a)\n    _, b, c, _ = for_impl(5, body2, (a, b, c, 0))\n    return (b, c)"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def g(a, b):\n    c = jnp.zeros_like(a)\n    _, b, c, _ = for_impl(5, body2, (a, b, c, 0))\n    return (b, c)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g():\n    _, _, attr_tangents = attrs.jvp(f, (), (), [(thing, 'x', 1.0)])\n    (thing_, attr_, tangent_), = attr_tangents\n    self.assertIs(thing, thing_)\n    self.assertEqual(attr_, 'x')\n    return (jax_getattr(thing, 'x'), tangent_)"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g():\n    _, _, attr_tangents = attrs.jvp(f, (), (), [(thing, 'x', 1.0)])\n    (thing_, attr_, tangent_), = attr_tangents\n    self.assertIs(thing, thing_)\n    self.assertEqual(attr_, 'x')\n    return (jax_getattr(thing, 'x'), tangent_)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@pjit\ndef g(y):\n    return jnp.sin(y)"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@pjit\ndef g(y):\n    return jnp.sin(y)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.remat\ndef g(x):\n    jax.jit(lambda: 0 if jnp.add(1, 1) else 0)()\n    return lax.sin(x)"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.remat\ndef g(x):\n    jax.jit(lambda: 0 if jnp.add(1, 1) else 0)()\n    return lax.sin(x)"
  },
  {
    "test_code": "@jtu.run_on_devices('tpu')\ndef test_ragged_copy_on_host(self):\n    mesh = jtu.create_mesh((2,), 'x')\n    sharding = jax.sharding.NamedSharding(mesh, P('x'))\n    cpu_sharding = sharding.with_memory_kind('pinned_host')\n    num_pages = 512 * 1024\n    page_size = 1024\n    x = jnp.full((num_pages, page_size), 1, dtype=jnp.bfloat16, device=sharding)\n\n    def write(x):\n        return x.at[16 * 1024:].set(0)\n    x = shard_map(write, mesh, P('x'), P('x'))(x)\n    chunk_size = 8\n\n    def inner(state):\n        idx, x, output = state\n        chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n        chunk_host = jax.device_put(chunk, TransferToMemoryKind('pinned_host'))\n        output = jax.lax.dynamic_update_slice_in_dim(output, chunk_host, idx * chunk_size, axis=0)\n        return (idx + 1, x, output)\n\n    def cond(state):\n        idx, x, _ = state\n        chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n        return (idx * chunk_size < x.shape[0]) & jnp.any(chunk > 0)\n\n    def foo(x):\n        output = jnp.zeros_like(x, device=cpu_sharding)\n        _, _, cpu_x = jax.lax.while_loop(cond, inner, (0, x, output))\n        return cpu_x\n    fn = jax.jit(shard_map(foo, mesh, P('x'), P('x'), check_rep=False), out_shardings=cpu_sharding)\n    y = fn(x)\n    jax.block_until_ready(y)\n    compiled_text = fn.lower(x).compile().as_text()\n    if compiled_text is not None:\n        self.assertIn('custom_call_target=\"AllocateBuffer\"', compiled_text)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@custom_transpose_with_example_out(jnp.ones(2))\ndef fn(r, x):\n    tracer_spy.append(r)\n    tracer_spy.append(x['c'])\n    return dict(b=x['c'] / r)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g(x):\n    if x > 0.0:\n        return x * 2\n    else:\n        return x + 2"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g(x):\n    if x > 0.0:\n        return x * 2\n    else:\n        return x + 2"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef g(z):\n    return f(z, z + 77)"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.pmap\ndef g(z):\n    return f(z, z + 77)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g(x):\n    z = x * 2\n    return shard_alike(x, z)"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g(x):\n    z = x * 2\n    return shard_alike(x, z)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.custom_jvp\ndef g(x):\n    return x"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.custom_jvp\ndef g(x):\n    return x"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.custom_jvp\ndef h(x):\n    return x"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g(x):\n    if x > 0.0:\n        return x * 2\n    else:\n        return x + 2"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g(x):\n    if x > 0.0:\n        return x * 2\n    else:\n        return x + 2"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('x', 'y'), out_specs=out_spec)\ndef g(x):\n    result = lax.psum(x, axis_name=reduce_along)\n\n    def check_rep(result):\n        self.assertEqual(jax.experimental.shard_map.get_replication(result), set(reduce_along))\n        return result\n    result = check_rep(result)\n    result = jax.vmap(check_rep)(result)\n    return result"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('x', 'y'), out_specs=out_spec)\ndef g(x):\n    result = lax.psum(x, axis_name=reduce_along)\n\n    def check_rep(result):\n        self.assertEqual(jax.experimental.shard_map.get_replication(result), set(reduce_along))\n        return result\n    result = check_rep(result)\n    result = jax.vmap(check_rep)(result)\n    return result"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def h():\n\n    def _make_zeros():\n        return jnp.zeros(())\n    s = jax.sharding.NamedSharding(mesh2, P())\n    y = jax.jit(_make_zeros, out_shardings=s)()\n    return y.reshape((1,))"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g(x):\n    return x"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g(x):\n    return x"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def g(x):\n    return jax.pure_callback(lambda x: x, x, x)"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def g(x):\n    return jax.pure_callback(lambda x: x, x, x)"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\n@functools.partial(jax.vmap, in_axes=(1, None), out_axes=1)\ndef h(x, y):\n    return jax.pure_callback(lambda x, y: np.sin(x) + y, x, x, y, vmap_method='legacy_vectorized')"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.custom_jvp\ndef sin(x):\n    return jax.pure_callback(np.sin, x, x)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.custom_jvp\ndef sin(x):\n    return jax.pure_callback(np.sin, x, x)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.custom_jvp\ndef sin(x):\n    return jax.pure_callback(np.sin, x, x)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.custom_jvp\ndef sin(x):\n    return jax.pure_callback(np.sin, x, x)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def g(a, b):\n    an, ai = a\n    bn, bi = b\n    which = an >= bn\n    return (jnp.where(which, an, bn), jnp.where(which, ai, bi))"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def g(a, b):\n    an, ai = a\n    bn, bi = b\n    which = an >= bn\n    return (jnp.where(which, an, bn), jnp.where(which, ai, bi))"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.profiler.annotate_function, name='aname')\ndef g(x):\n    return x + 2"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.profiler.annotate_function, name='aname')\ndef g(x):\n    return x + 2"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.profiler.annotate_function, name='aname', akwarg='hello')\ndef h(x):\n    return x + 2"
  },
  {
    "test_code": "@jtu.run_on_devices('tpu')\ndef test_ragged_copy_on_host(self):\n    mesh = jtu.create_mesh((2,), 'x')\n    sharding = jax.sharding.NamedSharding(mesh, P('x'))\n    cpu_sharding = sharding.with_memory_kind('pinned_host')\n    num_pages = 512 * 1024\n    page_size = 1024\n    x = jnp.full((num_pages, page_size), 1, dtype=jnp.bfloat16, device=sharding)\n\n    def write(x):\n        return x.at[16 * 1024:].set(0)\n    x = shard_map(write, mesh, P('x'), P('x'))(x)\n    chunk_size = 8\n\n    def inner(state):\n        idx, x, output = state\n        chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n        chunk_host = jax.device_put(chunk, TransferToMemoryKind('pinned_host'))\n        output = jax.lax.dynamic_update_slice_in_dim(output, chunk_host, idx * chunk_size, axis=0)\n        return (idx + 1, x, output)\n\n    def cond(state):\n        idx, x, _ = state\n        chunk = jax.lax.dynamic_slice_in_dim(x, idx * chunk_size, chunk_size)\n        return (idx * chunk_size < x.shape[0]) & jnp.any(chunk > 0)\n\n    def foo(x):\n        output = jnp.zeros_like(x, device=cpu_sharding)\n        _, _, cpu_x = jax.lax.while_loop(cond, inner, (0, x, output))\n        return cpu_x\n    fn = jax.jit(shard_map(foo, mesh, P('x'), P('x'), check_rep=False), out_shardings=cpu_sharding)\n    y = fn(x)\n    jax.block_until_ready(y)\n    compiled_text = fn.lower(x).compile().as_text()\n    if compiled_text is not None:\n        self.assertIn('custom_call_target=\"AllocateBuffer\"', compiled_text)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def fn(data, segment_ids):\n    return jax.ops.segment_sum(data, segment_ids, num_segments).sum()"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\ndef g(x):\n    return x * 2"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\ndef g(x):\n    return x * 2"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_parameter_streaming_with_scalar_and_constant(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    scalar_inp = 1\n    s_host = NamedSharding(mesh, P(), memory_kind='pinned_host')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(scalar_input):\n        y = jax.device_put(scalar_input, s_host)\n        z = 2\n        w = jax.device_put(z, s_host)\n        return (y, w)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, 2, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_array(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    inp_host = jax.device_put(np_inp, s_host)\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host)\n    self._check_device_put_addressable_shards(out1, np_inp, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_parameter_and_output_streaming_with_scalar(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jax.sharding.Mesh(jax.devices(), 'axis')\n    s_host = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(), memory_kind='pinned_host')\n    scalar_inp = 1\n\n    @functools.partial(jax.jit, out_shardings=(s_host, s_host))\n    def f(x):\n        return (x, x)\n    compiled = f.lower(scalar_inp).compile()\n    compiled_text = compiled.as_text()\n    if compiled_text is not None:\n        self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(scalar_inp)\n    self._check_device_put_addressable_shards(out1, scalar_inp, s_host, 'pinned_host', index=False)\n    self._check_device_put_addressable_shards(out2, scalar_inp, s_host, 'pinned_host', index=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_parameter_streaming_inside_scan(self):\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096.0).reshape(16, 16, 16)\n    s_host = NamedSharding(mesh, P('x', 'y', 'z'), memory_kind='pinned_host')\n    arr_host = jax.device_put(np_inp, s_host)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            x_tpu = jax.device_put(x, TransferToMemoryKind('device'))\n            return (carry, x_tpu + carry)\n        return jax.lax.scan(body, 1.0, xs)\n    _, out_hbm = f(arr_host)\n    self.assertArraysEqual(out_hbm, np_inp + 1.0)\n    out_s = NamedSharding(mesh, P(None, None, 'z'), memory_kind='device')\n    self.assertEqual(out_hbm.sharding, out_s)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_output_streaming(self):\n    mesh = jtu.create_mesh((1, 1), ('x', 'y'))\n    np_inp = np.arange(16.0).reshape(8, 2)\n    s_hbm = NamedSharding(mesh, P('x', 'y'), memory_kind='device')\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(xs):\n        out_tpu = xs + 1.0\n        return out_tpu\n    out_host = f(arr_hbm)\n    self.assertArraysEqual(out_host, np_inp + 1.0)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_output_streaming_inside_scan(self):\n    if xb.backend_xla_version() is not None and xb.backend_xla_version() < 2:\n        self.skipTest('This test requires an xla_version >= 2.')\n    mesh = jtu.create_mesh((1, 1, 2), ('x', 'y', 'z'))\n    np_inp = np.arange(4096).reshape(16, 16, 16)\n    s_hbm = NamedSharding(mesh, P(None, 'y', 'z'), memory_kind='device')\n    arr_hbm = jax.device_put(np_inp, s_hbm)\n\n    @jax.jit\n    def f(xs):\n\n        def body(carry, x):\n            out_tpu = x + carry\n            return (carry, jax.device_put(out_tpu, NamedSharding(mesh, P('y', 'z'), memory_kind='pinned_host')))\n        _, res = jax.lax.scan(body, 1, xs)\n        return res\n    out = f(arr_hbm)\n    self.assertArraysEqual(out, np_inp + 1)\n    self.assertEqual(out.sharding.memory_kind, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_remat_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    inp = jax.device_put(np.arange(16.0), NamedSharding(mesh, P('x')))\n\n    def policy(prim, *avals, **params):\n        return Offloadable(src='device', dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        x = jnp.sin(x)\n        return jnp.sum(x)\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 4)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 3)\n    self.assertLen(bwd_jaxpr.in_avals, 4)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 3)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        if jtu.pjrt_c_api_version_at_least(0, 43):\n            self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_remat_scan_jaxpr_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    with self.assertRaisesRegex(ValueError, 'The names should be exclusive and should not intersect'):\n        jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['y', 'w'], offload_src='device', offload_dst='pinned_host')\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    fwd_jaxpr, bwd_jaxpr = jtu.fwd_bwd_jaxprs(f, inp)\n    self.assertLen(fwd_jaxpr.out_avals, 5)\n    fwd_mem_kind_count = str(fwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='pinned_host')\")\n    self.assertEqual(fwd_mem_kind_count, 2)\n    self.assertLen(bwd_jaxpr.in_avals, 5)\n    bwd_mem_kind_count = str(bwd_jaxpr).count(\"TransferToMemoryKind(memory_kind='device')\")\n    self.assertEqual(bwd_mem_kind_count, 2)\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_remat_scan_layout_change_offloadable(self):\n    mesh = jtu.create_mesh((2,), ('x',))\n    shape = (256, 128)\n    np_inp = np.arange(math.prod(shape), dtype=np.float32).reshape(shape)\n    s = NamedSharding(mesh, P('x'))\n    inp = jax.device_put(np_inp, s)\n    policy = jax.checkpoint_policies.save_and_offload_only_these_names(names_which_can_be_saved=['y'], names_which_can_be_offloaded=['z', 'w'], offload_src='device', offload_dst='pinned_host')\n\n    @functools.partial(remat, policy=policy)\n    def f(x):\n\n        def g(ys, _):\n            y, _ = ys\n            y = checkpoint_name(jnp.sin(y), 'y')\n            z = checkpoint_name(jnp.sin(y), 'z')\n            z = jax.lax.with_sharding_constraint(z, s)\n            z = z.T\n            w = checkpoint_name(jnp.sin(z), 'w')\n            return ((w.T, jnp.sum(w)), None)\n        _, scan_out = jax.lax.scan(g, (x, np.array(1, dtype=np.float32)), [np_inp])[0]\n        return scan_out\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertNotRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertNotRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-update-slice-done.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'dynamic-slice-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_remat_checkpoint_dots_with_no_batch_dims(self):\n    policy = jax.checkpoint_policies.offload_dot_with_no_batch_dims('device', 'pinned_host')\n\n    @functools.partial(new_checkpoint, policy=policy)\n    def f(x):\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n        x = jnp.sin(x)\n        x = jnp.sum(x)\n        return x\n    inp = jnp.ones((2, 2))\n    f = jax.jit(jax.grad(f))\n    f(inp)\n    compiled_f = f.lower(inp).compile()\n    compiled_text = compiled_f.as_text()\n    if compiled_text is not None:\n        self.assertIn('S(5)', compiled_text)\n        self.assertRegex(compiled_text, 'copy-start.*S\\\\(5\\\\)')\n        self.assertRegex(compiled_text, 'copy-done.*S\\\\(5\\\\)')\n    compiled_stats = compiled_f.memory_analysis()\n    if compiled_stats is not None:\n        self.assertGreater(compiled_stats.host_temp_size_in_bytes, 0)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_identity_jit_host_to_device_and_vice_versa(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(16).reshape(8, 2)\n    s_host = NamedSharding(mesh, P('x', 'y'), memory_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    arr_host = jax.device_put(np_inp, s_host)\n    arr_dev = jax.device_put(np_inp, s_dev)\n    f = jax.jit(lambda x: x, out_shardings=s_dev)\n    out_dev = f(arr_host)\n    self.assertArraysEqual(out_dev, np_inp)\n    self.assertEqual(out_dev.sharding, s_dev)\n    g = jax.jit(lambda x: x, out_shardings=s_host)\n    out_host = g(arr_dev)\n    self.assertArraysEqual(out_host, np_inp)\n    self.assertEqual(out_host.sharding, s_host)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g():\n    x = x_ref[...] * y_ref[...]\n    y_ref[...] = x * 2\n    x_ref[...] = y_ref[...] + x_ref[...]"
  },
  {
    "test_code": "def test_stream_annotation_inside_shmap(self):\n    if not jtu.test_device_matches(['gpu']):\n        self.skipTest('Stream annotation is only supported on GPU.')\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    np_inp = np.ones((8, 8))\n    arr1 = jax.device_put(np_inp, s)\n    arr2 = jax.device_put(np_inp, s)\n\n    @compute_on('gpu_stream:1')\n    @jax.jit\n    def g(x, y):\n        return x @ y\n\n    @compute_on('gpu_stream:2')\n    @jax.jit\n    def h(x, y):\n        return x @ y\n\n    def f(x, y):\n        z = g(x, y)\n        w = h(3 * x, 2 * y)\n        return z + w\n    out = jax.jit(shard_map(f, mesh=mesh, in_specs=(P('x', 'y'), P('x', 'y')), out_specs=P('x', 'y')))(arr1, arr2)\n    self.assertArraysEqual(out, arr1 * 28)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "@jax.jit\ndef g():\n    x = x_ref[...] * y_ref[...]\n    y_ref[...] = x * 2\n    x_ref[...] = y_ref[...] + x_ref[...]"
  },
  {
    "test_code": "def test_device_put_inside_jit(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @jax.jit\n    def f(a, b):\n        x, y = jax.device_put((a, b), s_dev)\n        return x * y\n    out = f(inp_host, inp_host)\n    self._check_device_put_addressable_shards(out, np_inp * np_inp, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def _create_inputs(shape, pspec, mem_kind=None):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    s = NamedSharding(mesh, pspec, memory_kind=mem_kind)\n    inp = jax.device_put(np_inp, s)\n    return (mesh, s, np_inp, inp)"
  },
  {
    "test_code": "def test_parameter_streaming(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n    inp_dev = jax.device_put(np_inp, s_dev)\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a, b):\n        x = b * 2\n        y = jax.device_put(a, s_dev)\n        z = x * y\n        return (z * 4, z)\n    compiled = f.lower(inp_host, inp_dev).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out1, out2 = f(inp_host, inp_dev)\n    self._check_device_put_addressable_shards(out1, np_inp * np_inp * 8, s_host, 'pinned_host')\n    self._check_device_put_addressable_shards(out2, np_inp * np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def _create_inputs(shape, pspec, mem_kind=None):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    s = NamedSharding(mesh, pspec, memory_kind=mem_kind)\n    inp = jax.device_put(np_inp, s)\n    return (mesh, s, np_inp, inp)"
  },
  {
    "test_code": "def test_zero_size_parameter(self):\n    if jtu.test_device_matches(['gpu']):\n        self.skipTest('This test does not work on GPU backend.')\n    _, s_host, np_inp, inp_host = _create_inputs((0,), P(), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_host)\n    def f(a):\n        b = jax.device_put(a, s_dev)\n        return b\n    compiled = f.lower(inp_host).compile()\n    compiled_text = compiled.as_text()\n    self.assertRegex(compiled_text, 'entry_computation_layout=.*S\\\\(5\\\\)}')\n    out = f(inp_host)\n    self._check_device_put_addressable_shards(out, np_inp, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def _create_inputs(shape, pspec, mem_kind=None):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    s = NamedSharding(mesh, pspec, memory_kind=mem_kind)\n    inp = jax.device_put(np_inp, s)\n    return (mesh, s, np_inp, inp)"
  },
  {
    "test_code": "def test_weight_offload_with_dp_on_output(self):\n    _, s_dev, np_inp, inp_dev = _create_inputs((8, 2), P('x', 'y'), mem_kind='device')\n    s_host = s_dev.with_memory_kind('pinned_host')\n\n    @jax.jit\n    def f(x):\n        x = x * 2\n        y = jax.device_put(x, s_host)\n        return y\n    out_host = f(inp_dev)\n    self._check_device_put_addressable_shards(out_host, np_inp * 2, s_host, 'pinned_host')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def _create_inputs(shape, pspec, mem_kind=None):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    s = NamedSharding(mesh, pspec, memory_kind=mem_kind)\n    inp = jax.device_put(np_inp, s)\n    return (mesh, s, np_inp, inp)"
  },
  {
    "test_code": "def test_close_over_host_constant_and_stream(self):\n    _, s_host, np_inp, inp_host = _create_inputs((8, 2), P('x', 'y'), mem_kind='pinned_host')\n    s_dev = s_host.with_memory_kind('device')\n\n    @functools.partial(jax.jit, out_shardings=s_dev)\n    def f():\n        y = jax.device_put(inp_host, s_dev)\n        z = y * 2\n        return z\n    out = f()\n    self._check_device_put_addressable_shards(out, np_inp * 2, s_dev, 'device')",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/memories_test.py",
    "function": "def _create_inputs(shape, pspec, mem_kind=None):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    s = NamedSharding(mesh, pspec, memory_kind=mem_kind)\n    inp = jax.device_put(np_inp, s)\n    return (mesh, s, np_inp, inp)"
  }
]