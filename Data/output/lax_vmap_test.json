[
  {
    "test_code": "@jtu.sample_product([dict(lhs_shape=lhs_shape, rhs_shape=rhs_shape, dimension_numbers=dimension_numbers, bdims=bdims) for lhs_shape, rhs_shape, dimension_numbers in [((3, 3, 2), (3, 2, 4), (([2], [1]), ([0], [0]))), ((3, 3, 2), (2, 3, 4), (([2], [0]), ([0], [1]))), ((3, 4, 2, 4), (3, 4, 3, 2), (([2], [3]), ([0, 1], [0, 1])))] for bdims in lax_test_util.all_bdims(lhs_shape, rhs_shape)], dtype=lax_test_util.default_dtypes)\ndef testDotGeneralContractAndBatch(self, lhs_shape, rhs_shape, dtype, dimension_numbers, bdims):\n    rng = jtu.rand_small(self.rng())\n    dot = partial(lax.dot_general, dimension_numbers=dimension_numbers)\n    self._CheckBatching(dot, 5, bdims, (lhs_shape, rhs_shape), (dtype, dtype), rng)\n    jaxpr = jax.make_jaxpr(dot)(np.zeros(lhs_shape, dtype), np.zeros(rhs_shape, dtype))\n    for eqn in jtu.iter_eqns(jaxpr.jaxpr):\n        self.assertFalse(eqn.primitive in ['transpose', 'broadcast'])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "@jtu.skip_on_devices('gpu')\ndef test_variadic_reduce_window(self):\n\n    def normpool(x):\n        norms = jnp.linalg.norm(x, axis=-1)\n        idxs = jnp.arange(x.shape[0])\n\n        def g(a, b):\n            an, ai = a\n            bn, bi = b\n            which = an >= bn\n            return (jnp.where(which, an, bn), jnp.where(which, ai, bi))\n        inf = jnp.array(np.inf, dtype=norms.dtype)\n        one = jnp.array(1, dtype=idxs.dtype)\n        _, idxs = lax.reduce_window((norms, idxs), (-inf, -one), g, window_dimensions=(2,), window_strides=(2,), padding=((0, 0),))\n        return x[idxs]\n    inpt = jnp.array([[1.0, 0.0, 1.0], [2.0, 2.0, 0.0], [3.0, 0.0, 1.0], [0.0, 1.0, 1.0]])\n    output = jax.vmap(normpool)(inpt[None, ...])\n    expected = jnp.array([[[2.0, 2.0, 0.0], [3.0, 0.0, 1.0]]])\n    self.assertAllClose(output, expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def norm(x):\n    norm = np.linalg.norm(x, axis=(-2, -1))\n    return norm / ((inner_dimension + 1) * jnp.finfo(dtype).eps)"
  },
  {
    "test_code": "@jtu.sample_product([dict(lhs_shape=lhs_shape, rhs_shape=rhs_shape, batch_group_count=batch_group_count, feature_group_count=feature_group_count) for batch_group_count, feature_group_count in [(1, 1), (2, 1), (1, 2)] for b, i, j in itertools.product([1, 2], repeat=3) for lhs_shape in [(b * batch_group_count, i * feature_group_count, 6, 7)] for rhs_shape in [(j * batch_group_count * feature_group_count, i, 1, 2)]], [dict(lhs_bdim=lhs_bdim, rhs_bdim=rhs_bdim) for lhs_bdim in itertools.chain([cast(Union[int, None], None)], range(5)) for rhs_bdim in itertools.chain([cast(Union[int, None], None)], range(5)) if (lhs_bdim, rhs_bdim) != (None, None)], [dict(dimension_numbers=dim_nums, perms=perms) for dim_nums, perms in [(('NCHW', 'OIHW', 'NCHW'), ([0, 1, 2, 3], [0, 1, 2, 3])), (('NHWC', 'HWIO', 'NHWC'), ([0, 2, 3, 1], [2, 3, 1, 0])), (('NHWC', 'OIHW', 'NCHW'), ([0, 2, 3, 1], [0, 1, 2, 3])), (('HWCN', 'HWIO', 'HWCN'), ([2, 3, 1, 0], [2, 3, 1, 0]))]], strides=[(1, 1), (1, 2), (2, 1)], padding=[((0, 0), (0, 0)), ((1, 0), (0, 1)), ((0, -1), (0, 0))], lhs_dil=[(1, 1), (2, 1)], rhs_dil=[(1, 1), (2, 2)], bdim_size=list(range(5)), dtype=[np.float32])\ndef testConvGeneralDilatedBatching(self, lhs_shape, rhs_shape, dtype, strides, padding, lhs_dil, rhs_dil, dimension_numbers, perms, feature_group_count, batch_group_count, lhs_bdim, rhs_bdim, bdim_size):\n    rng = jtu.rand_default(self.rng())\n    tol = 0.1 if dtypes.finfo(dtype).bits <= 32 else 0.001\n    lhs_perm, rhs_perm = perms\n    lhs_shape = list(np.take(lhs_shape, lhs_perm))\n    rhs_shape = list(np.take(rhs_shape, rhs_perm))\n    conv = partial(lax.conv_general_dilated, window_strides=strides, padding=padding, lhs_dilation=lhs_dil, rhs_dilation=rhs_dil, dimension_numbers=dimension_numbers, feature_group_count=feature_group_count, batch_group_count=batch_group_count, precision=lax.Precision.HIGHEST)\n    self._CheckBatching(conv, bdim_size, (lhs_bdim, rhs_bdim), (lhs_shape, rhs_shape), (dtype, dtype), rng, rtol=tol, atol=tol)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(from_dtype=f, to_dtype=t) for f, t in itertools.product([np.float32, np.int32, 'float32', 'int32'], repeat=2)], [dict(shape=shape, bdims=bdims) for shape in [(2, 3)] for bdims in lax_test_util.all_bdims(shape)])\ndef testConvertElementType(self, shape, from_dtype, to_dtype, bdims):\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.convert_element_type(x, to_dtype)\n    self._CheckBatching(op, 10, bdims, (shape,), (from_dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, bdims=bdims) for shape in [(2, 4)] for bdims in lax_test_util.all_bdims(shape)], dtype=lax_test_util.float_dtypes, nexp=[1, 3, 5], nmant=[0, 2, 4])\ndef testReducePrecision(self, shape, dtype, nmant, nexp, bdims):\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.reduce_precision(x, exponent_bits=nexp, mantissa_bits=nmant)\n    self._CheckBatching(op, 10, bdims, (shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(from_dtype=f, to_dtype=t) for f, t in itertools.product([np.float32, np.int32, 'float32', 'int32'], repeat=2)], [dict(shape=shape, bdims=bdims) for shape in [(2, 3)] for bdims in lax_test_util.all_bdims(shape)])\ndef testBitcastElementType(self, shape, from_dtype, to_dtype, bdims):\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.bitcast_convert_type(x, to_dtype)\n    self._CheckBatching(op, 10, bdims, (shape,), (from_dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(min_shape=min_shape, operand_shape=operand_shape, max_shape=max_shape, bdims=bdims) for min_shape, operand_shape, max_shape in [[(), (2, 3), ()], [(2, 3), (2, 3), ()], [(), (2, 3), (2, 3)], [(2, 3), (2, 3), (2, 3)]] for bdims in lax_test_util.all_bdims(min_shape, operand_shape, max_shape)], dtype=lax_test_util.default_dtypes)\ndef testClamp(self, min_shape, operand_shape, max_shape, dtype, bdims):\n    rng = jtu.rand_default(self.rng())\n    shapes = [min_shape, operand_shape, max_shape]\n    self._CheckBatching(lax.clamp, 10, bdims, shapes, [dtype] * 3, rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(lhs_shape=lhs_shape, rhs_shape=rhs_shape, bdims=bdims) for lhs_shape in [(3,), (4, 3)] for rhs_shape in [(3,), (3, 6)] for bdims in lax_test_util.all_bdims(lhs_shape, rhs_shape)], dtype=lax_test_util.default_dtypes)\ndef testDot(self, lhs_shape, rhs_shape, dtype, bdims):\n    rng = jtu.rand_default(self.rng())\n    op = partial(lax.dot, precision=lax.Precision.HIGHEST)\n    self._CheckBatching(op, 5, bdims, (lhs_shape, rhs_shape), (dtype, dtype), rng, rtol={np.float16: 0.05, np.float64: 5e-14})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(bdims=bdims, lhs_shape=lhs_shape, rhs_shape=rhs_shape, lhs_contracting=lhs_contracting, rhs_contracting=rhs_contracting) for lhs_shape, rhs_shape, lhs_contracting, rhs_contracting in [[(5,), (5,), [0], [0]], [(5, 7), (5,), [0], [0]], [(7, 5), (5,), [1], [0]], [(3, 5), (2, 5), [1], [1]], [(5, 3), (5, 2), [0], [0]], [(5, 3, 2), (5, 2, 4), [0], [0]], [(5, 3, 2), (5, 2, 4), [0, 2], [0, 1]], [(5, 3, 2), (3, 5, 2, 4), [0, 2], [1, 2]], [(1, 2, 2, 3), (1, 2, 3, 1), [1], [1]], [(3, 2), (2, 4), [1], [0]]] for bdims in lax_test_util.all_bdims(lhs_shape, rhs_shape)], dtype=lax_test_util.default_dtypes)\ndef testDotGeneralContractOnly(self, lhs_shape, rhs_shape, dtype, lhs_contracting, rhs_contracting, bdims):\n    rng = jtu.rand_small(self.rng())\n    dimension_numbers = ((lhs_contracting, rhs_contracting), ([], []))\n    dot = partial(lax.dot_general, dimension_numbers=dimension_numbers)\n    self._CheckBatching(dot, 5, bdims, (lhs_shape, rhs_shape), (dtype, dtype), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(lhs_shape=lhs_shape, rhs_shape=rhs_shape, dimension_numbers=dimension_numbers, bdims=bdims) for lhs_shape, rhs_shape, dimension_numbers in [((3, 3, 2), (3, 2, 4), (([2], [1]), ([0], [0]))), ((3, 3, 2), (2, 3, 4), (([2], [0]), ([0], [1]))), ((3, 4, 2, 4), (3, 4, 3, 2), (([2], [3]), ([0, 1], [0, 1])))] for bdims in lax_test_util.all_bdims(lhs_shape, rhs_shape)], dtype=lax_test_util.default_dtypes)\ndef testDotGeneralContractAndBatch(self, lhs_shape, rhs_shape, dtype, dimension_numbers, bdims):\n    rng = jtu.rand_small(self.rng())\n    dot = partial(lax.dot_general, dimension_numbers=dimension_numbers)\n    self._CheckBatching(dot, 5, bdims, (lhs_shape, rhs_shape), (dtype, dtype), rng)\n    jaxpr = jax.make_jaxpr(dot)(np.zeros(lhs_shape, dtype), np.zeros(rhs_shape, dtype))\n    for eqn in jtu.iter_eqns(jaxpr.jaxpr):\n        self.assertFalse(eqn.primitive in ['transpose', 'broadcast'])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, bdims=bdims) for shape in [(), (2, 3)] for bdims in lax_test_util.all_bdims(shape)], dtype=lax_test_util.default_dtypes, broadcast_sizes=[(), (2,), (1, 2)])\ndef testBroadcast(self, shape, dtype, broadcast_sizes, bdims):\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.broadcast(x, broadcast_sizes)\n    self._CheckBatching(op, 5, bdims, (shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(inshape=inshape, outshape=outshape, broadcast_dimensions=broadcast_dimensions, bdims=bdims) for inshape, outshape, broadcast_dimensions in [([2], [2, 2], [0]), ([2], [2, 2], [1]), ([2], [2, 3], [0]), ([], [2, 3], [])] for bdims in lax_test_util.all_bdims(inshape)], dtype=lax_test_util.default_dtypes)\n@unittest.skip('this test has failures in some cases')\ndef testBroadcastInDim(self, inshape, dtype, outshape, dimensions, bdims):\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.broadcast_in_dim(x, outshape, dimensions)\n    self._CheckBatching(op, 5, bdims, (inshape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, dimensions=dimensions, bdims=bdims) for arg_shape, dimensions in [[(1,), (0,)], [(1,), (-1,)], [(2, 1, 4), (1,)], [(2, 1, 4), (-2,)], [(2, 1, 3, 1), (1,)], [(2, 1, 3, 1), (1, 3)], [(2, 1, 3, 1), (3,)], [(2, 1, 3, 1), (1, -1)]] for bdims in lax_test_util.all_bdims(arg_shape)])\ndef testSqueeze(self, arg_shape, dimensions, bdims):\n    dtype = np.float32\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.squeeze(x, dimensions)\n    self._CheckBatching(op, 10, bdims, (arg_shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, out_shape=out_shape, dimensions=dimensions, bdims=bdims) for arg_shape, dimensions, out_shape in [[(3, 4), None, (12,)], [(2, 1, 4), None, (8,)], [(2, 2, 4), None, (2, 8)], [(2, 2, 4), (0, 1, 2), (2, 8)], [(2, 2, 4), (1, 0, 2), (8, 2)], [(2, 2, 4), (2, 1, 0), (4, 2, 2)]] for bdims in lax_test_util.all_bdims(arg_shape)], dtype=lax_test_util.default_dtypes)\ndef testReshape(self, arg_shape, out_shape, dtype, dimensions, bdims):\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.reshape(x, out_shape, dimensions=dimensions)\n    self._CheckBatching(op, 10, bdims, (arg_shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, bdims=bdims) for shape in [(2, 3)] for bdims in lax_test_util.all_bdims(shape, ())], dtype=lax_test_util.default_dtypes, pads=[[(1, 2, 1), (0, 1, 0)]])\ndef testPad(self, shape, dtype, pads, bdims):\n    rng = jtu.rand_small(self.rng())\n    fun = lambda operand, padding: lax.pad(operand, padding, pads)\n    self._CheckBatching(fun, 5, bdims, (shape, ()), (dtype, dtype), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, pred_shape=pred_shape, bdims=bdims) for arg_shape in [(), (3,), (2, 3)] for pred_shape in ([(), arg_shape] if arg_shape else [()]) for bdims in lax_test_util.all_bdims(pred_shape, arg_shape, arg_shape)], arg_dtype=lax_test_util.default_dtypes)\ndef testSelect(self, pred_shape, arg_shape, arg_dtype, bdims):\n    rng = jtu.rand_default(self.rng())\n    op = lambda c, x, y: lax.select(c < 0, x, y)\n    self._CheckBatching(op, 5, bdims, (pred_shape, arg_shape, arg_shape), (arg_dtype, arg_dtype, arg_dtype), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, starts=start_indices, limits=limit_indices, strides=strides, bdims=bdims) for shape, start_indices, limit_indices, strides in [[(3,), (1,), (2,), None], [(7,), (4,), (7,), None], [(5,), (1,), (5,), (2,)], [(8,), (1,), (6,), (2,)], [(5, 3), (1, 1), (3, 2), None], [(5, 3), (1, 1), (3, 1), None], [(7, 5, 3), (4, 0, 1), (7, 1, 3), None], [(5, 3), (1, 1), (2, 1), (1, 1)], [(5, 3), (1, 1), (5, 3), (2, 1)]] for bdims in lax_test_util.all_bdims(shape)], dtype=lax_test_util.default_dtypes)\ndef testSlice(self, shape, dtype, starts, limits, strides, bdims):\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.slice(x, starts, limits, strides)\n    self._CheckBatching(op, 5, bdims, (shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(base_shape=base_shape, axis=axis, bdims=bdims) for base_shape in [(4,), (3, 4), (2, 3, 4)] for axis in range(len(base_shape)) for bdims in lax_test_util.all_bdims(base_shape)], num_pieces=range(3), dtype=lax_test_util.default_dtypes)\ndef testSplit(self, base_shape, dtype, num_pieces, axis, bdims):\n    sizes = jtu.rand_int(self.rng(), 5)((num_pieces + 1,), np.int64)\n    shape = list(base_shape)\n    shape[axis] = np.sum(sizes)\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.split(x, sizes, axis)\n    self._CheckBatching(op, 5, bdims, (shape,), (dtype,), rng, multiple_results=True)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, perm=perm, bdims=bdims) for shape, perm in [[(3, 4), (1, 0)], [(3, 4), (0, 1)], [(3, 4, 5), (2, 1, 0)], [(3, 4, 5), (1, 0, 2)]] for bdims in lax_test_util.all_bdims(shape)], dtype=lax_test_util.default_dtypes)\ndef testTranspose(self, shape, dtype, perm, bdims):\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.transpose(x, perm)\n    self._CheckBatching(op, 5, bdims, (shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(0, lax.add, lax_test_util.default_dtypes), (1, lax.mul, lax_test_util.default_dtypes), (0, lax.max, lax_test_util.all_dtypes), (-np.inf, lax.max, lax_test_util.float_dtypes), (dtypes.iinfo(np.int32).min, lax.max, [np.int32]), (dtypes.iinfo(np.int64).min, lax.max, [np.int64]), (np.inf, lax.min, lax_test_util.float_dtypes), (dtypes.iinfo(np.int32).max, lax.min, [np.int32]), (dtypes.iinfo(np.int64).max, lax.min, [np.int64]), (dtypes.iinfo(np.uint32).max, lax.min, [np.uint32]), (dtypes.iinfo(np.uint64).max, lax.min, [np.uint64])] for dtype in dtypes], [dict(shape=shape, dims=dims, bdims=bdims) for shape, dims in [[(3, 4, 5), (0,)], [(3, 4, 5), (1, 2)], [(3, 4, 5), (0, 2)], [(3, 4, 5), (0, 1, 2)]] for bdims in lax_test_util.all_bdims(shape)])\ndef testReduce(self, op, init_val, shape, dtype, dims, bdims):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n    fun = lambda operand: lax.reduce(operand, init_val, op, dims)\n    self._CheckBatching(fun, 5, bdims, (shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, dims=dims, bdims=bdims) for shape, dims in [[(3, 4, 5), (0,)], [(3, 4, 5), (1, 2)], [(3, 4, 5), (0, 2)], [(3, 4, 5), (0, 1, 2)]] for bdims in lax_test_util.all_bdims(shape, shape)], dtype=lax_test_util.default_dtypes)\ndef testVariadicReduce(self, shape, dtype, dims, bdims):\n\n    def op(a, b):\n        x1, y1 = a\n        x2, y2 = b\n        return (x1 + x2, y1 * y2)\n    rng = jtu.rand_small(self.rng())\n    init_val = tuple(np.asarray([0, 1], dtype=dtype))\n    fun = lambda x, y: lax.reduce((x, y), init_val, op, dims)\n    self._CheckBatching(fun, 5, bdims, (shape, shape), (dtype, dtype), rng, multiple_results=True)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, bdims=bdims, dim=dim) for shape in [(3, 4, 5)] for bdims in lax_test_util.all_bdims(shape) for dim in range(len(shape))], op=[lax.argmin, lax.argmax], dtype=lax_test_util.default_dtypes)\ndef testArgminmax(self, op, shape, dtype, dim, bdims):\n    rng = jtu.rand_default(self.rng())\n    fun = lambda operand: op(operand, dim, np.int32)\n    self._CheckBatching(fun, 5, bdims, (shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(init_val=init_val, op=op, dtype=dtype) for init_val, op, dtypes in [(0, lax.add, [np.float32]), (-np.inf, lax.max, [np.float32]), (np.inf, lax.min, [np.float32])] for dtype in dtypes], [dict(shape=shape, dims=dims, strides=strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation) for shape, dims, strides, padding, base_dilation, window_dilation in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)], ['VALID', 'SAME', [(0, 3), (1, 2)]], [(1, 1), (2, 3)], [(1, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)], ['VALID', 'SAME', [(0, 1), (1, 0), (2, 3), (0, 2)]], [(1, 1, 1, 1), (2, 1, 3, 2)], [(1, 1, 1, 1), (1, 2, 2, 1)]))])\ndef testReduceWindow(self, op, init_val, dtype, shape, dims, strides, padding, base_dilation, window_dilation):\n    rng = jtu.rand_small(self.rng())\n    init_val = np.asarray(init_val, dtype=dtype)\n\n    def fun(operand):\n        return lax.reduce_window(operand, init_val, op, dims, strides, padding, base_dilation, window_dilation)\n    for bdims in lax_test_util.all_bdims(shape):\n        self._CheckBatching(fun, 3, bdims, (shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(op=op, dtype=dtype) for op, types in [(lax.cumsum, [np.float32, np.float64]), (lax.cumprod, [np.float32, np.float64])] for dtype in types], [dict(shape=shape, bdims=bdims, axis=axis) for shape in [[10], [3, 4, 5]] for axis in range(len(shape)) for bdims in lax_test_util.all_bdims(shape)], reverse=[False, True])\ndef testCumulativeReduce(self, op, shape, dtype, axis, bdims, reverse):\n    rng_factory = jtu.rand_default if dtypes.issubdtype(dtype, np.integer) else jtu.rand_small\n    rng = rng_factory(self.rng())\n    self._CheckBatching(partial(op, axis=axis, reverse=reverse), 7, bdims, (shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, dims=dims, strides=strides, bdims=bdims) for shape, dims, strides in itertools.chain(itertools.product([(4, 6)], [(2, 1), (1, 2)], [(1, 1), (2, 1), (1, 2)]), itertools.product([(3, 2, 4, 6)], [(1, 1, 2, 1), (2, 1, 2, 1)], [(1, 2, 2, 1), (1, 1, 1, 1)])) for bdims in lax_test_util.all_bdims(shape, shape)], dtype=lax_test_util.float_dtypes, padding=['VALID', 'SAME'])\n@jtu.ignore_warning(message='Using reduced precision for gradient.*')\ndef testSelectAndGatherAdd(self, dtype, padding, shape, dims, strides, bdims):\n    rng = jtu.rand_small(self.rng())\n\n    def fun(operand, tangents):\n        pads = lax.padtype_to_pads(operand.shape, dims, strides, padding)\n        ones = (1,) * len(operand.shape)\n        return lax_windowed_reductions._select_and_gather_add(operand, tangents, lax.ge_p, dims, strides, pads, ones, ones)\n    self._CheckBatching(fun, 3, bdims, (shape, shape), (dtype, dtype), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product(dtype=lax_test_util.float_dtypes, padding=['VALID', 'SAME'], shape=[(3, 2, 4, 6)], dims=[(1, 1, 2, 1)], strides=[(1, 2, 2, 1), (1, 1, 1, 1)])\ndef testSelectAndScatterAdd(self, dtype, padding, shape, dims, strides):\n    rng = jtu.rand_small(self.rng())\n    pads = lax.padtype_to_pads(shape, dims, strides, padding)\n\n    def fun(operand, cotangents):\n        return lax_windowed_reductions._select_and_scatter_add(operand, cotangents, lax.ge_p, dims, strides, pads)\n    ones = (1,) * len(shape)\n    cotangent_shape = jax.eval_shape(lambda x: lax_windowed_reductions._select_and_gather_add(x, x, lax.ge_p, dims, strides, pads, ones, ones), np.ones(shape, dtype)).shape\n    for bdims in lax_test_util.all_bdims(cotangent_shape, shape):\n        self._CheckBatching(fun, 3, bdims, (cotangent_shape, shape), (dtype, dtype), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, fft_ndims=fft_ndims, bdims=bdims) for shape in [(5,), (3, 4, 5), (2, 3, 4, 5)] for bdims in lax_test_util.all_bdims(shape) for fft_ndims in range(0, min(3, len(shape)) + 1)])\ndef testFft(self, fft_ndims, shape, bdims):\n    rng = jtu.rand_default(self.rng())\n    ndims = len(shape)\n    axes = range(ndims - fft_ndims, ndims)\n    fft_lengths = tuple((shape[axis] for axis in axes))\n    op = lambda x: lax.fft(x, lax.FftType.FFT, fft_lengths)\n    self._CheckBatching(op, 5, bdims, [shape], [np.complex64], rng, rtol=1e-05)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, idxs=idxs, dnums=dnums, slice_sizes=slice_sizes, bdims=bdims) for shape, idxs, dnums, slice_sizes in [((5,), np.array([[0], [2]]), lax.GatherDimensionNumbers(offset_dims=(), collapsed_slice_dims=(0,), start_index_map=(0,)), (1,)), ((10,), np.array([[0], [0], [0]]), lax.GatherDimensionNumbers(offset_dims=(1,), collapsed_slice_dims=(), start_index_map=(0,)), (2,)), ((10, 5), np.array([[0], [2], [1]]), lax.GatherDimensionNumbers(offset_dims=(1,), collapsed_slice_dims=(0,), start_index_map=(0,)), (1, 3)), ((10, 5), np.array([[0, 2], [1, 0]]), lax.GatherDimensionNumbers(offset_dims=(1,), collapsed_slice_dims=(0,), start_index_map=(0, 1)), (1, 3)), ((2, 5), np.array([[[0], [2]], [[1], [1]]]), lax.GatherDimensionNumbers(offset_dims=(), collapsed_slice_dims=(1,), start_index_map=(1,), operand_batching_dims=(0,), start_indices_batching_dims=(0,)), (1, 1)), ((2, 3, 10), np.array([[[0], [1]], [[2], [3]], [[4], [5]]]), lax.GatherDimensionNumbers(offset_dims=(2,), collapsed_slice_dims=(), start_index_map=(2,), operand_batching_dims=(0, 1), start_indices_batching_dims=(1, 0)), (1, 1, 3))] for bdims in lax_test_util.all_bdims(shape, idxs.shape)], dtype=lax_test_util.all_dtypes)\ndef testGather(self, shape, dtype, idxs, dnums, slice_sizes, bdims):\n    fun = partial(lax.gather, dimension_numbers=dnums, slice_sizes=slice_sizes)\n    self._CheckBatching(fun, 0, bdims, [shape, idxs.shape], [dtype, idxs.dtype], jtu.rand_default(self.rng()))\n    self._CheckBatching(fun, 5, bdims, [shape, idxs.shape], [dtype, idxs.dtype], jtu.rand_default(self.rng()))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, idxs=idxs, update_shape=update_shape, dnums=dnums, bdims=bdims) for arg_shape, idxs, update_shape, dnums in [((5,), np.array([[0], [2]]), (2,), lax.ScatterDimensionNumbers(update_window_dims=(), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))), ((10,), np.array([[0], [0], [0]]), (3, 2), lax.ScatterDimensionNumbers(update_window_dims=(1,), inserted_window_dims=(), scatter_dims_to_operand_dims=(0,))), ((10, 5), np.array([[0], [2], [1]]), (3, 3), lax.ScatterDimensionNumbers(update_window_dims=(1,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))), ((2, 5), np.array([[[0], [2]], [[1], [1]]]), (2, 2), lax.ScatterDimensionNumbers(update_window_dims=(), inserted_window_dims=(1,), scatter_dims_to_operand_dims=(1,), operand_batching_dims=(0,), scatter_indices_batching_dims=(0,))), ((2, 3, 10), np.array([[[0], [1]], [[2], [3]], [[4], [5]]]), (3, 2, 3), lax.ScatterDimensionNumbers(update_window_dims=(2,), inserted_window_dims=(), scatter_dims_to_operand_dims=(2,), operand_batching_dims=(0, 1), scatter_indices_batching_dims=(1, 0)))] for bdims in lax_test_util.all_bdims(arg_shape, idxs.shape, update_shape)], dtype=lax_test_util.float_dtypes)\ndef testScatterAdd(self, arg_shape, dtype, idxs, update_shape, dnums, bdims):\n    fun = partial(lax.scatter_add, dimension_numbers=dnums)\n    self._CheckBatching(fun, 5, bdims, [arg_shape, idxs.shape, update_shape], [dtype, idxs.dtype, dtype], jtu.rand_default(self.rng()), rtol={np.float16: 0.005, dtypes.bfloat16: 0.07})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(arg_shape=arg_shape, idxs=idxs, update_shape=update_shape, dnums=dnums, bdims=bdims) for arg_shape, idxs, update_shape, dnums in [((5,), np.array([[0], [2]]), (2,), lax.ScatterDimensionNumbers(update_window_dims=(), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))), ((10,), np.array([[0], [0], [0]]), (3, 2), lax.ScatterDimensionNumbers(update_window_dims=(1,), inserted_window_dims=(), scatter_dims_to_operand_dims=(0,))), ((10, 5), np.array([[0], [2], [1]]), (3, 3), lax.ScatterDimensionNumbers(update_window_dims=(1,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))), ((2, 5), np.array([[[0], [2]], [[1], [1]]]), (2, 2), lax.ScatterDimensionNumbers(update_window_dims=(), inserted_window_dims=(1,), scatter_dims_to_operand_dims=(1,), operand_batching_dims=(0,), scatter_indices_batching_dims=(0,))), ((2, 3, 10), np.array([[[0], [1]], [[2], [3]], [[4], [5]]]), (3, 2, 3), lax.ScatterDimensionNumbers(update_window_dims=(2,), inserted_window_dims=(), scatter_dims_to_operand_dims=(2,), operand_batching_dims=(0, 1), scatter_indices_batching_dims=(1, 0)))] for bdims in lax_test_util.all_bdims(arg_shape, idxs.shape)], dtype=lax_test_util.float_dtypes)\ndef testScatterApply(self, arg_shape, dtype, idxs, update_shape, dnums, bdims):\n    fun = partial(lax.scatter_apply, func=jnp.sin, update_shape=update_shape, dimension_numbers=dnums)\n    self._CheckBatching(fun, 5, bdims, [arg_shape, idxs.shape], [dtype, idxs.dtype], jtu.rand_default(self.rng()), rtol={np.float16: 0.005, dtypes.bfloat16: 0.07})",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, bdims=bdims) for shape in [(4,), (3, 5, 3)] for bdims in lax_test_util.all_bdims(shape)], k=[1, 3], dtype=lax_test_util.default_dtypes)\ndef testTopK(self, shape, dtype, k, bdims):\n    rng = jtu.rand_int(self.rng(), high=math.prod(shape))\n    op1 = lambda x: lax.top_k(x, k=k)[0]\n    self._CheckBatching(op1, 5, bdims, (shape,), (dtype,), rng)\n    op2 = lambda x: lax.top_k(x, k=k)[1]\n    self._CheckBatching(op2, 5, bdims, (shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, bdims=bdims) for shape in [(8,), (3, 4, 5)] for bdims in lax_test_util.all_bdims(shape)], dtype=lax_test_util.default_dtypes)\ndef test_optimization_barrier_vmap(self, shape, dtype, bdims):\n    rng = jtu.rand_small(self.rng())\n    self._CheckBatching(lax.optimization_barrier, 5, bdims, (shape,), (dtype,), rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.sample_product([dict(shape=shape, bdims=bdims, dimension=dimension, arity=arity) for shape in [(2, 3)] for dimension in [0, 1] for arity in range(3) for bdims in lax_test_util.all_bdims(*(shape,) * arity)], is_stable=[False, True])\ndef testSort(self, shape, dimension, arity, bdims, is_stable):\n    rng = jtu.rand_default(self.rng())\n    if arity == 1:\n        fun = partial(lax.sort, dimension=dimension)\n        self._CheckBatching(fun, 5, bdims, (shape,) * arity, (np.float32,) * arity, rng)\n    else:\n        for i in range(arity):\n            fun = lambda *args, i=i: lax.sort(args, dimension=dimension, is_stable=is_stable)[i]\n            self._CheckBatching(fun, 5, bdims, (shape,) * arity, (np.float32,) * arity, rng)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def _CheckBatching(self, op, bdim_size, bdims, shapes, dtypes, rng, rtol=None, atol=None, multiple_results=False):\n    batched_shapes = map(functools.partial(lax_test_util.add_bdim, bdim_size), bdims, shapes)\n    args = [rng(shape, dtype) for shape, dtype in zip(batched_shapes, dtypes)]\n    args_slice = lax_test_util.args_slicer(args, bdims)\n    ans = jax.vmap(op, bdims)(*args)\n    if bdim_size == 0:\n        args = [rng(shape, dtype) for shape, dtype in zip(shapes, dtypes)]\n        out = op(*args)\n        if not multiple_results:\n            expected = np.zeros((0,) + out.shape, out.dtype)\n        else:\n            expected = [np.zeros((0,) + o.shape, o.dtype) for o in out]\n    else:\n        outs = [op(*args_slice(i)) for i in range(bdim_size)]\n        if not multiple_results:\n            expected = np.stack(outs)\n        else:\n            expected = [np.stack(xs) for xs in zip(*outs)]\n    self.assertAllClose(ans, expected, rtol=rtol, atol=atol)"
  },
  {
    "test_code": "@jtu.skip_on_devices('gpu')\ndef test_variadic_reduce_window(self):\n\n    def normpool(x):\n        norms = jnp.linalg.norm(x, axis=-1)\n        idxs = jnp.arange(x.shape[0])\n\n        def g(a, b):\n            an, ai = a\n            bn, bi = b\n            which = an >= bn\n            return (jnp.where(which, an, bn), jnp.where(which, ai, bi))\n        inf = jnp.array(np.inf, dtype=norms.dtype)\n        one = jnp.array(1, dtype=idxs.dtype)\n        _, idxs = lax.reduce_window((norms, idxs), (-inf, -one), g, window_dimensions=(2,), window_strides=(2,), padding=((0, 0),))\n        return x[idxs]\n    inpt = jnp.array([[1.0, 0.0, 1.0], [2.0, 2.0, 0.0], [3.0, 0.0, 1.0], [0.0, 1.0, 1.0]])\n    output = jax.vmap(normpool)(inpt[None, ...])\n    expected = jnp.array([[[2.0, 2.0, 0.0], [3.0, 0.0, 1.0]]])\n    self.assertAllClose(output, expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def norm(x):\n    norm = np.linalg.norm(x, axis=(-2, -1))\n    return norm / ((n + 1) * jnp.finfo(dtype).eps)"
  },
  {
    "test_code": "@jtu.sample_product([dict(base_shape=base_shape, axis=axis, bdims=bdims) for base_shape in [(4,), (3, 4), (2, 3, 4)] for axis in range(len(base_shape)) for bdims in lax_test_util.all_bdims(base_shape)], num_pieces=range(3), dtype=lax_test_util.default_dtypes)\ndef testSplit(self, base_shape, dtype, num_pieces, axis, bdims):\n    sizes = jtu.rand_int(self.rng(), 5)((num_pieces + 1,), np.int64)\n    shape = list(base_shape)\n    shape[axis] = np.sum(sizes)\n    rng = jtu.rand_default(self.rng())\n    op = lambda x: lax.split(x, sizes, axis)\n    self._CheckBatching(op, 5, bdims, (shape,), (dtype,), rng, multiple_results=True)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def split(self) -> jax.Array:\n    key = jax_getattr(self, 'key')\n    new_key, returned_key = jax.random.split(key)\n    jax_setattr(self, 'key', new_key)\n    return returned_key"
  },
  {
    "test_code": "@jtu.skip_on_devices('gpu')\ndef test_variadic_reduce_window(self):\n\n    def normpool(x):\n        norms = jnp.linalg.norm(x, axis=-1)\n        idxs = jnp.arange(x.shape[0])\n\n        def g(a, b):\n            an, ai = a\n            bn, bi = b\n            which = an >= bn\n            return (jnp.where(which, an, bn), jnp.where(which, ai, bi))\n        inf = jnp.array(np.inf, dtype=norms.dtype)\n        one = jnp.array(1, dtype=idxs.dtype)\n        _, idxs = lax.reduce_window((norms, idxs), (-inf, -one), g, window_dimensions=(2,), window_strides=(2,), padding=((0, 0),))\n        return x[idxs]\n    inpt = jnp.array([[1.0, 0.0, 1.0], [2.0, 2.0, 0.0], [3.0, 0.0, 1.0], [0.0, 1.0, 1.0]])\n    output = jax.vmap(normpool)(inpt[None, ...])\n    expected = jnp.array([[[2.0, 2.0, 0.0], [3.0, 0.0, 1.0]]])\n    self.assertAllClose(output, expected, check_dtypes=False)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/lax_vmap_test.py",
    "function": "def norm(x):\n    n = np.linalg.norm(x, axis=(-2, -1))\n    return n / (max(1, max_rank) * jnp.finfo(dtype).eps)"
  }
]