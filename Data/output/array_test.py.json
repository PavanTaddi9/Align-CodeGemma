[
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_sharded_zeros_like(self):\n    global_mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    input_shape = (8, 2)\n    a, input_data = create_array(input_shape, jax.sharding.NamedSharding(global_mesh, P('x', 'y')))\n    out = jnp.zeros_like(a)\n    expected = jnp.zeros(input_data.shape, dtype=a.dtype)\n    self.assertArraysEqual(out, expected)\n    self.assertLen(out.addressable_shards, 8)\n    for i in out.addressable_shards:\n        self.assertArraysEqual(i.data, expected[i.index])",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_zeros_like(self):\n    a = jnp.array([1, 2, 3], dtype=np.int32)\n    out = jnp.zeros_like(a)\n    expected = np.zeros(a.shape, dtype=np.int32)\n    self.assertArraysEqual(out, expected)\n    self.assertTrue(dispatch.is_single_device_sharding(out.sharding))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_default_pmap_sharding_replicated(self):\n    x = np.zeros((len(jax.local_devices()), 8), dtype=np.float32)\n    x = jax.pmap(lambda x: x, in_axes=0, out_axes=None)(x)\n    ps = jax.sharding.PmapSharding.default(shape=(8,), sharded_dim=None, devices=jax.local_devices())\n    self.assertEqual(x.sharding, ps)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def zeros(shape):\n    if not isinstance(shape, (tuple, list)):\n        shape = (shape,)\n    return lax.broadcast(jnp.float32(0.0), shape)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_array_getitem_compile_multi_device_sharding(self):\n\n    def _check(out, inp, shard_shape):\n        self.assertArraysEqual(out, inp)\n        self.assertEqual(out.sharding.shard_shape(out.shape), shard_shape)\n        self.assertNotIsInstance(out.sharding, jax.sharding.SingleDeviceSharding)\n    global_mesh = jtu.create_mesh((2, 2, 2), ('x', 'y', 'z'))\n    input_shape = (4, 4, 2)\n    arr, np_inp = create_array(input_shape, jax.sharding.NamedSharding(global_mesh, P('x', 'y', 'z')))\n    _check(arr[:, -1, :], np_inp[:, -1, :], (2, 1))\n    _check(arr[0, 0, 0], np_inp[0, 0, 0], ())\n    _check(arr[-1, -1, :], np_inp[-1, -1, :], (1,))\n    _check(arr[:, 1, 0], np_inp[:, 1, 0], (2,))\n    _check(arr[:, :, :], np_inp[:, :, :], (2, 2, 1))\n    _check(arr[3, :, :], np_inp[3, :, :], (2, 1))\n    _check(arr[-1, -1, -1], np_inp[-1, -1, -1], ())\n    _check(arr[2, -1, :], np_inp[2, -1, :], (1,))\n    _check(arr[2, 3, 1], np_inp[2, 3, 1], ())\n    _check(arr[-1], np_inp[-1], (2, 1))\n    _check(arr[:], np_inp[:], (2, 2, 1))\n    _check(arr[np.array(0), :, :], np_inp[np.array(0), :, :], (2, 1))\n    _check(arr[jnp.array(0), :, :], np_inp[jnp.array(0), :, :], (2, 1))\n    _check(arr[0, :2, 1], np_inp[0, :2, 1], (2,))\n    _check(arr[:, 1::2], np_inp[:, 1::2], (2, 2, 1))\n    _check(arr[:, -1:, :], np_inp[:, -1:, :], (2, 1, 1))\n    _check(arr[0:6:1], np_inp[0:6:1], (2, 2, 1))\n    _check(arr[:4], np_inp[:4], (2, 2, 1))\n    _check(arr[::-1], np_inp[::-1], (2, 2, 1))\n    _check(arr[1], np_inp[1], (2, 1))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def _check(self, s, *ops):\n    a = np.einsum(s, *ops)\n    b = jnp.einsum(s, *ops, precision=lax.Precision.HIGHEST)\n    self.assertAllClose(a, b, atol=0.0001, rtol=0.0001)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_array_getitem_compile_multi_device_sharding(self):\n\n    def _check(out, inp, shard_shape):\n        self.assertArraysEqual(out, inp)\n        self.assertEqual(out.sharding.shard_shape(out.shape), shard_shape)\n        self.assertNotIsInstance(out.sharding, jax.sharding.SingleDeviceSharding)\n    global_mesh = jtu.create_mesh((2, 2, 2), ('x', 'y', 'z'))\n    input_shape = (4, 4, 2)\n    arr, np_inp = create_array(input_shape, jax.sharding.NamedSharding(global_mesh, P('x', 'y', 'z')))\n    _check(arr[:, -1, :], np_inp[:, -1, :], (2, 1))\n    _check(arr[0, 0, 0], np_inp[0, 0, 0], ())\n    _check(arr[-1, -1, :], np_inp[-1, -1, :], (1,))\n    _check(arr[:, 1, 0], np_inp[:, 1, 0], (2,))\n    _check(arr[:, :, :], np_inp[:, :, :], (2, 2, 1))\n    _check(arr[3, :, :], np_inp[3, :, :], (2, 1))\n    _check(arr[-1, -1, -1], np_inp[-1, -1, -1], ())\n    _check(arr[2, -1, :], np_inp[2, -1, :], (1,))\n    _check(arr[2, 3, 1], np_inp[2, 3, 1], ())\n    _check(arr[-1], np_inp[-1], (2, 1))\n    _check(arr[:], np_inp[:], (2, 2, 1))\n    _check(arr[np.array(0), :, :], np_inp[np.array(0), :, :], (2, 1))\n    _check(arr[jnp.array(0), :, :], np_inp[jnp.array(0), :, :], (2, 1))\n    _check(arr[0, :2, 1], np_inp[0, :2, 1], (2,))\n    _check(arr[:, 1::2], np_inp[:, 1::2], (2, 2, 1))\n    _check(arr[:, -1:, :], np_inp[:, -1:, :], (2, 1, 1))\n    _check(arr[0:6:1], np_inp[0:6:1], (2, 2, 1))\n    _check(arr[:4], np_inp[:4], (2, 2, 1))\n    _check(arr[::-1], np_inp[::-1], (2, 2, 1))\n    _check(arr[1], np_inp[1], (2, 1))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def _check(obj, out_dtype, weak_type):\n    dtype_reference = np.array(obj, dtype=out_dtype)\n    out = jnp.array(obj)\n    self.assertDtypesMatch(out, dtype_reference)\n    self.assertEqual(dtypes.is_weakly_typed(out), weak_type)\n    out_jit = jax.jit(jnp.array)(obj)\n    self.assertDtypesMatch(out_jit, dtype_reference)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), weak_type)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_jnp_array_jnp_add(self):\n    arr = jnp.add(jnp.array([1, 2, 3]), jnp.array([4, 5, 6]))\n    self.assertIsInstance(arr, array.ArrayImpl)\n    self.assertArraysEqual(arr, np.array([5, 7, 9]))\n    self.assertIsInstance(arr.sharding, jax.sharding.SingleDeviceSharding)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@staticmethod\ndef add(dt, x, y):\n    fromscale = partial(jax.lax.convert_element_type, new_dtype=dt.float_dtype)\n    toscale = partial(jax.lax.convert_element_type, new_dtype=dt)\n    return toscale(jax.lax.max(fromscale(x), fromscale(y)))"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_array_getitem_compile_multi_device_sharding(self):\n\n    def _check(out, inp, shard_shape):\n        self.assertArraysEqual(out, inp)\n        self.assertEqual(out.sharding.shard_shape(out.shape), shard_shape)\n        self.assertNotIsInstance(out.sharding, jax.sharding.SingleDeviceSharding)\n    global_mesh = jtu.create_mesh((2, 2, 2), ('x', 'y', 'z'))\n    input_shape = (4, 4, 2)\n    arr, np_inp = create_array(input_shape, jax.sharding.NamedSharding(global_mesh, P('x', 'y', 'z')))\n    _check(arr[:, -1, :], np_inp[:, -1, :], (2, 1))\n    _check(arr[0, 0, 0], np_inp[0, 0, 0], ())\n    _check(arr[-1, -1, :], np_inp[-1, -1, :], (1,))\n    _check(arr[:, 1, 0], np_inp[:, 1, 0], (2,))\n    _check(arr[:, :, :], np_inp[:, :, :], (2, 2, 1))\n    _check(arr[3, :, :], np_inp[3, :, :], (2, 1))\n    _check(arr[-1, -1, -1], np_inp[-1, -1, -1], ())\n    _check(arr[2, -1, :], np_inp[2, -1, :], (1,))\n    _check(arr[2, 3, 1], np_inp[2, 3, 1], ())\n    _check(arr[-1], np_inp[-1], (2, 1))\n    _check(arr[:], np_inp[:], (2, 2, 1))\n    _check(arr[np.array(0), :, :], np_inp[np.array(0), :, :], (2, 1))\n    _check(arr[jnp.array(0), :, :], np_inp[jnp.array(0), :, :], (2, 1))\n    _check(arr[0, :2, 1], np_inp[0, :2, 1], (2,))\n    _check(arr[:, 1::2], np_inp[:, 1::2], (2, 2, 1))\n    _check(arr[:, -1:, :], np_inp[:, -1:, :], (2, 1, 1))\n    _check(arr[0:6:1], np_inp[0:6:1], (2, 2, 1))\n    _check(arr[:4], np_inp[:4], (2, 2, 1))\n    _check(arr[::-1], np_inp[::-1], (2, 2, 1))\n    _check(arr[1], np_inp[1], (2, 1))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def _check(obj, out_dtype, weak_type):\n    dtype_reference = np.array(obj, dtype=out_dtype)\n    out = jnp.array(obj)\n    self.assertDtypesMatch(out, dtype_reference)\n    self.assertEqual(dtypes.is_weakly_typed(out), weak_type)\n    out_jit = jax.jit(jnp.array)(obj)\n    self.assertDtypesMatch(out_jit, dtype_reference)\n    self.assertEqual(dtypes.is_weakly_typed(out_jit), weak_type)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_array_iter_pmap_sharding(self):\n    if jax.device_count() < 2:\n        self.skipTest('Test requires >= 2 devices.')\n    x = jnp.array([[1.0, 0.0, 0.0], [0.0, 2.0, 3.0]])\n    y = jax.pmap(jnp.sin)(x)\n    self.assertArraysEqual([list(a.devices())[0] for a in y], y.sharding._device_assignment, allow_object_dtype=True)\n    sin_x = iter(np.sin(x))\n    for i, j in zip(iter(y), sin_x):\n        self.assertIsInstance(i, array.ArrayImpl)\n        self.assertArraysAllClose(i, j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.custom_jvp\ndef sin(x):\n    return jax.pure_callback(np.sin, x, x)"
  },
  {
    "test_code": "def test_array_iter_pmap_sharding_last_dim_sharded(self):\n    if jax.device_count() < 2:\n        self.skipTest('Test requires >= 2 devices.')\n    x = jnp.array([[1.0, 0.0, 0.0], [0.0, 2.0, 3.0]])\n    y = jax.pmap(jnp.sin, out_axes=1)(x)\n    for i, j in zip(iter(y), iter(np.sin(x).T)):\n        self.assertArraysAllClose(i, j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.custom_jvp\ndef sin(x):\n    return jax.pure_callback(np.sin, x, x)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_array_getitem_compile_multi_device_sharding(self):\n\n    def _check(out, inp, shard_shape):\n        self.assertArraysEqual(out, inp)\n        self.assertEqual(out.sharding.shard_shape(out.shape), shard_shape)\n        self.assertNotIsInstance(out.sharding, jax.sharding.SingleDeviceSharding)\n    global_mesh = jtu.create_mesh((2, 2, 2), ('x', 'y', 'z'))\n    input_shape = (4, 4, 2)\n    arr, np_inp = create_array(input_shape, jax.sharding.NamedSharding(global_mesh, P('x', 'y', 'z')))\n    _check(arr[:, -1, :], np_inp[:, -1, :], (2, 1))\n    _check(arr[0, 0, 0], np_inp[0, 0, 0], ())\n    _check(arr[-1, -1, :], np_inp[-1, -1, :], (1,))\n    _check(arr[:, 1, 0], np_inp[:, 1, 0], (2,))\n    _check(arr[:, :, :], np_inp[:, :, :], (2, 2, 1))\n    _check(arr[3, :, :], np_inp[3, :, :], (2, 1))\n    _check(arr[-1, -1, -1], np_inp[-1, -1, -1], ())\n    _check(arr[2, -1, :], np_inp[2, -1, :], (1,))\n    _check(arr[2, 3, 1], np_inp[2, 3, 1], ())\n    _check(arr[-1], np_inp[-1], (2, 1))\n    _check(arr[:], np_inp[:], (2, 2, 1))\n    _check(arr[np.array(0), :, :], np_inp[np.array(0), :, :], (2, 1))\n    _check(arr[jnp.array(0), :, :], np_inp[jnp.array(0), :, :], (2, 1))\n    _check(arr[0, :2, 1], np_inp[0, :2, 1], (2,))\n    _check(arr[:, 1::2], np_inp[:, 1::2], (2, 2, 1))\n    _check(arr[:, -1:, :], np_inp[:, -1:, :], (2, 1, 1))\n    _check(arr[0:6:1], np_inp[0:6:1], (2, 2, 1))\n    _check(arr[:4], np_inp[:4], (2, 2, 1))\n    _check(arr[::-1], np_inp[::-1], (2, 2, 1))\n    _check(arr[1], np_inp[1], (2, 1))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def _check(x_type, y_type):\n    x = jnp.arange(5, dtype=x_type)\n    y = y_type(0)\n    out = x.at[0].set(y)\n    self.assertEqual(x.dtype, out.dtype)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\ndef f(x):\n    return x * 2"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(z):\n    x_re = jnp.concatenate([jnp.real(z), jnp.imag(z)])\n    return f_re(x_re)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@run_state\ndef f(x_ref):\n    x = x_ref[...]\n\n    def _body(ref):\n        ref[...] = jnp.sin(ref[...])\n    x = run_state(_body)(x)\n    x_ref[...] = x"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@functools.partial(new_checkpoint, policy=policy)\ndef f(x):\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.einsum('ij,jk->ik', x, x, precision=lax.Precision.HIGHEST)\n    x = jnp.sin(x)\n    x = jnp.sum(x)\n    return x"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@functools.partial(jax.jit, static_argnames=['c'])\ndef f(x, *, c):\n    return c * jnp.sin(x)"
  },
  {
    "test_code": "def test_shape_dtype_struct_sharding_jit(self):\n    mesh = jtu.create_mesh((8,), 'x')\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    x_dummy = jax.ShapeDtypeStruct(shape=(16,), dtype=jnp.dtype('float32'), sharding=s)\n\n    def f(x):\n        return x * 2\n    c = jax.jit(f).lower(x_dummy).compile()\n    input_shardings, output_shardings = (c.input_shardings, c.output_shardings)\n    self.assertLen(input_shardings, 2)\n    self.assertEqual(input_shardings[1], {})\n    self.assertEqual(input_shardings[1], {})\n    self.assertTrue(op_shardings.are_op_shardings_equal(input_shardings[0][0]._to_xla_hlo_sharding(x_dummy.ndim), s._to_xla_hlo_sharding(x_dummy.ndim)))\n    self.assertTrue(op_shardings.are_op_shardings_equal(output_shardings._to_xla_hlo_sharding(x_dummy.ndim), s._to_xla_hlo_sharding(x_dummy.ndim)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_shape_dtype_struct_sharding_pjit(self):\n    mesh = jtu.create_mesh((4, 2), ('x', 'y'))\n    s = jax.sharding.NamedSharding(mesh, P('x', 'y'))\n\n    def f(x):\n        return x * 2.0\n    x_dummy = jax.ShapeDtypeStruct(shape=(8, 2), dtype=jnp.dtype('float32'), sharding=s)\n    c = pjit(f).lower(x_dummy).compile()\n    input_shardings, output_shardings = (c.input_shardings, c.output_shardings)\n    self.assertTrue(op_shardings.are_op_shardings_equal(input_shardings[0][0]._to_xla_hlo_sharding(x_dummy.ndim), s._to_xla_hlo_sharding(x_dummy.ndim)))\n    self.assertTrue(op_shardings.are_op_shardings_equal(output_shardings._to_xla_hlo_sharding(x_dummy.ndim), s._to_xla_hlo_sharding(x_dummy.ndim)))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "@parameterized.named_parameters(('sharded_dim_0', (4, 2), 0), ('sharded_dim_1_0', (4, 2), 1), ('sharded_dim_2', (4, 2, 4), 2), ('sharded_dim_1_1', (2, 4), 1))\ndef test_default_pmap_sharding(self, shape, sharded_dim):\n    if jax.device_count() < 4:\n        self.skipTest('Test needs >= 4 devices.')\n    ps = jax.sharding.PmapSharding.default(shape, sharded_dim)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    compiled = jax.pmap(lambda x: x, in_axes=sharded_dim).lower(inp).compile()\n    pmap_in_sharding, = compiled._executable.unsafe_call.in_handler.in_shardings\n    self.assertEqual(ps._device_assignment, pmap_in_sharding._device_assignment)\n    self.assertEqual(ps.sharding_spec, pmap_in_sharding.sharding_spec)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def lower(self, x, _experimental_lowering_parameters=None):\n    return jax.jit(self.__call__).lower(x, _experimental_lowering_parameters=_experimental_lowering_parameters)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n\n    @partial(map_fun, in_axes=1, out_axes=2)\n    def h(y):\n        return jnp.sin(x + y)\n    return h(y).sum()"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(carry, x):\n    return (carry + jax.lax.psum(jnp.sum(x), axis_name='x'), None)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(k1, k2, k3, k4):\n    batch_size = 1\n    seq_len = 1\n    input_size = 1\n    hidden_size = 1\n    bidirectional = False\n    num_directions = 2 if bidirectional else 1\n    num_layers = 1\n    x = jax.random.normal(k1, (batch_size, seq_len, input_size), dtype=jnp.float32)\n    h_0 = jax.random.normal(k2, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    c_0 = jax.random.normal(k3, (num_directions * num_layers, batch_size, hidden_size), dtype=jnp.float32)\n    seq_lengths = jnp.ones((batch_size,), dtype=jnp.int32) * seq_len\n    weights = rnn.init_lstm_weight(k4, input_size, hidden_size, num_layers, bidirectional)\n    return rnn.lstm(x, h_0, c_0, weights, seq_lengths=seq_lengths, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=False, bidirectional=bidirectional)"
  },
  {
    "test_code": "def test_jnp_array_jnp_add(self):\n    arr = jnp.add(jnp.array([1, 2, 3]), jnp.array([4, 5, 6]))\n    self.assertIsInstance(arr, array.ArrayImpl)\n    self.assertArraysEqual(arr, np.array([5, 7, 9]))\n    self.assertIsInstance(arr.sharding, jax.sharding.SingleDeviceSharding)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def add(self, x: jax.Array) -> jax.Array:\n    self.value += np.asarray(x)\n    return jax.device_put(self.value, x.sharding)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@colocated_python.colocated_python\ndef f(x):\n    out_arrays = []\n    for shard in x.addressable_shards:\n        np_array = jax.device_get(shard.data)\n        input_ints = struct.unpack('<ii', base64.b64decode(np_array[0].encode('ascii')))\n        output_string = base64.b64encode(struct.pack('<ii', input_ints[0] + 1, input_ints[1] + 1)).decode('ascii')\n        out_np_array = np.array([output_string], dtype=np.dtypes.StringDType())\n        out_arrays.append(jax.device_put(out_np_array, device=shard.device))\n    out = jax.make_array_from_single_device_arrays(sharding=x.sharding, shape=x.shape, arrays=out_arrays)\n    return out"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x, y):\n    s = jit(jnp.sin)(x)\n    return jnp.sin(s) + jnp.cos(y)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@partial(jax.jit, in_shardings=NamedSharding(mesh, PartitionSpec('x')), out_shardings=NamedSharding(mesh, PartitionSpec('x')), compiler_options=compiler_options)\ndef f(x):\n    agg = x\n    for _ in range(its):\n        agg = agg @ x\n    return agg"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.jit\ndef f(_, y):\n    input_effect(y, index=0)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@checkify.checkify\ndef f():\n    checkify.check(x > 0, 'must be positive!')\n    return jnp.log(x)"
  },
  {
    "test_code": "def test_array_iter_pmap_sharding(self):\n    if jax.device_count() < 2:\n        self.skipTest('Test requires >= 2 devices.')\n    x = jnp.array([[1.0, 0.0, 0.0], [0.0, 2.0, 3.0]])\n    y = jax.pmap(jnp.sin)(x)\n    self.assertArraysEqual([list(a.devices())[0] for a in y], y.sharding._device_assignment, allow_object_dtype=True)\n    sin_x = iter(np.sin(x))\n    for i, j in zip(iter(y), sin_x):\n        self.assertIsInstance(i, array.ArrayImpl)\n        self.assertArraysAllClose(i, j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.custom_vjp\ndef sin(x):\n    return jnp.sin(x)"
  },
  {
    "test_code": "def test_array_iter_pmap_sharding_last_dim_sharded(self):\n    if jax.device_count() < 2:\n        self.skipTest('Test requires >= 2 devices.')\n    x = jnp.array([[1.0, 0.0, 0.0], [0.0, 2.0, 3.0]])\n    y = jax.pmap(jnp.sin, out_axes=1)(x)\n    for i, j in zip(iter(y), iter(np.sin(x).T)):\n        self.assertArraysAllClose(i, j)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "@jax.custom_vjp\ndef sin(x):\n    return jnp.sin(x)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(z):\n    y = odeint(dz_dt, z, jnp.arange(10.0))\n    return jnp.sum(y)"
  },
  {
    "test_code": "def test_make_array_from_callback_error(self):\n    mesh_shape = (2, 3)\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    pspec = P('x', 'y')\n    sharding = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = jnp.arange(n).astype('uint32').reshape(global_shape)\n\n    def f(arr):\n        return array.make_array_from_callback(arr.shape, sharding, lambda i: arr[i])\n    out = f(global_x)\n    self.assertEqual(out.shape, global_shape)\n    msg = 'jax.make_array_from_callback cannot be called within a traced context'\n    with self.assertRaisesRegex(jax.errors.UnexpectedTracerError, msg):\n        jax.jit(f)(global_x)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "@parameterized.named_parameters(('3', 3), ('4', 4), ('5', 5))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_1d(self, num_devices):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    mesh = jtu.create_mesh((num_devices,), ('x',), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, P('x'))\n    n = num_devices ** 2\n    global_x = jnp.arange(n).astype('uint32')\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        self.assertIn(f'[{n}]', unopt_txt)\n        self.assertNotIn(f'[{n}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  },
  {
    "test_code": "@parameterized.named_parameters(({'testcase_name': f'_{mesh_shape}_{pspec}', 'mesh_shape': mesh_shape, 'pspec': pspec} for mesh_shape in [(3, 2), (4, 2), (2, 3)] for pspec in [P('x', None), P(None, 'y'), P('x', 'y')]))\n@jtu.skip_on_devices('gpu')\ndef test_random_bits_is_pure_map_2d(self, mesh_shape, pspec):\n\n    @jax.jit\n    def f(x):\n        bits = prng.threefry_random_bits(jnp.array([0, 0], dtype='uint32'), 32, x.shape)\n        return bits + x\n    global_shape = tuple(np.square(mesh_shape))\n    mesh = jtu.create_mesh(mesh_shape, ('x', 'y'), iota_order=True)\n    s = jax.sharding.NamedSharding(mesh, pspec)\n    n = math.prod(global_shape)\n    global_x = np.arange(n).astype('uint32').reshape(global_shape)\n    x = array.make_array_from_callback(global_x.shape, s, lambda i: global_x[i])\n    with jax.threefry_partitionable(True):\n        unopt_txt = f.lower(x).as_text(dialect='hlo')\n        opt_txt = f.lower(x).compile().as_text()\n        global_shape_fmt = ','.join((str(x) for x in global_shape))\n        self.assertIn(f'[{global_shape_fmt}]', unopt_txt)\n        self.assertNotIn(f'[{global_shape_fmt}]', opt_txt)\n        self.assertNotIn('all-reduce', opt_txt)\n        self.assertNotIn('collective-permute', opt_txt)\n        y = f(x)\n        y_ref1 = f(jax.device_put(x, jax.devices()[0]))\n        self.assertArraysEqual(y, y_ref1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/array_test.py",
    "function": "def f(x):\n    return x.at[1].apply(jax.numpy.sin)"
  }
]