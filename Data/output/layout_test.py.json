[
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g():\n    return jnp.zeros(n) + x"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g():\n    return jnp.zeros(n) + x"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def g():\n    return jax.lax.cond(True, lambda: data[0], lambda: data[1])"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def g():\n    return jax.lax.cond(True, lambda: data[0], lambda: data[1])"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g():\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g():\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def g(a, b):\n    c = jnp.zeros_like(a)\n    _, b, c, _ = for_impl(5, body2, (a, b, c, 0))\n    return (b, c)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def g(a, b):\n    c = jnp.zeros_like(a)\n    _, b, c, _ = for_impl(5, body2, (a, b, c, 0))\n    return (b, c)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jsp.special.betainc(jnp.ones(3), 1.0, x)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return jnp.add(3.0, 4.0)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x, y):\n    z = jax_getattr(thing1, 'x')\n    w = jax_getattr(thing2, 'x')\n    out = jnp.sin(x * y * z * w)\n    jax_setattr(thing1, 'x', out)\n    jax_setattr(thing2, 'x', 2 * out)\n    return (3 * out, 4 * out)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g():\n    _, _, attr_tangents = attrs.jvp(f, (), (), [(thing, 'x', 1.0)])\n    (thing_, attr_, tangent_), = attr_tangents\n    self.assertIs(thing, thing_)\n    self.assertEqual(attr_, 'x')\n    return (jax_getattr(thing, 'x'), tangent_)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g():\n    _, _, attr_tangents = attrs.jvp(f, (), (), [(thing, 'x', 1.0)])\n    (thing_, attr_, tangent_), = attr_tangents\n    self.assertIs(thing, thing_)\n    self.assertEqual(attr_, 'x')\n    return (jax_getattr(thing, 'x'), tangent_)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.vmap\n@jax.value_and_grad\n@jax.named_scope('foo')\ndef f(x):\n\n    @jax.named_scope('scan_body')\n    def body(carry, x):\n        return (carry * x, carry + x)\n    return lax.scan(body, x, jnp.arange(8.0))[0]"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@pjit\ndef g(y):\n    return jnp.sin(y)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@pjit\ndef g(y):\n    return jnp.sin(y)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(c, a):\n    tracer_spy.append(c)\n    d = 0.75\n    b = jnp.sin(c * jnp.sum(jnp.cos(d * a)))\n    c = 0.9 * jnp.cos(d * jnp.sum(jnp.sin(c * a)))\n    return (c, b)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.remat\ndef g(x):\n    jax.jit(lambda: 0 if jnp.add(1, 1) else 0)()\n    return lax.sin(x)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.remat\ndef g(x):\n    jax.jit(lambda: 0 if jnp.add(1, 1) else 0)()\n    return lax.sin(x)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(pred):\n\n    def true_fun():\n        x_ref[()] = 1.0\n\n    def false_fun():\n        x_ref[()] = 2.0\n    jax.lax.cond(pred, true_fun, false_fun)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@functools.partial(pjit.pjit, in_shardings=jax.sharding.PartitionSpec(None), out_shardings=jax.sharding.PartitionSpec('x'))\ndef f():\n    return jnp.zeros([32, 10])"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, r):\n    x = x.at[:, 0].set(x[:, 0] / r)\n    return x"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g(x):\n    if x > 0.0:\n        return x * 2\n    else:\n        return x + 2"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g(x):\n    if x > 0.0:\n        return x * 2\n    else:\n        return x + 2"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jnp.vectorize, excluded={1})\ndef f(x, y):\n    assert x.ndim == 0\n    assert y == 'foo'\n    return x"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef f(x, y):\n    return x * y"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef g(z):\n    return f(z, z + 77)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.pmap\ndef g(z):\n    return f(z, z + 77)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef f(x, y):\n    return jax.vmap(shard_alike, in_axes=(0, 1))(x, y)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g(x):\n    z = x * 2\n    return shard_alike(x, z)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g(x):\n    z = x * 2\n    return shard_alike(x, z)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    return random.uniform(self.make_key(3), (308000000, 128), dtype=jnp.bfloat16)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.custom_jvp\ndef g(x):\n    return x"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.custom_jvp\ndef g(x):\n    return x"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    return jax.lax.convert_element_type(x, FooTy())"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    y = x * jnp.arange(3.0).reshape((1, 3))\n    return jnp.take_along_axis(y, idx, -1).sum()"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g(x):\n    if x > 0.0:\n        return x * 2\n    else:\n        return x + 2"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g(x):\n    if x > 0.0:\n        return x * 2\n    else:\n        return x + 2"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P())\ndef f(x):\n    return jax.lax.psum(((w * x) ** 2).sum(), 'i')"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('x', 'y'), out_specs=out_spec)\ndef g(x):\n    result = lax.psum(x, axis_name=reduce_along)\n\n    def check_rep(result):\n        self.assertEqual(jax.experimental.shard_map.get_replication(result), set(reduce_along))\n        return result\n    result = check_rep(result)\n    result = jax.vmap(check_rep)(result)\n    return result"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(shard_map, mesh=mesh, in_specs=P('x', 'y'), out_specs=out_spec)\ndef g(x):\n    result = lax.psum(x, axis_name=reduce_along)\n\n    def check_rep(result):\n        self.assertEqual(jax.experimental.shard_map.get_replication(result), set(reduce_along))\n        return result\n    result = check_rep(result)\n    result = jax.vmap(check_rep)(result)\n    return result"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f():\n    out = [rng(shape, dtype or jnp.float_) for shape, dtype in zip(shapes, dtypes)]\n    if np_arrays:\n        return out\n    return [jnp.asarray(a) if isinstance(a, (np.ndarray, np.generic)) else a for a in out]"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(seed):\n    key = jax.random.key(seed)\n    return jax.random.uniform(key) + jax.random.normal(key)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g(x):\n    return x"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.jit\ndef g(x):\n    return x"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x_ref):\n    ones = jnp.ones_like(x_ref)[slc]\n    ref_primitives.ref_addupdate(x_ref, slc, ones)\n    x1 = ref_primitives.ref_get(x_ref, slc)\n    x2 = x1 + ones\n    ref_primitives.ref_set(x_ref, slc, x2)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(self, ys):\n    return lax.fori_loop(0, 10, loop_body, jnp.ones(4, np.float32))"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def g(x):\n    return jax.pure_callback(lambda x: x, x, x)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def g(x):\n    return jax.pure_callback(lambda x: x, x, x)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(hx, _):\n    hx = jax.nn.sigmoid(hx + a)\n    return (hx, None)"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def f(x):\n    u, s, v = jnp.linalg.svd(a + x * b, full_matrices=full_matrices, compute_uv=compute_uv)\n    vdiag = jnp.vectorize(jnp.diag, signature='(k)->(k,k)')\n    return jnp.matmul(jnp.matmul(u, vdiag(s).astype(u.dtype)), v).real"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def g(a, b):\n    an, ai = a\n    bn, bi = b\n    which = an >= bn\n    return (jnp.where(which, an, bn), jnp.where(which, ai, bi))"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "def g(a, b):\n    an, ai = a\n    bn, bi = b\n    which = an >= bn\n    return (jnp.where(which, an, bn), jnp.where(which, ai, bi))"
  },
  {
    "test_code": "def test_wsc_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_wsc_bfloat16_concrete_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    inp = jnp.arange(math.prod(shape), dtype=jnp.bfloat16).reshape(shape)\n    arr = jax.device_put(inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @jax.jit\n    def f(x):\n        y = x.T\n        return jax.lax.with_sharding_constraint(y, Layout(custom_dll, s))\n    out = f(arr)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)\n    self.assertEqual(out.layout, arr.layout)\n    self.assertArraysEqual(out, inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_concrete_layout_jit(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    shape = (16, 128)\n    s = NamedSharding(mesh, P('x'))\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    def f(x):\n        return x.T\n    custom_dll = DLL(major_to_minor=(0, 1))\n    f = jax.jit(f, out_shardings=Layout(custom_dll, s))\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_compatible_aval_error(self):\n    custom_dll = DLL(major_to_minor=(0, 1, 2))\n    l = Layout(custom_dll, SingleDeviceSharding(jax.devices()[0]))\n    inp = np.arange(8)\n\n    @partial(jax.jit, in_shardings=l)\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Length of major_to_minor and the rank of the value should match.*'):\n        f(inp)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_in_layouts_jit_jnp_input(self):\n    major_last_layout = DLL(major_to_minor=(1, 0))\n    sharding = jax.sharding.SingleDeviceSharding(jax.devices()[0])\n    f = jax.jit(lambda x: x + 1, in_shardings=Layout(major_last_layout, sharding))\n    arr = jnp.arange(8 * 128).reshape(8, 128)\n    out = f(arr)\n    self.assertArraysEqual(out, arr + 1)\n    out2 = f(arr)\n    self.assertArraysEqual(out2, arr + 1)\n    np_inp = np.arange(8 * 128).reshape(8, 128)\n    out3 = f(np_inp)\n    self.assertArraysEqual(out3, np_inp + 1)\n    out4 = f(np_inp)\n    self.assertArraysEqual(out4, np_inp + 1)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_layout_donation(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    arr = jax.device_put(np_inp, Layout(custom_dll, s))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), donate_argnums=0)\n    def f(x):\n        return x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_layout_donation_auto(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n\n    @partial(jax.jit, out_shardings=Layout(DLL.AUTO), donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_layout_donation_matching_in_and_out(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (128, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    custom_dll = DLL(major_to_minor=(0, 1))\n    l = Layout(custom_dll, s)\n    arr = jax.device_put(np_inp, l)\n\n    @partial(jax.jit, in_shardings=l, out_shardings=l, donate_argnums=0)\n    def f(x):\n        return x * x\n    f(arr)\n    self.assertTrue(arr.is_deleted())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_sparsecore_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    dense_layout = Layout(DLL(major_to_minor=(0, 1)), s)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @partial(jax.jit, out_shardings=(dense_layout, sparse_layout))\n    def f(x, y):\n        return (x * 2, sparsecore_compute(y))\n    f(inp, sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_sparsecore_compute_twice(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (4096, 8)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_layout = Layout(dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_multiply(x, y):\n        return x * y\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_add(x, y):\n        return x + y\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=sparse_layout)\n    def f(x):\n        return sparsecore_multiply(sparsecore_add(x, x) + 1, x)\n    f(sparecore_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_sparsecore_and_host_compute(self):\n    if not (jax.devices()[0].device_kind == 'TPU v5' or jtu.is_device_tpu_at_least(6)):\n        self.skipTest('Does not have a sparsecore present')\n    shape = (128, 128)\n    inp = jnp.arange(math.prod(shape)).reshape(shape)\n    s = SingleDeviceSharding(jax.devices()[0])\n    sparse_dll = DLL(major_to_minor=(0, 1), _tiling=((8,),))\n    sparse_layout = Layout(sparse_dll, s)\n    sparecore_arr = jax.device_put(inp, sparse_layout)\n    host_dll = DLL(major_to_minor=(0, 1), _tiling=((1,),))\n    host_layout = Layout(host_dll, s)\n    host_arr = jax.device_put(inp, host_layout)\n\n    @compute_on('tpu_sparsecore')\n    @jax.jit\n    def sparsecore_compute(x):\n        return x * x\n\n    @compute_on('device_host')\n    @jax.jit\n    def host_compute(x):\n        return x + x\n\n    @partial(jax.jit, in_shardings=(sparse_layout, host_layout), out_shardings=(sparse_layout, host_layout))\n    def f(x, y):\n        return (sparsecore_compute(x), host_compute(y))\n    f(sparecore_arr, host_arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_cpp_layout_cache_miss(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    arr_m2m = arr.layout.device_local_layout.major_to_minor\n    custom_layout = Layout(DLL(major_to_minor=arr_m2m[::-1]), s)\n    arr2 = jax.device_put(np_inp, custom_layout)\n\n    @jax.jit\n    def f(x):\n        return x @ x.T\n    with jtu.count_pjit_cpp_cache_miss() as count:\n        out = f(arr)\n        out2 = f(arr2)\n    self.assertEqual(count(), 2)\n    self.assertArraysEqual(out, np_inp @ np_inp.T)\n    self.assertArraysEqual(out2, np_inp @ np_inp.T)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_layout_donation_with_default_layout(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 16)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    out_layout = Layout(arr.layout.device_local_layout, s)\n\n    @partial(jax.jit, out_shardings=out_layout, donate_argnums=0)\n    def f(x):\n        return x * 2\n    lowered_text = f.lower(arr).as_text()\n    self.assertIn('tf.aliasing_output = 0', lowered_text)\n    self.assertNotIn('jax.buffer_donor', lowered_text)\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp * 2)\n    self.assertEqual(out.layout, out_layout)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@jax.profiler.annotate_function\ndef f(x, *, name):\n    return x + 2 * len(name)"
  },
  {
    "test_code": "def test_concrete_layout_in_shardings(self):\n    mesh = jtu.create_mesh((2, 2), ('x', 'y'))\n    s = NamedSharding(mesh, P('x', 'y'))\n    shape = (16, 128)\n    np_inp = np.arange(math.prod(shape)).reshape(shape)\n    arr = jax.device_put(np_inp, s)\n    custom_dll = DLL(major_to_minor=(0, 1))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll, s), out_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x.T\n    out = f(arr)\n    self.assertArraysEqual(out, np_inp.T)\n    self.assertEqual(out.layout.device_local_layout.major_to_minor, custom_dll.major_to_minor[::-1])\n    custom_dll2 = DLL(major_to_minor=(1, 0))\n\n    @partial(jax.jit, in_shardings=Layout(custom_dll2, s))\n    def g(x):\n        return x.T\n    with self.assertRaisesRegex(ValueError, 'Layout passed to jit does not match the layout on the respective arg'):\n        g(arr)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.profiler.annotate_function, name='aname')\ndef g(x):\n    return x + 2"
  },
  {
    "test_code": "def test_donation_error_on_auto(self):\n\n    @partial(jax.jit, donate_argnums=0, in_shardings=Layout(DLL.AUTO))\n    def f(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*output layout.*AUTO.*'):\n        f(jnp.arange(8))\n\n    @partial(jax.jit, donate_argnums=0, out_shardings=Layout(DLL.AUTO))\n    def g(x):\n        return x * 2\n    with self.assertRaisesRegex(ValueError, '.*Did you mean to set the.*input layout.*AUTO.*'):\n        g(jnp.arange(8))",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/layout_test.py",
    "function": "@partial(jax.profiler.annotate_function, name='aname')\ndef g(x):\n    return x + 2"
  }
]