[
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'))\n    def f(x):\n        return ffi_call_geqrf(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'), check_rep=False)\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_batch_partitioning(self):\n\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n    x_sharding = jax.NamedSharding(mesh, P('i'))\n    x = jax.device_put(x, x_sharding)\n    f_jit = jax.jit(f, out_shardings=x_sharding)\n    f(x)\n    f_jit(x)\n    self.assertNotIn('all-gather', f_jit.lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f():\n    jax.random.normal(jax.random.key(0), 1000)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'))\n    def f(x):\n        return ffi_call_geqrf(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'), check_rep=False)\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_batch_partitioning(self):\n\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n    x_sharding = jax.NamedSharding(mesh, P('i'))\n    x = jax.device_put(x, x_sharding)\n    f_jit = jax.jit(f, out_shardings=x_sharding)\n    f(x)\n    f_jit(x)\n    self.assertNotIn('all-gather', f_jit.lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@partial(jax.jit, abstracted_axes=(None, 'n'))\ndef f(x):\n    return x[0]"
  },
  {
    "test_code": "def test_non_hashable_attributes(self):\n\n    def fun(x):\n        return jax.ffi.ffi_call('test_ffi', x)(x, non_hashable_arg={'a': 1})\n    self.assertIn('HashableDict', str(jax.make_jaxpr(fun)(jnp.ones(5))))\n    hlo = jax.jit(fun).lower(jnp.ones(5)).as_text()\n    self.assertIn('non_hashable_arg = {a = 1', hlo)\n    with self.assertRaises(Exception) as manager:\n        fun(jnp.ones(5))\n    self.assertNotIsInstance(manager.exception, TypeError)\n\n    def fun(x):\n        return jax.ffi.ffi_call('test_ffi', x)(x, non_hashable_arg=np.arange(3))\n    self.assertIn('HashableArray', str(jax.make_jaxpr(fun)(jnp.ones(5))))\n    hlo = jax.jit(fun).lower(jnp.ones(5)).as_text()\n    self.assertIn('non_hashable_arg = dense<[0, 1, 2]> : tensor<3xi64>', hlo)\n    with self.assertRaises(Exception) as manager:\n        fun(jnp.ones(5))\n    self.assertNotIsInstance(manager.exception, TypeError)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@partial(jax.jit, abstracted_axes=('n',))\ndef fun(x):\n    return jnp.sum(x)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'))\n    def f(x):\n        return ffi_call_geqrf(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'), check_rep=False)\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_batch_partitioning(self):\n\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n    x_sharding = jax.NamedSharding(mesh, P('i'))\n    x = jax.device_put(x, x_sharding)\n    f_jit = jax.jit(f, out_shardings=x_sharding)\n    f(x)\n    f_jit(x)\n    self.assertNotIn('all-gather', f_jit.lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(x):\n    y = x + 2\n    return (jnp.nan, y)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'))\n    def f(x):\n        return ffi_call_geqrf(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'), check_rep=False)\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_batch_partitioning(self):\n\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n    x_sharding = jax.NamedSharding(mesh, P('i'))\n    x = jax.device_put(x, x_sharding)\n    f_jit = jax.jit(f, out_shardings=x_sharding)\n    f(x)\n    f_jit(x)\n    self.assertNotIn('all-gather', f_jit.lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "def f(x, y):\n    x, y = jax.lax.cond(x < 3, lambda x, y: (x * 2, y), lambda x, y: (x * 3, y), x, y)\n    return (x, y)"
  },
  {
    "test_code": "def test_non_hashable_attributes(self):\n\n    def fun(x):\n        return jax.ffi.ffi_call('test_ffi', x)(x, non_hashable_arg={'a': 1})\n    self.assertIn('HashableDict', str(jax.make_jaxpr(fun)(jnp.ones(5))))\n    hlo = jax.jit(fun).lower(jnp.ones(5)).as_text()\n    self.assertIn('non_hashable_arg = {a = 1', hlo)\n    with self.assertRaises(Exception) as manager:\n        fun(jnp.ones(5))\n    self.assertNotIsInstance(manager.exception, TypeError)\n\n    def fun(x):\n        return jax.ffi.ffi_call('test_ffi', x)(x, non_hashable_arg=np.arange(3))\n    self.assertIn('HashableArray', str(jax.make_jaxpr(fun)(jnp.ones(5))))\n    hlo = jax.jit(fun).lower(jnp.ones(5)).as_text()\n    self.assertIn('non_hashable_arg = dense<[0, 1, 2]> : tensor<3xi64>', hlo)\n    with self.assertRaises(Exception) as manager:\n        fun(jnp.ones(5))\n    self.assertNotIsInstance(manager.exception, TypeError)",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef fun(x, y):\n    return cond(x < 3, None, lambda _: 2.0 * jnp.sin(y), x, lambda x: 2.0 * x)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'))\n    def f(x):\n        return ffi_call_geqrf(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'), check_rep=False)\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_batch_partitioning(self):\n\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n    x_sharding = jax.NamedSharding(mesh, P('i'))\n    x = jax.device_put(x, x_sharding)\n    f_jit = jax.jit(f, out_shardings=x_sharding)\n    f(x)\n    f_jit(x)\n    self.assertNotIn('all-gather', f_jit.lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(x):\n    return 0.0 / x"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'))\n    def f(x):\n        return ffi_call_geqrf(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'), check_rep=False)\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_batch_partitioning(self):\n\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n    x_sharding = jax.NamedSharding(mesh, P('i'))\n    x = jax.device_put(x, x_sharding)\n    f_jit = jax.jit(f, out_shardings=x_sharding)\n    f(x)\n    f_jit(x)\n    self.assertNotIn('all-gather', f_jit.lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f():\n    weird_dict = {lambda x: x: 2.0, lambda x: x * 2: 3}\n    weirder_dict = {lambda x: x: weird_dict}\n    x = 2.0\n    debugger.breakpoint(stdin=stdin, stdout=stdout, backend='cli')\n    del weirder_dict\n    return x"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'))\n    def f(x):\n        return ffi_call_geqrf(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'), check_rep=False)\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_batch_partitioning(self):\n\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n    x_sharding = jax.NamedSharding(mesh, P('i'))\n    x = jax.device_put(x, x_sharding)\n    f_jit = jax.jit(f, out_shardings=x_sharding)\n    f(x)\n    f_jit(x)\n    self.assertNotIn('all-gather', f_jit.lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(x):\n    out = jnp.zeros_like(x)\n\n    def body(i, j, k, refs):\n        x_ref, out_ref = refs\n        y = func(x_ref[i, j, k])\n        out_ref[i, j, k] += y\n    return for_loop.for_loop(x.shape, body, (x, out))[1].sum()"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'))\n    def f(x):\n        return ffi_call_geqrf(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_shard_map(self):\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n\n    @partial(shard_map, mesh=mesh, in_specs=P('i'), out_specs=P('i'), check_rep=False)\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    f(x)\n    jax.jit(f)(x)\n    self.assertNotIn('all-gather', jax.jit(f).lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  },
  {
    "test_code": "@jtu.run_on_devices('gpu', 'cpu')\ndef test_batch_partitioning(self):\n\n    def f(x):\n        return batch_partitionable_ffi_call(x)\n    mesh = jtu.create_mesh((len(jax.devices()),), ('i',))\n    x = self.rng().randn(8, 4, 5).astype(np.float32)\n    x_sharding = jax.NamedSharding(mesh, P('i'))\n    x = jax.device_put(x, x_sharding)\n    f_jit = jax.jit(f, out_shardings=x_sharding)\n    f(x)\n    f_jit(x)\n    self.assertNotIn('all-gather', f_jit.lower(x).compile().as_text())",
    "assertions": [],
    "test_file": "/var/folders/q5/p2sqhr0d6nqb_h8x_fxyxpz80000gn/T/tmp_1jzy6em/jax/tests/ffi_test.py",
    "function": "@jax.jit\ndef f(a, b, c, d, e):\n    return (a, b, c, d, e)"
  }
]