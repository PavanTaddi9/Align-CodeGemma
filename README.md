# Align-CodeGemma: JAX-Aware Code Generation & Alignment

A comprehensive framework for fine-tuning Google's **Gemma-3** to generate high-quality **JAX-based code** for computational tasks. This project implements advanced alignment techniques, execution-time validation, and reward-driven optimization using **GRPO** (Guided Reinforcement with Prompt Objectives).

## ğŸ¯ Project Overview

This project addresses the challenge of generating domain-specific JAX code by:
- Fine-tuning Gemma-3 4B with specialized alignment techniques
- Implementing real-time code execution validation
- Using reinforcement learning to optimize code quality
- Developing custom metrics for JAX primitive evaluation

## ğŸš€ Key Features

- **Fill-in-the-Middle (FIM) Training**: Advanced data preprocessing for better code completion
- **GRPO Optimization**: Custom reinforcement learning approach for code generation improvement
- **Execution Validation**: Real-time code testing and validation pipeline
- **JAX-Specific Metrics**: Custom evaluation framework for JAX primitive usage
- **Scalable Architecture**: Docker-based deployment with FastAPI execution server

## ğŸ“ Project Structure

```
Align-CodeGemma/
â”œâ”€â”€ datas/                          # Data preprocessing & tokenization
â”‚   â”œâ”€â”€ prepare_data.py            # Dataset preparation and format conversion
â”‚   â””â”€â”€ tokenize_dataset.ipynb     # Tokenization analysis and optimization
â”‚
â”œâ”€â”€ execserver/                     # Code execution and validation system
â”‚   â”œâ”€â”€ server.py                  # FastAPI server for code execution
â”‚   â”œâ”€â”€ routes.py                  # API endpoints for validation pipeline
â”‚   â””â”€â”€ utils.py                   # JAX primitive validation utilities
â”‚
â”œâ”€â”€ src/                           # Core alignment and inference logic
â”‚   â”œâ”€â”€ alignment.py               # FIM-style training data generation
â”‚   â”œâ”€â”€ inference.py               # CodeGemma model interaction and decoding
â”‚   â”œâ”€â”€ evaluate.py                # Functional correctness evaluation
â”‚   â””â”€â”€ rewards.py                 # Multi-objective reward computation
â”‚
â”œâ”€â”€ Dockerfile                     # Container deployment configuration
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”§ Technical Implementation

### Data Processing (`datas/`)
- **Data Preparation**: Converts raw code datasets into FIM-compatible training formats optimized for JAX syntax
- **Tokenization Analysis**: Implements specialized tokenization strategies for JAX computational graphs

### Execution Server (`execserver/`)
- **Validation Pipeline**: Real-time code execution with security sandboxing
- **API Framework**: RESTful endpoints for code testing and result aggregation
- **JAX Analysis**: Automated detection and validation of JAX primitives

### Core Engine (`src/`)
- **Model Alignment**: FIM-based training data generation with JAX-specific optimizations
- **Inference System**: Advanced decoding strategies with constraint-guided generation
- **Evaluation Framework**: Comprehensive metrics for code quality and functional correctness
- **Reward Optimization**: GRPO implementation with execution feedback integration

## ğŸ† Results & Impact

- **Improved Code Quality**: Significant enhancement in JAX-specific code generation accuracy
- **Functional Correctness**: High success rate in generated code execution and validation
- **Performance Optimization**: Efficient JAX primitive utilization in generated code
- **Scalable Framework**: Production-ready system with containerized deployment

## ğŸ› ï¸ Technologies Used

- **Model**: Google CodeGemma-3
- **Framework**: JAX, FastAPI, Docker
- **ML Techniques**: Fill-in-the-Middle training, GRPO, Reinforcement Learning
- **Evaluation**: Custom metrics, execution validation, automated testing

